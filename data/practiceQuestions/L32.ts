import type { PracticeQuestion } from '../../types';

export const L32_PRACTICE: Record<string, PracticeQuestion[]> = {
  L32101: [
    {
      question: '根據指引，金融機構在評估AI系統風險時，下列哪個情境的風險「較高」？',
      options: {
        A: '用於提升內部行政效率的AI系統。',
        B: '不涉及個人原始資料的智能客服系統。',
        C: '完全取代人類進行信用評分決策的AI系統。',
        D: '對AI決策結果提供完整申訴管道的系統。'
      },
      correctAnswer: 'C',
      explanation: '指引中提到，AI自主決策程度越高、對客戶權益影響越重大的系統，其風險越高。完全取代人類進行信用評分決策，符合這兩項特徵，因此風險較高。'
    },
    {
      question: 'AI系統的生命週期不包含下列哪個階段？',
      options: {
        A: '系統規劃及設計',
        B: '資料蒐集及輸入',
        C: '市場行銷及推廣',
        D: '系統部署及監控'
      },
      correctAnswer: 'C',
      explanation: '指引中定義的AI系統生命週期為：1.系統規劃及設計 -> 2.資料蒐集及輸入 -> 3.模型建立及驗證 -> 4.系統部署及監控。市場行銷推廣是商業活動，不屬於AI系統自身的技術生命週期。'
    },
    {
      question: '金融機構委託第三方業者導入AI時，應採取的監督管理措施「不」包含下列何者？',
      options: {
        A: '進行檢視評估',
        B: '簽訂書面契約',
        C: '完全信任第三方業者，不干涉其作業',
        D: '要求留存作業紀錄以利追蹤管理'
      },
      correctAnswer: 'C',
      explanation: '即使委外，金融機構仍需對AI系統負最終責任。因此，必須對第三方業者進行有效的監督管理，包括盡職調查、簽訂合約、確保資料保護和釐清責任，而非完全放任。'
    },
    {
      question: '在風險評估考量因素中，「AI系統越複雜、參數越多，可解釋性可能越低」，這指的是哪個因素？',
      options: {
        A: '對客戶/營運的影響',
        B: '個資使用程度',
        C: 'AI系統複雜性',
        D: '利害關係人影響廣度'
      },
      correctAnswer: 'C',
      explanation: '模型複雜性與可解釋性通常成反比。越複雜的模型（如深度神經網路）雖然性能可能更高，但其決策過程越難以理解，這本身就是一種風險。'
    },
    {
      question: '下列哪個AI應用，根據風險評估考量，最可能被視為「低風險」系統？',
      options: {
        A: '用於決定是否批准客戶貸款的AI模型。',
        B: '用於分析交易數據以進行反洗錢偵測的系統。',
        C: '用於內部會議，自動生成會議記錄摘要的AI工具。',
        D: '用於決定保險核保與費率的AI系統。'
      },
      correctAnswer: 'C',
      explanation: '內部使用的行政效率工具，不直接影響客戶權益，也不涉及客戶個資，其風險顯著低於直接影響客戶權益的信評、反洗錢或核保系統。'
    },
    {
      question: '金融機構應以何種基礎來決定AI系統風險控管措施的程度？',
      options: {
        A: '以成本最低為基礎',
        B: '以技術最先進為基礎',
        C: '以風險為基礎 (Risk-based Approach)',
        D: '以導入速度最快為基礎'
      },
      correctAnswer: 'C',
      explanation: '指引的核心精神是以風險為基礎，對不同風險等級的AI應用採取不同程度的控管措施。高風險應用需要更嚴格的治理，低風險應用則可相對簡化。'
    },
    {
      question: '「風險評估六角戰士」記憶輔助中，指的是哪六個評估面向？',
      options: {
        A: '成本、速度、人力、技術、市場、法規',
        B: '影響、個資、自主、複雜、廣度、救濟',
        C: '規劃、設計、開發、測試、部署、監控',
        D: '公平、透明、安全、穩健、隱私、永續'
      },
      correctAnswer: 'B',
      explanation: '記憶輔助對應了指引中的六大風險評估考量因素：對客戶/營運的影響、個資使用程度、AI自主決策程度、AI系統複雜性、利害關係人影響廣度、救濟選項完整性。'
    },
    {
      question: '在AI系統生命週期的哪個階段，會進行選擇、建立及訓練模型的工作？',
      options: {
        A: '系統規劃及設計',
        B: '資料蒐集及輸入',
        C: '模型建立及驗證',
        D: '系統部署及監控'
      },
      correctAnswer: 'C',
      explanation: '模型建立及驗證階段是AI專案的技術核心，涵蓋了從演算法選擇、模型訓練到性能驗證的完整流程。'
    },
    {
      question: '金融機構對第三方業者的監督管理責任，在哪個時間點結束？',
      options: {
        A: '簽訂合約後即結束。',
        B: '系統上線後即結束。',
        C: '這是一個持續性的責任，需要定期追蹤管理。',
        D: '支付完款項後即結束。'
      },
      correctAnswer: 'C',
      explanation: '對第三方業者的監督是一個持續的過程，金融機構需要確保其在整個合作期間都符合契約要求和相關規範，而非一次性的任務。'
    },
    {
      question: '何謂「生成式AI」？',
      options: {
        A: '只能生成文字的AI系統。',
        B: '能生成模擬人類智慧創造之內容的AI系統。',
        C: '專門用於資料庫管理的AI系統。',
        D: '不會犯任何錯誤的AI系統。'
      },
      correctAnswer: 'B',
      explanation: '根據指引定義，生成式AI的特點在於其「創造性」，能夠生成如文章、圖像、程式碼等全新的內容。'
    }
  ],
  L32102: [
    {
      question: '金融業運用AI的六大核心原則，其最終的共同目標是什麼？',
      options: {
        A: '追求最大利潤，降低所有人力成本。',
        B: '引導金融業在創新、風控與消費者權益之間取得平衡。',
        C: '全面取代傳統金融服務。',
        D: '僅為了符合主管機關的書面要求。'
      },
      correctAnswer: 'B',
      explanation: '六大核心原則旨在引導金融業在享受AI帶來的創新效益的同時，也能兼顧對消費者權益的保護、金融市場的穩定及社會責任，實現一個平衡且可持續的發展。'
    },
    {
      question: '確保AI系統運作的穩健性(robustness)與安全性，以避免對消費者或金融體系造成損害，這屬於六大核心原則中的哪一項？',
      options: {
        A: '建立治理及問責機制',
        B: '重視公平性及以人為本的價值觀',
        C: '確保系統穩健性與安全性',
        D: '落實透明性與可解釋性'
      },
      correctAnswer: 'C',
      explanation: '這是核心原則四的直接內容，強調AI系統在技術層面的可靠性與安全性，是所有應用的基礎保障。'
    },
    {
      question: '「避免演算法偏見所造成的不公平」是哪個核心原則的主要關注點？',
      options: {
        A: '保護隱私及客戶權益',
        B: '重視公平性及以人為本的價值觀',
        C: '落實透明性與可解釋性',
        D: '促進永續發展'
      },
      correctAnswer: 'B',
      explanation: '核心原則二明確指出應避免演算法偏見，確保AI運用符合公平待客、普惠金融等以人為本的價值觀。'
    },
    {
      question: '金融機構應對其使用的AI系統承擔內、外部責任，建立全面有效的AI相關風險管理機制，這體現了哪個核心原則？',
      options: {
        A: '建立治理及問責機制',
        B: '保護隱私及客戶權益',
        C: '確保系統穩健性與安全性',
        D: '促進永續發展'
      },
      correctAnswer: 'A',
      explanation: '這是核心原則一的內容，強調從組織治理的頂層設計出發，建立清晰的權責歸屬和風險管理框架。'
    },
    {
      question: '在與消費者互動時進行適當揭露，確保AI系統運作可被理解，屬於哪個核心原則？',
      options: {
        A: '建立治理及問責機制',
        B: '重視公平性及以人為本的價值觀',
        C: '保護隱私及客戶權益',
        D: '落實透明性與可解釋性'
      },
      correctAnswer: 'D',
      explanation: '核心原則五強調了透明與可解釋的重要性，旨在打開AI的「黑盒子」，讓其決策過程能被理解和信任。'
    },
    {
      question: '確保AI發展策略與永續發展原則相結合，促進包容性成長，並維護員工工作權益，這屬於哪個核心原則？',
      options: {
        A: '重視公平性及以人為本的價值觀',
        B: '保護隱私及客戶權益',
        C: '落實透明性與可解釋性',
        D: '促進永續發展'
      },
      correctAnswer: 'D',
      explanation: '核心原則六將AI的發展置於更宏大的社會責任框架下，要求金融機構在追求技術進步的同時，兼顧環境、社會及員工福祉。'
    },
    {
      question: '「妥善管理及運用客戶資料，並尊重客戶選擇使用AI服務的權利」是哪個核心原則的體現？',
      options: {
        A: '建立治理及問責機制',
        B: '保護隱私及客戶權益',
        C: '確保系統穩健性與安全性',
        D: '促進永續發展'
      },
      correctAnswer: 'B',
      explanation: '這是核心原則三的內容，直接對應金融消費者保護的監理理念，強調對客戶資料和選擇權的尊重。'
    },
    {
      question: '六大核心原則的提出，其背後的監理理念不包含下列何者？',
      options: {
        A: '負責任創新',
        B: '公平待客及普惠金融',
        C: '追求利潤最大化',
        D: '永續金融及關懷員工'
      },
      correctAnswer: 'C',
      explanation: '六大核心原則對應的監理理念包括負責任創新、公平待客、消費者保護、資通安全、資訊揭露、永續金融等，旨在追求平衡發展，而非單純的利潤最大化。'
    },
    {
      question: '記憶輔助中的六大原則關鍵字，「治理、公平、隱私、安全、透明、永續」，下列何者對應正確？',
      options: {
        A: '公平 -> 原則五',
        B: '透明 -> 原則三',
        C: '安全 -> 原則四',
        D: '治理 -> 原則二'
      },
      correctAnswer: 'C',
      explanation: '對應關係為：治理(一)、公平(二)、隱私(三)、安全(四)、透明(五)、永續(六)。因此，安全對應原則四是正確的。'
    },
    {
      question: '為何需要建立六大核心原則？',
      options: {
        A: '為了增加金融業的營運成本。',
        B: '為了提供一個共同的綱領，引導金融業在風險可控下進行AI創新。',
        C: '為了讓所有金融機構的AI系統都一模一樣。',
        D: '為了完全禁止金融業使用AI。'
      },
      correctAnswer: 'B',
      explanation: '這六大原則是一個指導性的框架，旨在為金融業的AI發展提供一個共同的倫理和治理方向，鼓勵負責任的創新。'
    }
  ],
  L32201: [
    {
      question: '根據指引中「建立治理及問責機制」的原則，金融機構應由誰來負責整體監督管理AI系統的運用？',
      options: {
        A: '單一的IT部門工程師。',
        B: '外部的AI顧問公司。',
        C: '基層的業務單位主管。',
        D: '足以督導跨部門業務的高階主管或指定之委員會。'
      },
      correctAnswer: 'D',
      explanation: '指引強調，AI的治理應是「由上而下」的。應由能夠跨部門協調、具備決策權力的高階主管或委員會來負責，才能有效地制定AI政策並監督其執行。'
    },
    {
      question: '在治理架構中，金融機構的「外部責任」主要指的是什麼？',
      options: {
        A: '對股東的獲利承諾。',
        B: '建立有效的對外溝通管道，讓消費者或主管機關可查詢或審視AI決策。',
        C: '與其他金融機構進行技術交流。',
        D: '確保辦公室的環境安全。'
      },
      correctAnswer: 'B',
      explanation: '外部責任強調的是對客戶和社會的問責。建立透明的溝通管道，是讓外部利害關係人能夠監督並信任金融機構AI應用的基礎。'
    },
    {
      question: '「治理三要素」記憶輔助中，「高層要管」對應的是指引中的哪項要求？',
      options: {
        A: '建立有效的對外溝通管道。',
        B: '應由可督導跨部門職務的高階主管或指定委員會進行監督管理。',
        C: '界定各部門或業務線的功能與責任。',
        D: '確保AI系統的實際運用符合其規劃目的。'
      },
      correctAnswer: 'B',
      explanation: '「高層要管」直接對應了指引中要求由高階主管或委員會來進行頂層設計和監督管理的核心精神。'
    },
    {
      question: '為何需要明確界定組織內各單位的權責，並落實分層管理機制？',
      options: {
        A: '為了增加組織的層級，讓升遷變慢。',
        B: '為了在AI專案出問題時，能夠清晰地追溯責任，並確保各環節都有人負責。',
        C: '為了讓每個部門都可以獨立開發自己的AI系統。',
        D: '為了符合傳統的公司文化。'
      },
      correctAnswer: 'B',
      explanation: '清晰的權責劃分是問責制的基礎。在複雜的AI專案中，只有明確了各部門的角色和責任，才能在出現風險或問題時，快速定位並有效處理。'
    },
    {
      question: '下列何者是建立AI治理架構的主要目的？',
      options: {
        A: '減緩AI專案的開發速度。',
        B: '建立一個權責分明、可監督、可問責的管理體系。',
        C: '將所有AI相關的決策權都集中在IT部門。',
        D: '避免與外部客戶進行任何溝通。'
      },
      correctAnswer: 'B',
      explanation: 'AI治理架構的核心目標，就是將AI的發展納入一個有序、可控的框架内，確保其符合法規、倫理和企業戰略，並在出現問題時有人負責。'
    },
    {
      question: '金融機構設立一個由副總經理級以上主管領導的「AI治理委員會」，此舉落實了指引中的哪項建議？',
      options: {
        A: '確保目的合規',
        B: '指定高階主管或委員會進行監督',
        C: '建立對外溝通管道',
        D: '落實分層管理'
      },
      correctAnswer: 'B',
      explanation: '設立一個由高階主管領導的、跨部門的委員會，是實踐「由上而下」治理模式、有效監督管理AI運用的最佳實踐。'
    },
    {
      question: 'AI治理的「內部責任」不包含下列何者？',
      options: {
        A: '明確界定組織內各單位的權責。',
        B: '由高階主管進行監督管理。',
        C: '建立對外讓消費者查詢AI決策的管道。',
        D: '落實分層管理機制。'
      },
      correctAnswer: 'C',
      explanation: '建立對外查詢管道屬於對消費者和社會的「外部責任」範疇。內部責任主要關注組織內部的權責劃分和管理流程。'
    },
    {
      question: '確保AI系統的實際運用符合其規劃目的，這項要求的主要用意為何？',
      options: {
        A: '避免技術被濫用或產生非預期的負面影響。',
        B: '確保專案預算不會超支。',
        C: '確保開發人員不會修改程式碼。',
        D: '確保所有員工都了解AI的規劃。'
      },
      correctAnswer: 'A',
      explanation: '這項要求是為了防止「目的偏離」，確保一個為特定良善目的開發的AI系統，不會在實際應用中被用於其他可能有害或不合規的用途。'
    },
    {
      question: '一個權責分明的治理架構，對於AI專案的哪個階段最為重要？',
      options: {
        A: '僅在專案規劃階段重要。',
        B: '僅在專案部署後重要。',
        C: '在AI的整個生命週期中都非常重要。',
        D: '在專案遇到困難時才重要。'
      },
      correctAnswer: 'C',
      explanation: '治理是一個貫穿始終的概念。從初期的風險評估、開發中的監督，到部署後的問責，清晰的治理架構在AI的每一個環節都扮演著關鍵角色。'
    },
    {
      question: '「建立治理及問責機制」是六大核心原則中的第幾項？',
      options: {
        A: '原則一',
        B: '原則二',
        C: '原則三',
        D: '原則四'
      },
      correctAnswer: 'A',
      explanation: '這是六大核心原則之首，因為有效的治理是落實其他所有原則（如公平、透明、安全）的基礎和前提。'
    }
  ],
  L32202: [
    {
      question: '關於AI模型的風險管理，下列哪個做法是「不洽當」的？',
      options: {
        A: '在模型部署前進行充分的測試。',
        B: '建立一份AI模型清單，記錄其版本、用途等資訊。',
        C: '模型上線後就無需再理會，因為AI會自己學習。',
        D: '持續監控已部署模型的表現，並在性能下降時進行驗證。'
      },
      correctAnswer: 'C',
      explanation: 'AI模型上線後，由於數據漂移等因素，性能可能會隨時間衰退。因此，持續的監控與驗證是AI風險管理中至關重要的一環，絕非一勞永逸。'
    },
    {
      question: '金融機構應如何處理AI風險管理與現有的整體風險管理框架的關係？',
      options: {
        A: 'AI風險管理應完全獨立運作，與現有框架無關。',
        B: '應將AI風險管理整合至現有的整體風險管理及內部控制架構中。',
        C: 'AI風險管理應完全取代現有的風險管理框架。',
        D: '只需關注AI模型風險，無需考慮其他風險。'
      },
      correctAnswer: 'B',
      explanation: '指引建議，AI風險應被視為企業整體風險的一部分，將其納入現有的風管和內控體系，才能進行全面、一致的管理，而非單獨切割處理。'
    },
    {
      question: '建立並維護一份「AI模型清單」的主要目的是什麼？',
      options: {
        A: '為了向競爭對手展示公司的模型數量。',
        B: '為了有效地盤點、追蹤和管理組織內所有AI模型的版本、用途和風險。',
        C: '這只是一個形式上的文書作業，沒有實際用途。',
        D: '為了計算開發人員的績效。'
      },
      correctAnswer: 'B',
      explanation: '模型清單是AI治理的基礎工具。它提供了一個中央視圖，幫助組織了解自身擁有哪些AI資產，便於進行風險評估、合規檢查和生命週期管理。'
    },
    {
      question: '對負責AI系統的相關人員提供培訓與資源，其主要目的是什麼？',
      options: {
        A: '增加公司的培訓開支。',
        B: '提升組織整體的AI素養，使其具備足夠的知識與能力來應對AI帶來的挑戰。',
        C: '讓所有員工都轉型為AI工程師。',
        D: '滿足政府的最低培訓時數要求。'
      },
      correctAnswer: 'B',
      explanation: 'AI的成功導入不僅是技術問題，更是人的問題。透過持續的教育訓練，可以確保從高層到基層的相關人員都能理解AI、善用AI並有效管理AI的風險。'
    },
    {
      question: '「風險管理ABC」記憶輔助中，「A (Align)」指的是什麼？',
      options: {
        A: '分析(Analyze)所有可能的風險。',
        B: '將AI風險與現有風管框架對齊(Align)。',
        C: '批准(Approve)所有AI專案。',
        D: '攻擊(Attack)模型的漏洞。'
      },
      correctAnswer: 'B',
      explanation: '「Align」強調了將AI風險管理整合至現有企業風險管理框架的重要性，確保管理的一致性。'
    },
    {
      question: '在AI模型部署前的風險管理活動，應包含下列何者？',
      options: {
        A: '僅需確認模型可以執行即可。',
        B: '了解並記錄模型的目的、方法，並進行充分測試。',
        C: '刪除所有訓練數據。',
        D: '對外宣布模型的準確率達到100%。'
      },
      correctAnswer: 'B',
      explanation: '部署前的盡職調查至關重要，包括清晰地記錄模型規格、進行嚴謹的測試以驗證其可靠性，是防止有問題的模型進入生產環境的第一道防線。'
    },
    {
      question: '為何需要識別因導入AI而產生的新工作角色與所需技能？',
      options: {
        A: '為了證明AI會導致大規模失業。',
        B: '為了提前規劃招聘或內部培訓，確保組織具備運營AI系統所需的人才。',
        C: '為了可以向政府申請更多的補助。',
        D: '為了更新公司的組織圖。'
      },
      correctAnswer: 'B',
      explanation: 'AI的導入會改變工作流程，催生新的職能（如AI訓練師、提示工程師）。提前識別這些需求並進行人力規劃，是確保AI系統能長期、有效運作的人才保障。'
    },
    {
      question: '將各界反饋意見納入AI生命週期的各階段評估中，這體現了什麼管理思維？',
      options: {
        A: '閉門造車',
        B: '持續改進與開放溝通',
        C: '一次性交付',
        D: '絕對保密'
      },
      correctAnswer: 'B',
      explanation: '一個健康的AI治理體系應該是開放的，能夠接收來自客戶、員工、監管機構等各方的反饋，並將這些反饋作為持續優化AI系統的重要輸入。'
    },
    {
      question: '對AI相關人員進行培訓的對象應包含誰？',
      options: {
        A: '僅限於開發模型的IT人員。',
        B: '僅限於公司的高階主管。',
        C: '僅限於法遵與風控人員。',
        D: '應包含從高層主管、開發測試人員到法遵風控等所有相關人員。'
      },
      correctAnswer: 'D',
      explanation: 'AI的影響是跨部門的，因此培訓也應該是全面的。不同角色需要不同深度的培訓，但都應對AI的基本概念和相關風險有共同的理解。'
    },
    {
      question: '下列何者是有效的AI風險管理政策應涵蓋的內容？',
      options: {
        A: '僅包含資料蒐集的規定。',
        B: '僅包含資訊安全的規定。',
        C: '應涵蓋風險管理、資料蒐集、安全控管、法遵要求等多個面向。',
        D: '僅包含人員培訓的計畫。'
      },
      correctAnswer: 'C',
      explanation: '一個全面的AI風險管理政策應該是一個綜合性的指導方針，涵蓋AI生命週期中可能遇到的各類風險和對應的管理原則。'
    }
  ],
  L32301: [
    {
      question: '在AI生命週期的哪個階段，應盡量使用多元、具代表性的數據，而非僅依賴單一或特定群體的數據，以避免偏見？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'B',
      explanation: '數據是偏見的主要來源之一。在「資料蒐集及輸入」階段就確保數據的多元性和代表性，是從源頭上緩解演算法偏見的最重要措施之一。'
    },
    {
      question: '關於AI公平性，下列敘述何者正確？',
      options: {
        A: '只要模型的整體準確率很高，就代表它是公平的。',
        B: '應避免因演算法偏見對特定群體產生系統性的不利差別待遇。',
        C: '為了公平，模型對所有人的預測結果都應該一樣。',
        D: '公平性問題只能在模型部署後才能發現與處理。'
      },
      correctAnswer: 'B',
      explanation: 'AI公平性的核心是關注模型決策是否會對基於性別、種族等受保護屬性的群體造成不成比例的負面影響，即便這種影響是無意的。'
    },
    {
      question: '為確保AI模型的公平性，在模型建立及驗證階段可以採取的措施是什麼？',
      options: {
        A: '只使用單一來源的數據。',
        B: '透過測試與驗證模型對不同群體的預測及決策，確認其運作的公平性。',
        C: '盡可能使用最複雜的黑箱模型。',
        D: '刪除所有個人屬性資料。'
      },
      correctAnswer: 'B',
      explanation: '在模型建立和驗證階段，需要主動地、量化地去檢測模型是否存在偏見，例如比較模型在不同性別或族群上的錯誤率，並在發現問題時進行調整。'
    },
    {
      question: '在系統規劃及設計階段，為了落實公平性，應提供受不利影響群體可反饋意見的管道，這被稱為什麼？',
      options: {
        A: '模型清單',
        B: '壓力測試',
        C: '救濟選項',
        D: '對抗性攻擊'
      },

      correctAnswer: 'C',
      explanation: '提供申訴、反饋或人工複核等救濟選項，是保障受AI決策不利影響者權益的重要機制，也是公平性原則的具體體現。'
    },
    {
      question: '「公平性四階段檢核」記憶輔助中，「蒐集：收資料，要多元、要小心」，「小心」指的是什麼？',
      options: {
        A: '小心不要收集太多資料。',
        B: '小心資料儲存的成本。',
        C: '謹慎評估使用個人屬性資料的必要性，避免引入不相關的偏見。',
        D: '小心不要違反公司內部規定。'
      },
      correctAnswer: 'C',
      explanation: '「小心」指的是在使用如性別、居住地等敏感個人屬性作為模型特徵時，必須有充分的合理理由，並評估其是否可能導致歧視性後果。'
    },
    {
      question: '一個AI信貸模型，如果對某個特定居住地的借款人給予系統性偏低的分數，而沒有合理的風險理由，這可能違反了公平性的哪個概念？',
      options: {
        A: '決策的準確性',
        B: '決策的合理性',
        C: '系統的穩健性',
        D: '系統的安全性'
      },
      correctAnswer: 'B',
      explanation: '指引強調，使用個人屬性作為決策因素應有合理理由。如果沒有合理的風險解釋，僅因居住地就給予差別待遇，就可能構成不公平。'
    },
    {
      question: '在AI系統部署及監控階段，如何持續落實公平性？',
      options: {
        A: '部署後就不再需要監控公平性。',
        B: '定期檢視與分析AI系統產出之結果是否存在歧視。',
        C: '只監控模型的準確率。',
        D: '每個月都重新訓練一次模型。'
      },
      correctAnswer: 'B',
      explanation: '公平性不是一次性的工作，因為社會和數據都在變化。部署後需要建立持續的監控機制，定期審核模型的決策是否隨著時間推移而產生了新的偏見。'
    },
    {
      question: '為何需要將模型設計目的、運算邏輯等以簡單易懂的方式留下紀錄？',
      options: {
        A: '為了讓競爭對手可以抄襲。',
        B: '為了增加文書工作的負擔。',
        C: '為了在模型出現偏見或爭議時，能夠追溯、審計和解釋其決策邏輯。',
        D: '為了滿足開發人員的個人喜好。'
      },
      correctAnswer: 'C',
      explanation: '留下清晰的紀錄是實現問責性和可解釋性的基礎。當模型被質疑不公時，這些紀錄是證明其設計初衷和運作原理的關鍵證據。'
    },
    {
      question: '邀請外部專家參與AI系統的設計與執行過程，主要有何好處？',
      options: {
        A: '可以將所有責任都推給外部專家。',
        B: '可以借助外部的、中立的視角來識別內部可能忽略的偏見或歧視風險。',
        C: '可以加快專案的開發速度。',
        D: '可以降低專案的總成本。'
      },
      correctAnswer: 'B',
      explanation: '內部團隊可能存在知識盲點或思維慣性。引入外部專家（如倫理學家、社會學家）可以提供更多元的視角，幫助組織更全面地評估AI的潛在社會影響。'
    },
    {
      question: '下列何者是落實公平性原則的正確態度？',
      options: {
        A: '公平性是純粹的技術問題，與業務無關。',
        B: '只要使用了最新的AI技術，就自然是公平的。',
        C: '公平性是一個貫穿AI整個生命週期的系統性工程，需要持續關注。',
        D: '只有在被客戶投訴時，才需要考慮公平性問題。'
      },
      correctAnswer: 'C',
      explanation: '公平性問題可能出現在數據、演算法、監控等任何一個環節，因此必須在AI的整個生命週期中，系統性地去識別、衡量和緩解偏見。'
    }
  ],
  L32302: [
    {
      question: '一個AI理財顧問系統，僅提供投資建議，但最終的交易決策必須由人類理財專員確認後才能執行。這屬於哪一種人類監督機制？',
      options: {
        A: '人在指揮 (Human-in-command, HIC)',
        B: '人在迴圈內 (Human-in-the-loop, HITL)',
        C: '人在迴圈上 (Human-over-the-loop, HOTL)',
        D: '完全自動化 (Fully-automated)'
      },
      correctAnswer: 'B',
      explanation: '人在迴圈內 (HITL) 的核心特徵是，人類主動參與監督，並保留完全的控制權，AI僅作為提供資訊或建議的輔助角色。'
    },
    {
      question: '「以人為本 (Human-centric)」的AI原則，其核心意涵是什麼？',
      options: {
        A: 'AI系統的設計應以人類工程師的偏好為中心。',
        B: 'AI系統應以支持人類自主權、尊重人類基本權利及允許人類監督為原則。',
        C: 'AI系統應盡可能地模仿人類的所有行為，包括犯錯。',
        D: 'AI系統的目標是完全取代人類。'
      },
      correctAnswer: 'B',
      explanation: '以人為本的原則強調AI應作為增進人類福祉的工具，其發展和應用必須始終以尊重和服務人類為最終目的。'
    },
    {
      question: '一個自動化的工廠監控系統，在平時自主運行，僅在偵測到嚴重異常事件時才觸發警報，由人類工程師介入處理。這屬於哪種監督機制？',
      options: {
        A: '人在指揮 (HIC)',
        B: '人在迴圈內 (HITL)',
        C: '人在迴圈上 (HOTL)',
        D: '無人監督'
      },
      correctAnswer: 'C',
      explanation: '人在迴圈上 (HOTL) 的特點是人類對系統進行高層次的監督，在常規情況下不介入，僅在系統發出異常信號或需要決策仲裁時才介入。'
    },
    {
      question: '金融機構導入生成式AI時，若使用第三方業者的服務，應由誰對其產出資訊的風險進行管控？',
      options: {
        A: '第三方業者應負全部責任。',
        B: '使用者客戶應自行判斷。',
        C: '仍需由金融機構人員就其產出資訊的風險，進行客觀且專業的管控。',
        D: '主管機關會負責管控。'
      },
      correctAnswer: 'C',
      explanation: '即使使用了第三方工具，金融機構仍是對其客戶和業務負有最終責任的主體。因此，必須建立內部流程，對第三方AI的輸出進行審核和風險管控。'
    },
    {
      question: '人類監督三種模式記憶輔助中，「你是我的副駕，你給建議，我來開車」比喻的是哪種模式？',
      options: {
        A: 'HIC',
        B: 'HITL',
        C: 'HOTL',
        D: 'HIL'
      },
      correctAnswer: 'B',
      explanation: '這個比喻非常貼切地描述了「人在迴圈內(HITL)」的模式：AI提供輔助資訊和建議，但最終的控制權和決策權掌握在人類手中。'
    },
    {
      question: '在落實「人類可控」原則時，為何需要保留人員可安全地關閉AI系統的權利？',
      options: {
        A: '為了在系統升級時方便操作。',
        B: '為了在AI系統出現非預期的有害行為或失控時，能有最終的「剎車」機制。',
        C: '為了節省電力。',
        D: '為了讓員工有事可做。'
      },
      correctAnswer: 'B',
      explanation: '保留一個可靠的、人類可操作的關閉開關（Off-switch），是確保AI系統始終處於人類控制之下的最後一道防線，也是最重要的安全保障。'
    },
    {
      question: '根據決策的影響程度，採取不同級別的監督機制，這被稱為什麼？',
      options: {
        A: '一體適用監督',
        B: '分級監督',
        C: '隨機監督',
        D: '無監督'
      },
      correctAnswer: 'B',
      explanation: '這體現了風險為本的原則。對影響重大的決策（如核貸），應採取更強的人工介入（如HITL）；對影響較小的決策，則可採用較寬鬆的監督（如HOTL）。'
    },
    {
      question: '下列何者最能體現「人在指揮 (HIC)」的概念？',
      options: {
        A: 'AI系統自動執行所有交易，人類只在月底查看報表。',
        B: '人類科學家設定一個探索火星的總體目標，由AI自主規劃並執行所有具體任務。',
        C: 'AI推薦一部電影，使用者點擊播放。',
        D: 'AI草擬一封郵件，使用者修改後點擊發送。'
      },
      correctAnswer: 'B',
      explanation: '人在指揮 (HIC) 強調的是人類對AI的總體目標和活動擁有最終的決定權和監督權，即使AI在執行層面有很高的自主性。'
    },
    {
      question: '金融機構運用AI前，應先辨識系統是否遵循法令，並判斷是否可能影響客戶自主權或基本人權。這屬於哪個階段的落實方式？',
      options: {
        A: '事前評估',
        B: '部署監控',
        C: '模型驗證',
        D: '資料蒐集'
      },
      correctAnswer: 'A',
      explanation: '這是預防性的措施，在系統導入之前就進行倫理和人權的影響評估，以從源頭上避免潛在的負面影響。'
    },
    {
      question: '「以人為本與人類可控」是六大核心原則中的第幾項？',
      options: {
        A: '原則一',
        B: '原則二',
        C: '原則三',
        D: '原則四'
      },
      correctAnswer: 'B',
      explanation: '這是核心原則二「重視公平性及以人為本的價值觀」的後半部分，強調了在追求公平的同時，必須確保技術服務於人並受人控制。'
    }
  ],
  L32401: [
    {
      question: '金融機構在蒐集客戶資料以訓練AI模型時，應遵循「資料最小化原則」，其意涵為何？',
      options: {
        A: '蒐集的資料量越少越好，即使影響模型準確性。',
        B: '只蒐集與處理業務目的直接相關且「必要」的客戶資料。',
        C: '將所有資料都壓縮到最小的檔案大小。',
        D: '只蒐集客戶最不敏感的資料。'
      },
      correctAnswer: 'B',
      explanation: '資料最小化原則的核心是在滿足業務需求的同時，盡可能減少對個人隱私的干擾。它要求企業僅蒐集「必要」的資料，避免過度蒐集。'
    },
    {
      question: '在AI生命週期的哪個階段，應建立保護個資免於未授權存取的機制，如加密、存取控管等？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'A',
      explanation: '隱私保護應「由設計而始」(Privacy by Design)。在系統規劃設計之初，就必須將加密、權限控管等安全機制納入架構中，而非事後補救。'
    },
    {
      question: '當金融機構與第三方供應商合作開發AI時，關於隱私保護，金融機構的責任為何？',
      options: {
        A: '所有責任都轉嫁給供應商。',
        B: '應確保合作夥伴及供應商亦符合隱私權規範及安全標準。',
        C: '只需口頭告知供應商要注意隱私。',
        D: '金融機構沒有任何責任。'
      },
      correctAnswer: 'B',
      explanation: '在供應鏈中，資料的保護是共同的責任。金融機構必須對其合作夥伴進行盡職調查，確保其同樣遵守嚴格的隱私和安全標準。'
    },
    {
      question: '當發生資料外洩事件時，應在哪個階段循現行機制進行通報及處理？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'D',
      explanation: '資料外洩是營運階段可能發生的事件，因此應在「系統部署及監控」階段建立應急響應計畫，以便在事件發生時能及時通報和處理。'
    },
    {
      question: '「隱私保護四字訣」記憶輔助中，「少 (Minimize)」對應的是哪個原則？',
      options: {
        A: '告知同意原則',
        B: '資料最小化原則',
        C: '存取控管原則',
        D: '定期監控原則'
      },
      correctAnswer: 'B',
      explanation: '「少」字訣直接對應「資料最小化原則」，提醒在蒐集資料時應克制，只取必要的部分。'
    },
    {
      question: '對包含個人資料的數據進行「假名化」或「匿名化」處理，屬於哪個階段的額外隱私保護措施？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'B',
      explanation: '在將原始資料輸入到系統或資料庫之前，進行去識別化處理，是從源頭上降低隱私風險的有效技術手段。'
    },
    {
      question: '下列何者不是落實隱私保護與資料治理的主要目的？',
      options: {
        A: '贏得客戶的信任。',
        B: '符合個資法等法律規範。',
        C: '讓AI模型可以不受限制地使用所有客戶資料。',
        D: '降低資料外洩的風險。'
      },
      correctAnswer: 'C',
      explanation: '隱私保護與資料治理的核心目的恰恰相反，是為AI使用資料設立明確的「邊界」和「規則」，確保其在合法合規的範圍內運作，而非不受限制。'
    },
    {
      question: '除了保護客戶的個人資料，指引還提醒應注意保護哪一類智慧財產權？',
      options: {
        A: '客戶的社群媒體帳號',
        B: '競爭對手的專利',
        C: '營業秘密',
        D: '公開的政府資料'
      },
      correctAnswer: 'C',
      explanation: '指引中明確提到，在運用AI時，除了個資，也應注意保護如交易策略、模型演算法等屬於公司核心資產的營業秘密。'
    },
    {
      question: '在系統規劃及設計階段，如果發現使用公開資料已可滿足模型需求，根據資料最小化原則，應如何做？',
      options: {
        A: '仍然繼續蒐集更多的非公開個人資料。',
        B: '則不需蒐集非公開資料。',
        C: '混合使用公開與非公開資料。',
        D: '放棄使用公開資料。'
      },
      correctAnswer: 'B',
      explanation: '這正是資料最小化原則的體現：如果能用侵犯性較小的方式達成目的，就應避免採用侵犯性較大的方式。'
    },
    {
      question: '為何需要記錄資料的蒐集來源？',
      options: {
        A: '這只是為了方便統計。',
        B: '為了確保資料的合法性與可靠性，並在需要時可供追溯與審計。',
        C: '為了可以向資料來源收費。',
        D: '為了增加資料庫的欄位數量。'
      },
      correctAnswer: 'B',
      explanation: '記錄資料來源是資料治理的基礎。它不僅是確保資料合法性的證據，也是在資料出現品質問題時，能夠追溯源頭進行排查的關鍵。'
    }
  ],
  L32402: [
    {
      question: '根據指引，當金融機構使用AI系統向客戶提供服務時，下列哪項「不是」必須告知客戶的事項？',
      options: {
        A: '該服務係由AI系統所提供。',
        B: 'AI系統的詳細演算法原始碼。',
        C: 'AI系統的功能以及可能對客戶造成的影響。',
        D: '是否存在AI以外的替代方案。'
      },
      correctAnswer: 'B',
      explanation: '指引強調應讓客戶擁有知情權與選擇權，但這不代表需要揭露涉及營業秘密的演算法原始碼。重點是讓客戶理解AI的功能、影響以及是否有其他選擇。'
    },
    {
      question: '金融機構在決定是否為AI服務提供人工等替代方案時，應考量的因素「不」包含下列何者？',
      options: {
        A: '對客戶的風險及危害程度。',
        B: '替代方案的可行性及成本。',
        C: 'AI系統開發人員的個人偏好。',
        D: '技術可行性。'
      },
      correctAnswer: 'C',
      explanation: '是否提供替代方案，應基於對客戶影響、成本效益、技術可行性等客觀因素的綜合權衡，而非開發人員的個人偏好。'
    },
    {
      question: '當金融機構人員使用第三方開發的生成式AI時，關於客戶資料的處理，下列何者正確？',
      options: {
        A: '可以自由地將任何客戶資料輸入給生成式AI。',
        B: '在無適當管控機制下，不得向生成式AI提供未經客戶同意的資訊。',
        C: '只需口頭告知客戶即可使用。',
        D: '所有責任均由第三方業者承擔。'
      },
      correctAnswer: 'B',
      explanation: '這是對生成式AI帶來新興隱私風險的特別提醒。由於公開的生成式AI可能將輸入用於再訓練，因此嚴禁在無管控下輸入客戶資料，是保護客戶隱私的關鍵紅線。'
    },
    {
      question: '「客戶選擇權三部曲」記憶輔助中，「告知、解釋、給選擇」，「解釋」指的是什麼？',
      options: {
        A: '解釋AI的程式碼。',
        B: '解釋公司的財務狀況。',
        C: '說明AI系統的功能為何，以及由AI協助做出的決策可能會如何影響他們。',
        D: '解釋為何不提供人工服務。'
      },
      correctAnswer: 'C',
      explanation: '「解釋」是為了保障客戶的知情權，讓他們在做出選擇前，能充分理解AI服務的性質和可能帶來的影響。'
    },
    {
      question: '一家銀行導入智能客服機器人，但在對話中提供清晰的「轉接專員」選項。這個做法落實了指引中的哪項要求？',
      options: {
        A: '告知義務',
        B: '資訊透明',
        C: '提供替代方案',
        D: '以上皆是'
      },
      correctAnswer: 'D',
      explanation: '這個做法首先告知了有AI的存在（隱含），解釋了AI的功能（處理問題），並明確提供了人工客服這個「替代方案」，完整地體現了尊重客戶選擇權的原則。'
    },
    {
      question: '若金融機構權衡後決定不為某項AI服務提供替代方案，指引建議宜進一步評估什麼？',
      options: {
        A: '是否應停止該AI服務。',
        B: '是否為客戶提供補救措施。',
        C: '是否應該對客戶收取更高的費用。',
        D: '是否應該更換AI供應商。'
      },
      correctAnswer: 'B',
      explanation: '在無法提供替代方案的情況下，提供補救措施（如人工申訴管道、案件複審機制）是保障客戶權益的次要但重要的作法。'
    },
    {
      question: '尊重客戶選擇權的最終目的是什麼？',
      options: {
        A: '增加金融機構的營運成本。',
        B: '減緩AI技術的導入速度。',
        C: '維護客戶的權益，並建立基於信任的客戶關係。',
        D: '讓所有客戶都選擇使用人工服務。'
      },
      correctAnswer: 'C',
      explanation: '這項原則是公平待客精神的延伸，旨在確保客戶在享受科技便利的同時，其自主權和選擇權得到充分尊重，從而建立更穩固的信任關係。'
    },
    {
      question: '下列何者是金融機構「告知義務」的正確實踐？',
      options: {
        A: '在服務條款中用非常小的字體說明。',
        B: '讓AI模仿人類的語氣，讓客戶無法分辨。',
        C: '在與AI互動的介面中，以清晰、顯著的方式告知客戶其互動對象是AI。',
        D: '只有在客戶主動詢問時才承認是AI。'
      },
      correctAnswer: 'C',
      explanation: '告知義務應以主動、清晰、易於理解為原則，確保客戶在互動之初就對服務性質有明確的認知。'
    },
    {
      question: '對生成式AI的客戶資料外洩風險，指引建議的管控機制不包含下列何者？',
      options: {
        A: '採用封閉型部署之模型。',
        B: '確認系統環境的安全性。',
        C: '將所有客戶資料都備份到公開的雲端硬碟。',
        D: '禁止員工向無管控的生成式AI提供客戶資訊。'
      },
      correctAnswer: 'C',
      explanation: '將客戶資料備份到公開的雲端硬碟是極其危險、違反安全原則的行為，與指引建議的管控方向完全相反。'
    },
    {
      question: '尊重客戶選擇權是六大核心原則中的第幾項？',
      options: {
        A: '原則一',
        B: '原則二',
        C: '原則三',
        D: '原則四'
      },
      correctAnswer: 'C',
      explanation: '這是核心原則三「保護隱私及客戶權益」的後半部分，強調了在保護客戶資料的同時，也應尊重其使用服務的自主選擇權。'
    }
  ],
  L32501: [
    {
      question: '在AI系統穩健性的要求中，「可重製性 (Reproducibility)」指的是什麼？',
      options: {
        A: '模型可以被輕易地複製到不同的電腦上。',
        B: '模型的預測結果必須100%準確。',
        C: '在相同的條件下重複測試，模型應得到相近的產出。',
        D: '模型的程式碼可以被輕易地重寫。'
      },
      correctAnswer: 'C',
      explanation: '可重製性是科學驗證的基本要求，確保模型的行為是穩定且可預測的，而非隨機或偶然的結果，這對於建立對模型的信任至關重要。'
    },
    {
      question: '下列何者是評估模型在面對非預期輸入時韌性的有效方法？',
      options: {
        A: '交互驗證 (Cross-validation)',
        B: '壓力測試 (Stress Testing)',
        C: '對抗性測試 (Adversarial Testing)',
        D: '單位測試 (Unit Testing)'
      },
      correctAnswer: 'C',
      explanation: '對抗性測試專門用於評估模型在面對經過精心設計的、旨在欺騙模型的惡意輸入時的表現，是檢驗模型穩健性的重要手段。'
    },
    {
      question: '「穩健性三支柱」記憶輔助中，「穩、準、同」分別對應了穩健性的哪三個主要概念？',
      options: {
        A: '穩定性、準確率、複雜性',
        B: '穩定性、準確性、可重製性',
        C: '安全性、準確性、可重製性',
        D: '穩定性、速度、同理性'
      },
      correctAnswer: 'B',
      explanation: '記憶輔助中的「穩」對應穩定性，「準」對應準確性，「同」對應可重製性，是構成系統穩健性的三個核心要素。'
    },
    {
      question: '在AI生命週期的哪個階段，應明確定義用以衡量系統穩健性的指標及其應達到的標準？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'A',
      explanation: '在專案之初就定義好成功的標準，是所有工程專案的最佳實踐。在規劃設計階段就明確穩健性的衡量指標，可以為後續的開發和驗證提供清晰的目標。'
    },
    {
      question: '高品質的資料治理對於確保模型的穩定、準確、可重製至關重要。這項工作主要在哪個階段落實？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'B',
      explanation: '「Garbage in, garbage out」。資料是模型的基礎，因此在資料蒐集及輸入階段就確保其品質，是後續所有穩健性要求的根本保障。'
    },
    {
      question: '一個AI系統即使在接收到無效或格式錯誤的輸入時，仍能正常運作而不會崩潰。這體現了穩健性中的哪個概念？',
      options: {
        A: '穩定性 (Stability)',
        B: '準確性 (Accuracy)',
        C: '可重製性 (Reproducibility)',
        D: '複雜性 (Complexity)'
      },
      correctAnswer: 'A',
      explanation: '穩定性指的是系統處理異常和壓力情況的能力，一個穩定的系統應該對錯誤輸入有良好的容錯機制。'
    },
    {
      question: '在系統部署及監控階段，建立監控機制，定期檢測AI模型是否有效度偏移，主要是為了應對什麼問題？',
      options: {
        A: '伺服器硬體故障',
        B: '軟體授權到期',
        C: '因真實世界數據變化（數據漂移）導致模型準確性下降',
        D: '網路連線中斷'
      },
      correctAnswer: 'C',
      explanation: '模型部署後，真實世界的數據分佈可能隨時間改變，導致模型的預測不再準確。持續監控是及時發現這種「模型衰退」現象並採取行動的關鍵。'
    },
    {
      question: '一家證券公司利用歷史股災數據來測試其AI交易系統的表現，這種作法稱為什麼？',
      options: {
        A: '功能測試',
        B: '壓力測試',
        C: '使用者體驗測試',
        D: '安全測試'
      },
      correctAnswer: 'B',
      explanation: '壓力測試旨在評估系統在極端、異常或高負載條件下的表現，以確保其在危機情況下依然穩健可靠。'
    },
    {
      question: '透過交互驗證(cross-validation)與調校等技術，主要是為了增進模型的什麼特性？',
      options: {
        A: '開發速度',
        B: '穩健性及可靠性',
        C: '程式碼可讀性',
        D: '使用者介面美觀度'
      },
      correctAnswer: 'B',
      explanation: '交互驗證可以提供比單次劃分驗證集更穩定、更可靠的模型性能評估，有助於選擇出泛化能力更好、更穩健的模型。'
    },
    {
      question: '系統的穩健性(robustness)是指什麼？',
      options: {
        A: '系統可以抵抗所有的網路攻擊。',
        B: '系統具有預防風險發生的方法，能可靠地按照預設目的執行。',
        C: '系統的程式碼寫得非常優雅。',
        D: '系統的開發成本非常低。'
      },
      correctAnswer: 'B',
      explanation: '根據指引定義，穩健性是一個綜合性的概念，指的是系統能夠可靠、穩定、準確地運行，並能應對非預期情況的能力。'
    }
  ],
  L32502: [
    {
      question: '防止惡意使用者透過大量查詢來逆向工程或竊取核心模型，這屬於系統安全性的哪個環節？',
      options: {
        A: '提升員工資安意識',
        B: '保護基礎設施與API',
        C: '評估廠商安全性',
        D: '留下紀錄'
      },
      correctAnswer: 'B',
      explanation: '對API進行嚴格的存取控管、速率限制和異常行為監控，是保護已部署模型不被惡意濫用或竊取的關鍵技術措施。'
    },
    {
      question: '在AI生命週期的哪個階段，應評估或定期檢視AI相關廠商的安全性，並要求其遵守資安標準？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'C',
      explanation: '在模型建立和驗證過程中，可能會使用第三方的工具、平台或資料。因此，在這個階段對供應鏈的安全性進行審查，是確保整體安全的重要一環。'
    },
    {
      question: '「AI安全防護罩」記憶輔助中，「家當要數好」對應的是哪項安全措施？',
      options: {
        A: '提升員工資安意識',
        B: '保護基礎設施',
        C: '辨識、追蹤及保護AI相關資產',
        D: '持續監控'
      },
      correctAnswer: 'C',
      explanation: '「家當」比喻的是AI相關的核心資產（模型、資料、提示等）。「數好」則對應辨識和追蹤這些資產，這是進行有效保護的前提。'
    },
    {
      question: '下列何者是確保AI系統安全性的正確作法？',
      options: {
        A: '為了方便，所有員工都使用相同的管理員帳號。',
        B: '將客戶的原始資料以明文形式儲存在公用伺服器上。',
        C: '在模型部署前進行適當且有效的安全評估。',
        D: '相信AI系統是絕對安全的，無需任何額外防護。'
      },
      correctAnswer: 'C',
      explanation: '部署前的安全評估，如同產品上市前的安全檢查，是發現並修補潛在漏洞、確保系統上線後安全性的關鍵步驟。'
    },
    {
      question: '為何需要針對模型、資料及提示留下相關書面或數位紀錄？',
      options: {
        A: '這只是為了應付稽核，沒有實際作用。',
        B: '為了在發生安全事件或模型行為異常時，能夠追溯、分析和釐清責任。',
        C: '為了可以向客戶展示開發過程。',
        D: '為了增加儲存空間的負擔。'
      },
      correctAnswer: 'B',
      explanation: '留下詳細的紀錄（Versioning and Logging）是實現可追溯性和問責性的基礎，是安全事件應急響應和模型治理的重要環節。'
    },
    {
      question: '在系統規劃及設計階段，提升員工的資安意識，主要是為了達到什麼目的？',
      options: {
        A: '讓員工可以自己修復伺服器。',
        B: '讓員工了解最新的攻擊手法，並在規劃時就將潛在風險納入考量。',
        C: '讓員工可以參加外部的資安競賽。',
        D: '讓員工可以取代資安部門。'
      },
      correctAnswer: 'B',
      explanation: '安全是所有人的責任。在設計之初就讓團隊具備安全意識，可以從源頭上避免許多設計缺陷，建立更安全的系統。'
    },
    {
      question: '保護AI系統的「基礎設施」指的是什麼？',
      options: {
        A: '保護公司的辦公大樓。',
        B: '保護運行AI模型的伺服器、網路以及API等服務。',
        C: '保護員工的個人電腦。',
        D: '保護公司的股價。'
      },
      correctAnswer: 'B',
      explanation: 'AI基礎設施是承載AI模型和數據的軟硬體環境，是整個系統運行的根基，因此是資安防護的重點對象。'
    },
    {
      question: '下列何者是系統安全性(Security)與系統穩健性(Robustness)的主要區別？',
      options: {
        A: '兩者完全相同。',
        B: '安全性主要抵禦「惡意」攻擊，穩健性主要應對「非惡意」的異常或壓力情況。',
        C: '穩健性由IT部門負責，安全性由業務部門負責。',
        D: '安全性只在部署後重要，穩健性只在開發中重要。'
      },
      correctAnswer: 'B',
      explanation: '可以簡單理解為：安全性防「壞人」（如駭客攻擊），穩健性防「意外」（如錯誤輸入、極端市場波動）。兩者都是確保系統可靠運行的重要方面。'
    },
    {
      question: '持續監控模型及系統的輸出與效能，除了可以發現模型準確率下降外，還可以觀察到什麼？',
      options: {
        A: '公司的營收變化。',
        B: '可能影響安全性的變化，如異常的請求模式。',
        C: '員工的滿意度。',
        D: '天氣的變化。'
      },
      correctAnswer: 'B',
      explanation: '持續監控不僅是為了維護模型性能，也是一個重要的安全措施。許多攻擊行為（如模型竊取、對抗性攻擊）都會在系統的輸出或請求模式上留下異常的痕跡。'
    },
    {
      question: '金融機構應遵循相關資安規範，建立適當的防護與管控措施，這句話體現了什麼原則？',
      options: {
        A: '成本效益原則',
        B: '合法合規原則',
        C: '使用者體驗原則',
        D: '先發制人原則'
      },
      correctAnswer: 'B',
      explanation: '金融業是高度監管的行業，所有資安措施都必須首先滿足主管機關頒布的相關法律和規範，這是合規經營的底線。'
    }
  ],
  L32601: [
    {
      question: '當客戶使用銀行的智能客服機器人時，落實「透明性」原則的最佳作法是什麼？',
      options: {
        A: '讓機器人的回答聽起來盡可能像真人，讓客戶無法分辨。',
        B: '在對話開始時，主動告知客戶正在與AI互動。',
        C: '只在客戶提出質疑時，才承認是AI。',
        D: '在網站的隱私權政策最末頁用小字說明。'
      },
      correctAnswer: 'B',
      explanation: '透明性的核心是主動、清晰地揭露資訊。在互動開始時就告知客戶其互動對象是AI，是尊重客戶知情權最直接、最有效的作法。'
    },
    {
      question: '透明性原則的主要服務對象是誰？',
      options: {
        A: '公司內部的開發人員。',
        B: '外部利害關係人，如客戶、主管機關。',
        C: '競爭對手。',
        D: 'AI模型本身。'
      },
      correctAnswer: 'B',
      explanation: '透明性旨在向「外部」提供資訊，以建立信任和保障外部利害關係人的知情權。相對地，可解釋性的主要對象是「內部」人員和主管機關。'
    },
    {
      question: '在AI生命週期的哪個階段，應規劃如何以淺白之用語，向金融消費者適當揭露AI相關資訊？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'A',
      explanation: '對客溝通的策略和內容，應在系統設計之初就進行規劃，以確保透明性的要求能被完整地納入系統功能和使用者介面中。'
    },
    {
      question: '「透明三要素」記憶輔助中，「留條款」指的是什麼？',
      options: {
        A: '留下可以隨時終止服務的條款。',
        B: '在客戶或網站的約定服務條款中，適當揭露並更新AI相關資訊。',
        C: '為AI的錯誤決策留下補償條款。',
        D: '只與客戶簽訂短期合約。'
      },
      correctAnswer: 'B',
      explanation: '「留條款」對應的是在服務條款中，以書面形式詳細說明AI如何使用客戶資料、可能存在的風險等，作為正式的、具法律效力的告知。'
    },
    {
      question: '落實透明性原則，對於金融機構最主要的好處是什麼？',
      options: {
        A: '可以增加AI模型的準確率。',
        B: '可以降低開發成本。',
        C: '可以提升民眾的信任度，減少對新技術的疑慮。',
        D: '可以完全避免所有風險。'
      },
      correctAnswer: 'C',
      explanation: '公開、誠實的溝通是建立信任的唯一途徑。透過落實透明性，金融機構可以主動管理客戶的期望，化解其對AI「黑盒子」的恐懼，從而提高AI服務的接受度與信任感。'
    },
    {
      question: '一家銀行推出AI理財顧問服務，在其使用者條款中說明AI會如何使用客戶的財務數據，並揭露演算法可能存在的限制。這個做法體現了哪個階段的透明性落實？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'C',
      explanation: '規劃如何修改服務條款，並測試相應的透明性功能（如在UI中顯示提示），是在模型建立和驗證階段需要完成的工作，以確保部署時所有配套措施都已到位。'
    },
    {
      question: '下列何者不是金融機構應向客戶揭露的AI資訊？',
      options: {
        A: '該服務由AI提供。',
        B: 'AI決策可能如何影響他們。',
        C: 'AI模型的完整原始碼和權重參數。',
        D: 'AI系統可能存在的限制與風險。'
      },
      correctAnswer: 'C',
      explanation: '透明性要求揭露對客戶有影響的資訊，但不必揭露涉及營業秘密的核心技術細節，如原始碼和模型權重。'
    },
    {
      question: '金融機構宜就評估AI系統所需之適當透明性訂定「共通性原則」，其目的是什麼？',
      options: {
        A: '讓所有AI系統的透明度都達到完全相同的水平。',
        B: '建立一個內部一致的標準，指導不同部門在開發AI應用時如何落實透明性。',
        C: '取代主管機關的所有法規。',
        D: '為了讓開發過程更複雜。'
      },
      correctAnswer: 'B',
      explanation: '訂定共通性原則，可以確保整個組織對於透明性的要求有一致的理解和實踐標準，避免不同專案各自為政，造成管理上的混亂。'
    },
    {
      question: '在與客戶互動前「主動」告知是AI，這項要求主要在哪個階段被執行？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'D',
      explanation: '「主動告知」是在AI系統正式上線、與客戶產生實際互動時發生的行為，因此屬於系統部署及監控階段的執行事項。'
    },
    {
      question: '透明性與可解釋性的主要區別是什麼？',
      options: {
        A: '兩者沒有區別。',
        B: '透明性對外（客戶），可解釋性對內（管理者、稽核）。',
        C: '透明性是技術問題，可解釋性是法律問題。',
        D: '透明性是可選的，可解釋性是必須的。'
      },
      correctAnswer: 'A',
      explanation: '可以這樣理解：透明性是打開汽車的引擎蓋，讓你看見引擎的構造（如何運作）；可解釋性是提供一個儀表板，告訴你引擎現在為何會發出這個聲音（為何決策）。'
    }
  ],
  L32602: [
    {
      question: '「可解釋性 (explainability)」原則的主要服務對象是誰？',
      options: {
        A: '一般社會大眾與媒體。',
        B: '競爭同業。',
        C: '組織內部人員（如風控、稽核）及主管機關。',
        D: '駭客。'
      },
      correctAnswer: 'C',
      explanation: '可解釋性主要是為了滿足內部治理與外部監管的需求，確保AI的決策過程是可被理解、可被審計的，以便進行有效的風險管理。'
    },
    {
      question: '一個具備可解釋性的AI信貸審核系統，在拒絕一筆貸款申請時，應能做到什麼？',
      options: {
        A: '只輸出「拒絕」兩個字。',
        B: '提供一份包含數千頁程式碼的報告。',
        C: '向內部審核人員指出導致拒絕的主要原因，如「負債比過高」。',
        D: '自動向客戶道歉。'
      },
      correctAnswer: 'C',
      explanation: '可解釋性的價值在於提供「原因」。它能將複雜模型的黑箱決策，轉化為人類可理解的、有意義的解釋，從而實現有效的監督和問責。'
    },
    {
      question: '在AI生命週期的哪個階段，應確保以書面化或數位方式記錄用以訓練AI系統的資料來源、時間點等相關資訊？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'B',
      explanation: '記錄訓練資料的「履歷」是實現可追溯性和可解釋性的基礎。當需要審計或排查模型問題時，必須能夠回溯到模型是用了哪些資料訓練出來的。'
    },
    {
      question: '為何說可解釋性是AI系統得以被有效管理和監督的前提？',
      options: {
        A: '因為可解釋的模型運行速度更快。',
        B: '因為如果決策過程是一個無法檢視的「黑盒子」，管理者就無法判斷其決策是否合理、合規。',
        C: '因為可解釋的模型更容易被客戶接受。',
        D: '因為可解釋的模型開發成本更低。'
      },
      correctAnswer: 'B',
      explanation: '有效的管理和監督，建立在「理解」的基礎之上。如果連內部人員都無法理解AI為何如此決策，那麼任何風險管理和治理都將是空談。'
    },
    {
      question: '「解釋三問」記憶輔助中，「對誰解釋？」的答案是什麼？',
      options: {
        A: '對所有客戶解釋',
        B: '對媒體記者解釋',
        C: '對內部人員、主管機關解釋',
        D: '對AI自己解釋'
      },
      correctAnswer: 'C',
      explanation: '記憶輔助對應了指引的內容，即可解釋性的主要溝通對象是負責監督和管理模型的內部人員（業務、風控、稽核）以及外部的監理機關。'
    },
    {
      question: '金融機構應確保其人員知悉AI系統之架構、演算法及其決策因素。這項要求主要在哪個階段進行驗證？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'C',
      explanation: '在模型建立和驗證階段，除了驗證模型本身的性能，也應同步驗證相關人員是否已具備足夠的知識來理解和管理這個模型，確保人機協作的有效性。'
    },
    {
      question: '金融機構應規劃提供監理機關存取及了解AI系統運作之權限。這體現了哪項原則？',
      options: {
        A: '公平性',
        B: '穩健性',
        C: '可解釋性與透明性',
        D: '永續發展'
      },
      correctAnswer: 'C',
      explanation: '向監理機關開放存取權限，是最高程度的透明性與可解釋性實踐，旨在讓主管機關能夠有效地履行其監管職責。'
    },
    {
      question: '「確認可解釋性之程度與其AI系統應用之重要性相稱」這句話的意涵為何？',
      options: {
        A: '所有AI系統都必須達到最高等級的可解釋性。',
        B: '這體現了風險為本的原則，對風險越高的系統，可解釋性的要求也越高。',
        C: '不重要的系統就不需要任何解釋。',
        D: '可解釋性的程度由開發人員自行決定。'
      },
      correctAnswer: 'B',
      explanation: '這是一個務實的管理原則。對於直接影響客戶權益的高風險應用（如信貸審批），需要非常高的可解釋性；而對於內部低風險應用，可解釋性的要求則可適度放寬。'
    },
    {
      question: '提出一份「可解釋性報告」是在哪個階段的落實方式？',
      options: {
        A: '系統規劃及設計階段',
        B: '資料蒐集及輸入階段',
        C: '模型建立及驗證階段',
        D: '系統部署及監控階段'
      },
      correctAnswer: 'C',
      explanation: '在模型開發完成、進入驗證環節時，應產出一份正式的可解釋性報告，作為該模型文件的一部分，供後續的審查和稽核使用。'
    },
    {
      question: '下列何者是可解釋性與透明性的主要區別？',
      options: {
        A: '兩者沒有區別。',
        B: '可解釋性更關注「為何」做出某個決策，透明性更關注「如何」運作。',
        C: '可解釋性是法律要求，透明性是道德要求。',
        D: '可解釋性針對客戶，透明性針對內部員工。'
      },
      correctAnswer: 'A',
      explanation: '可以這樣理解：透明性是打開汽車的引擎蓋，讓你看見引擎的構造（如何運作）；可解釋性是提供一個儀表板，告訴你引擎現在為何會發出這個聲音（為何決策）。'
    }
  ],
  L32701: [
    {
      question: '下列何者是金融機構實踐AI永續發展原則中，針對「環境」面向的具體作法？',
      options: {
        A: '利用AI分析數據，為弱勢族群提供金融服務。',
        B: '選擇能效較高的節能伺服器來訓練模型。',
        C: '為因AI而工作受影響的員工提供轉型培訓。',
        D: '確保AI決策的公平性，避免歧視。'
      },
      correctAnswer: 'B',
      explanation: '選擇節能硬體、優化演算法以降低計算需求，是直接針對AI運算可能產生大量能源消耗的「環境(E)」衝擊所採取的緩解措施。A、D屬於社會(S)面向，C屬於員工關懷。'
    },
    {
      question: 'AI的永續發展原則，強調金融機構運用AI時，宜將社會、環境等視為？',
      options: {
        A: '次要考量因素',
        B: '成本中心',
        C: '利害關係人',
        D: '競爭對手'
      },
      correctAnswer: 'C',
      explanation: '永續發展的核心是將企業的責任範圍擴大，不再只對股東負責，而是對包括社會、環境在內的所有利害關係人負責。'
    },
    {
      question: '下列哪項作法有助於透過「改進模型與演算法」來提升AI的能源效率？',
      options: {
        A: '盡可能使用層數最多、參數最複雜的模型。',
        B: '優化演算法及減少模型的複雜度與計算需求。',
        C: '增加模型訓練的次數。',
        D: '使用未經處理的原始數據進行訓練。'
      },
      correctAnswer: 'B',
      explanation: '在滿足業務需求的前提下，選擇或設計更輕量、更高效的模型（如模型剪枝、量化），是從演算法層面降低能源消耗的有效途徑。'
    },
    {
      question: '透過虛擬化技術及資源共享方式，將運算資源集中管理，主要是為了達到什麼永續目標？',
      options: {
        A: '增加每個部門的伺服器數量。',
        B: '減少重複的硬體設置，從而節省能源消耗。',
        C: '提升每個模型的預測準確率。',
        D: '讓資料備份更困難。'
      },
      correctAnswer: 'B',
      explanation: '資源的集中管理與共享可以顯著提高硬體的利用率，避免各部門獨立建置低利用率的伺服器，從而達到節能減碳的環保效益。'
    },
    {
      question: '「永續AI三面向」記憶輔助中，「普惠金融、縮小數位落差」對應的是哪個面向？',
      options: {
        A: '環境 (E)',
        B: '社會 (S)',
        C: '治理 (G)',
        D: '經濟 (E)'
      },
      // FIX: Corrected an invalid correctAnswer 'S' to the valid option key 'B'.
      correctAnswer: 'B',
      explanation: '普惠金融和縮小數位落差都是旨在減少社會不平等、促進包容性成長的措施，屬於永續發展中的「社會(S)」範疇。'
    },
    {
      question: '利用AI分析替代數據，為過去無法獲得銀行服務的偏鄉居民提供貸款，這體現了AI在哪方面的永續價值？',
      options: {
        A: '環境保護',
        B: '促進包容性成長與社會公平',
        C: '提升能源效率',
        D: '保護員工權益'
      },
      correctAnswer: 'B',
      explanation: '這是一個典型的利用AI實踐「普惠金融」的案例，旨在將金融服務擴展到傳統服務未能觸及的群體，促進社會的包容性發展。'
    },
    {
      question: '為何需要「預先處理資料」以達成永續目標？',
      options: {
        A: '因為原始資料比較好看。',
        B: '可以減少不必要的數據傳輸，並透過提升資料品質，減少重複運算所消耗的能源。',
        C: '可以增加模型訓練的難度。',
        D: '可以讓資料庫的容量變大。'
      },
      correctAnswer: 'B',
      explanation: '乾淨、高品質的資料可以讓模型更快地收斂，減少因數據品質不佳而需要反覆進行的、耗費能源的訓練。同時，去除不必要的資料也能減少傳輸時的能耗。'
    },
    {
      question: '借重能源效能監控系統，實時監測AI系統之能源消耗，這屬於永續發展落實方式中的？',
      options: {
        A: '改進模型與演算法',
        B: '智慧控管能效',
        C: '優化硬體設施',
        D: '共享資源及虛擬化'
      },
      correctAnswer: 'B',
      explanation: '「沒有測量，就沒有管理」。透過監控系統來量化AI的能耗，是進行後續優化和管理的第一步，也是智慧化管理的一部分。'
    },
    {
      question: '下列何者是AI對環境可能產生的主要負面影響？',
      options: {
        A: '產生大量實體廢棄物。',
        B: '訓練大型模型時消耗巨大的電力能源。',
        C: '造成噪音污染。',
        D: '排放有毒氣體。'
      },
      correctAnswer: 'B',
      explanation: '訓練頂尖的大型AI模型，需要數千顆高性能GPU長時間運行，其電力消耗非常驚人，是AI發展中最受關注的環境議題。'
    },
    {
      question: 'AI的永續發展原則是六大核心原則中的第幾項？',
      options: {
        A: '原則三',
        B: '原則四',
        C: '原則五',
        D: '原則六'
      },
      correctAnswer: 'D',
      explanation: '促進永續發展是六大核心原則的最後一項，它將AI的視野從單純的商業和技術，擴展到了更廣泛的社會與環境責任層面。'
    }
  ],
  L32702: [
    {
      question: '面對AI可能帶來的職位轉變，根據指引，金融機構應對員工採取的主要措施是什麼？',
      options: {
        A: '鼓勵員工自行學習，公司不介入。',
        B: '直接淘汰所有可能被AI取代的職位。',
        C: '提供適當的教育及培訓，協助員工適應變革並維護其工作權益。',
        D: '禁止員工使用任何AI工具，以保護工作。'
      },
      correctAnswer: 'C',
      explanation: '指引強調，金融機構應盡可能維護員工的工作權益，並透過提供教育和培訓，幫助員工從重複性的工作中解放出來，轉型至需要更高價值判斷、與AI協作的新角色。'
    },
    {
      question: '為避免「數位落差」，金融機構在推行新的數位AI服務時，下列哪個做法最為洽當？',
      options: {
        A: '立即全面停止所有傳統的人工服務管道。',
        B: '只針對年輕客戶群體進行宣傳。',
        C: '提供數位弱勢族群（如高齡者）額外的教學與支持，並保留多元服務管道。',
        D: '要求所有客戶必須在一個月內學會使用新服務。'
      },
      correctAnswer: 'C',
      explanation: '一個包容性的數位轉型，應考慮到不同族群對科技的適應能力。提供教學、保留傳統服務管道，是幫助數位弱勢群體順利過渡、避免被排除在外的關鍵措施。'
    },
    {
      question: '將原有的人力客服，培訓轉型為負責維護和優化AI機器人知識庫的「AI訓練師」，這體現了什麼原則？',
      options: {
        A: '追求成本最小化',
        B: '保護員工工作權益並協助其價值提升',
        C: '加速數位落差',
        D: '強化系統安全性'
      },
      correctAnswer: 'B',
      explanation: '這是一個成功的人機協作轉型案例。它不是簡單地用AI取代人，而是透過培訓，讓員工轉向更有價值、與AI協同工作的新角色，實現了雙贏。'
    },
    {
      question: '「員工轉型雙引擎」記憶輔助中，「賦能 (Enable)」指的是什麼？',
      options: {
        A: '給予員工更高的薪水。',
        B: '讓員工可以提早退休。',
        C: '透過教育訓練，賦予員工與AI協作的新技能。',
        D: '賦予員工管理AI的最高權限。'
      },
      correctAnswer: 'C',
      explanation: '「賦能」的核心是提升能力。透過有效的培訓，讓員工掌握使用新工具、適應新流程所需的能力，是成功轉型的基礎。'
    },
    {
      question: '下列何者是金融機構應對員工提供的AI相關教育及培訓內容？',
      options: {
        A: '僅需提供AI如何威脅其工作的資訊。',
        B: '僅需教導如何編寫AI程式碼。',
        C: '應包含AI基本概念、如何影響工作流程等，並可視需要建立專案小組監控。',
        D: '只需提供外部線上課程連結，不需內部規劃。'
      },
      correctAnswer: 'C',
      explanation: '一個有效的培訓計畫應該是全面且有組織的，不僅要傳授知識，還要結合實際工作流程，並建立機制來追蹤培訓成效和員工適應情況。'
    },
    {
      question: '金融機構關懷員工、維護其工作權益，最主要的目的是什麼？',
      options: {
        A: '這只是為了符合法規的最低要求。',
        B: '建立一個更具韌性與向心力的組織，實現和諧的人機協作未來。',
        C: '減緩公司導入AI的速度。',
        D: '增加公司的營運成本。'
      },
      correctAnswer: 'B',
      explanation: '員工是企業最重要的資產。在技術變革中關懷員工，幫助他們成長，不僅能降低轉型的阻力，更能激發員工的潛力，共同打造一個更能適應未來挑戰的組織。'
    },
    {
      question: '為不熟悉數位工具的客戶，保留傳統的電話理財專員和臨櫃服務，這主要是為了？',
      options: {
        A: '增加分行的工作量。',
        B: '降低數位焦慮與落差。',
        C: '鼓勵客戶不要使用數位服務。',
        D: '測試分行人員的耐心。'
      },
      correctAnswer: 'B',
      explanation: '這是普惠金融精神的體現，確保金融服務的普及性，不因客戶的年齡或數位能力而產生排擠效應。'
    },
    {
      question: '提升員工對節約能源、照顧數位弱勢之意識，這屬於哪個核心原則的範疇？',
      options: {
        A: '公平性',
        B: '安全性',
        C: '透明性',
        D: '永續發展'
      },
      correctAnswer: 'D',
      explanation: '將永續發展的理念（環境保護、社會包容）融入員工培訓，是將永續文化深植於組織DNA的有效作法。'
    },
    {
      question: '在AI導入過程中，建立專案小組來監控員工適應情況，其目的是什麼？',
      options: {
        A: '為了找出適應不良的員工並予以懲罰。',
        B: '為了根據實際需求，及時調整教育及培訓計畫。',
        C: '為了向高層證明專案的困難度。',
        D: '為了撰寫一份詳細的歷史報告。'
      },
      correctAnswer: 'B',
      explanation: '這是一個動態的管理過程。透過監控和回饋，可以了解培訓計畫的成效和員工遇到的實際困難，從而進行滾動式修正，讓培訓更貼近需求。'
    },
    {
      question: '下列何者是金融機構在數位轉型中，對員工應負的責任？',
      options: {
        A: '要求員工自行承擔所有轉型成本。',
        B: '尊重並保護其工作權益，提供適當的教育及培訓。',
        C: '對員工隱瞞所有AI導入計畫。',
        D: '鼓勵員工盡早退休。'
      },
      correctAnswer: 'B',
      explanation: '指引明確指出，金融機構對員工負有尊重、保護和協助其適應變革的責任，這不僅是倫理要求，也是實現永續經營的策略。'
    }
  ]
};