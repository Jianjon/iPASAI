import type { PracticeQuestion } from '../../types';

export const L21_PRACTICE: Record<string, PracticeQuestion[]> = {
  L21101: [
    {
      question: '關於Transformer模型中的自注意力機制(Self-Attention)，下列敘述何者正確？',
      options: {
        A: '只能處理序列中相鄰詞彙的關係。',
        B: '計算成本隨序列長度呈線性增長。',
        C: '使得模型可以進行大規模平行運算。',
        D: '主要用於自然語言生成，而非理解。'
      },
      correctAnswer: 'C',
      explanation: '自注意力機制的核心優勢在於它能一步到位地計算序列中所有詞彙之間的相互影響，這種計算可以大規模並行化，極大地提高了訓練效率。它能捕捉長距離依賴，不僅限於相鄰詞彙，且計算成本隨序列長度呈二次方增長。'
    },
    {
      question: '某客服中心希望從大量的客戶通話錄音轉譯文本中，自動識別出客戶提到的產品型號與問題類型。此任務最核心的NLP技術是？',
      options: {
        A: '情感分析 (Sentiment Analysis)',
        B: '機器翻譯 (Machine Translation)',
        C: '命名實體識別 (Named Entity Recognition)',
        D: '文本摘要 (Text Summarization)'
      },
      correctAnswer: 'C',
      explanation: '命名實體識別（NER）專門用於從文本中識別和分類預先定義好的實體，如人名、地名、組織名，以及此處的「產品型號」和「問題類型」。'
    },
    {
      question: '在比較傳統詞向量(Word Embedding)如Word2Vec與基於Transformer的BERT模型時，BERT最主要的優勢為何？',
      options: {
        A: '訓練速度更快。',
        B: '能處理一詞多義的問題，根據上下文生成不同的詞向量。',
        C: '模型參數較少，對硬體要求較低。',
        D: '不需要大量的訓練數據。'
      },
      correctAnswer: 'B',
      explanation: 'BERT是基於上下文的動態詞向量模型。與Word2Vec為每個詞生成固定向量不同，BERT會根據詞彙在句子中的具體上下文，生成不同的向量表示，從而有效地解決了「bank」可以指銀行也可以指河岸這樣的一詞多義問題。'
    },
    {
      question: '自然語言理解 (NLU) 與自然語言生成 (NLG) 的主要區別是什麼？',
      options: {
        A: 'NLU負責將文本轉為語音，NLG負責將語音轉為文本。',
        B: 'NLU是關於理解語言的意義，NLG是關於創造自然的語言文本。',
        C: 'NLU使用Transformer，NLG使用RNN。',
        D: '兩者沒有本質區別，只是應用的名稱不同。'
      },
      correctAnswer: 'B',
      explanation: 'NLU (Natural Language Understanding) 的核心是「讀懂」，即將非結構化的語言輸入轉化為結構化的意義表示；而NLG (Natural Language Generation) 的核心是「寫作」或「說話」，即將結構化的資訊轉化為人類可讀的自然語言。'
    },
    {
      question: '在中文自然語言處理中，通常第一個關鍵步驟是什麼？',
      options: {
        A: '命名實體識別 (NER)',
        B: '情感分析',
        C: '斷詞 (Tokenization)',
        D: '詞性標註 (POS Tagging)'
      },
      correctAnswer: 'C',
      explanation: '與英文不同，中文句子中的詞與詞之間沒有空格分隔，因此在進行任何後續分析之前，必須先將連續的句子切分成有意義的詞彙單位，這個過程稱為斷詞。'
    },
    {
      question: '聊天機器人(Chatbot)為了理解使用者的主要目的（例如，查詢訂單、預約服務），最需要依賴下列哪項NLU技術？',
      options: {
        A: '詞向量 (Word Embedding)',
        B: '意圖識別 (Intent Recognition)',
        C: '文本摘要',
        D: '機器翻譯'
      },
      correctAnswer: 'B',
      explanation: '意圖識別是聊天機器人系統的核心，它專門用來判斷用戶輸入的一段話背後的主要意圖或目的，以便系統能觸發對應的處理流程。'
    },
    {
      question: '下列何者是範本式(Template-based)自然語言生成的主要缺點？',
      options: {
        A: '生成速度非常慢',
        B: '需要大量的計算資源',
        C: '生成的文本缺乏靈活性和多樣性',
        D: '無法保證語法的正確性'
      },
      correctAnswer: 'C',
      explanation: '範本式生成依賴預先定義好的句子框架，雖然可靠且語法正確，但生成的內容非常固定，缺乏變化和自然的感覺，無法應對複雜或未預料到的情況。'
    },
    {
      question: '「模型可能從訓練數據中學到並放大了社會上已存在的性別或種族偏見。」這個問題描述了NLP領域的哪一項主要挑戰？',
      options: {
        A: '語言歧義性',
        B: '計算資源限制',
        C: '演算法偏見',
        D: '缺乏常識'
      },
      correctAnswer: 'C',
      explanation: '這正是演算法偏見（Algorithmic Bias）的典型例子。如果訓練數據本身就帶有偏見，AI模型會忠實地學習這些偏見，並可能在應用中重現甚至加劇不公平的現象。'
    },
    {
      question: '下列哪一項技術最能體現「將詞彙映射到高維向量空間，使語義相近的詞在空間中也相近」的概念？',
      options: {
        A: '詞性標註 (POS Tagging)',
        B: '命名實體識別 (NER)',
        C: '斷詞 (Tokenization)',
        D: '詞向量 (Word Embedding)'
      },
      correctAnswer: 'D',
      explanation: '詞向量（如Word2Vec, GloVe）的核心思想就是為每個詞學習一個數值向量，這個向量能夠捕捉詞的語義資訊。在向量空間中，「國王」和「皇后」的向量會比「國王」和「香蕉」的向量更接近。'
    },
    {
      question: '為何說Transformer架構的出現徹底改變了NLP領域？',
      options: {
        A: '它是第一個能夠處理中文的架構。',
        B: '它大幅降低了訓練NLP模型的成本。',
        C: '它引入的自注意力機制能高效捕捉長距離依賴且適合平行運算。',
        D: '它完全解決了語言歧義性的問題。'
      },
      correctAnswer: 'C',
      explanation: 'Transformer的革命性在於其自注意力機制，它擺脫了RNN的序列化處理依賴，不僅能更好地捕捉句子中任意兩個詞之間的長距離關係，而且其計算過程可以高度平行化，使得訓練前所未有的大型語言模型成為可能。'
    }
  ],
  L21102: [
    {
      question: '下列哪一項電腦視覺任務，旨在對影像中的每一個像素點都進行分類，並區分出同類別的不同實例（例如，標示出圖中的「第一隻貓」和「第二隻貓」）？',
      options: {
        A: '影像分類 (Image Classification)',
        B: '物件偵測 (Object Detection)',
        C: '語意分割 (Semantic Segmentation)',
        D: '實例分割 (Instance Segmentation)'
      },
      correctAnswer: 'D',
      explanation: '實例分割是電腦視覺中最精細的任務，它不僅需要像語意分割那樣為每個像素分類，還需要區分開屬於同一類別的不同個體。'
    },
    {
      question: '一個需要部署在邊緣設備（如無人機）上進行即時障礙物識別的系統，在選擇物件偵測模型時，應優先考量下列何者？',
      options: {
        A: '模型的偵測精確率（mAP）',
        B: '模型的推論速度（FPS）',
        C: '模型的可解釋性',
        D: '模型的訓練資料量'
      },
      correctAnswer: 'B',
      explanation: '對於邊緣設備和即時應用場景，模型的推論速度（每秒能處理的幀數，FPS）是關鍵限制因素。像YOLO這樣的單階段模型因其高速度而常被選用，即使其精確率可能略低於某些兩階段模型。'
    },
    {
      question: '關於卷積神經網路（CNN）的核心特性，下列敘述何者錯誤？',
      options: {
        A: '透過權重共享（Weight Sharing）大幅減少模型參數。',
        B: '擅長捕捉圖像的局部空間特徵。',
        C: 'ResNet透過殘差學習解決了深度網路的梯度消失問題。',
        D: 'CNN的性能與網路深度成反比，越淺越好。'
      },
      correctAnswer: 'D',
      explanation: '一般來說，在一定範圍內，增加CNN的深度可以讓模型學習到更複雜、更抽象的特徵，從而提升性能。ResNet的出現更是讓訓練非常深的網路成為可能。因此「越淺越好」是錯誤的。'
    },
    {
      question: 'YOLO (You Only Look Once) 系列演算法屬於下列哪一類物件偵測方法？',
      options: {
        A: '兩階段 (Two-stage) 方法',
        B: '單階段 (One-stage) 方法',
        C: '基於候選區域的方法',
        D: '基於影像分割的方法'
      },
      correctAnswer: 'B',
      explanation: 'YOLO是單階段偵測器的代表，它將物件偵測視為一個單一的迴歸問題，直接從整個圖像中預測邊界框和類別機率，因此速度非常快。'
    },
    {
      question: '在醫療影像分析中，U-Net模型特別適用於下列哪項任務？',
      options: {
        A: '計算影像中的細胞數量',
        B: '判斷X光片是否有骨折',
        C: '從CT掃描中精確分割出腫瘤區域',
        D: '對醫療報告進行分類'
      },
      correctAnswer: 'C',
      explanation: 'U-Net是一種專為生物醫學影像分割設計的CNN架構，其獨特的U形結構和跳躍連接能很好地結合深層語義特徵和淺層細節特徵，實現像素級的精確分割。'
    },
    {
      question: '下列哪個經典CNN模型，透過引入「殘差連接」(Residual Connection) 成功解決了深度網路訓練時的梯度消失問題？',
      options: {
        A: 'AlexNet',
        B: 'VGGNet',
        C: 'LeNet-5',
        D: 'ResNet'
      },
      correctAnswer: 'D',
      explanation: 'ResNet（殘差網路）的核心創新是引入了「捷徑連接」或「殘差塊」，允許梯度在反向傳播時可以「跳過」某些層直接向後傳遞，極大地緩解了梯度消失問題，使得訓練數百甚至上千層的超深度網路成為可能。'
    },
    {
      question: '物件偵測 (Object Detection) 與影像分類 (Image Classification) 最主要的區別是什麼？',
      options: {
        A: '物件偵測只能識別一種物體，影像分類可以識別多種。',
        B: '物件偵測不僅要識別物體類別，還要標示出其在圖像中的位置。',
        C: '物件偵測使用CNN，影像分類使用RNN。',
        D: '兩者在任務目標上沒有區別。'
      },
      correctAnswer: 'B',
      explanation: '影像分類的任務是回答「圖中有什麼？」（例如，貓），而物件偵測更進一步，需要回答「圖中的物體在哪裡，以及它們是什麼？」（例如，在左上角有一隻貓）。因此，物件偵測的輸出包含了類別標籤和位置邊界框。'
    },
    {
      question: '在圖像中加入人眼無法察覺的微小擾動，卻能導致模型做出完全錯誤的判斷，這種現象被稱為什麼？',
      options: {
        A: '遮擋 (Occlusion)',
        B: '數據偏見 (Data Bias)',
        C: '對抗性攻擊 (Adversarial Attack)',
        D: '模型退化 (Model Degradation)'
      },
      correctAnswer: 'C',
      explanation: '對抗性攻擊是深度學習模型的一個重要安全漏洞。攻擊者可以精心設計微小的、有針對性的噪聲疊加到原始圖像上，生成一個「對抗樣本」，這個樣本在人眼看來與原圖無異，但能讓模型產生高信心的錯誤預測。'
    },
    {
      question: '語意分割 (Semantic Segmentation) 和實例分割 (Instance Segmentation) 的共同點是什麼？',
      options: {
        A: '它們都能區分同類別的不同個體。',
        B: '它們的輸出都只是物體的邊界框。',
        C: '它們都對圖像中的每個像素進行分類。',
        D: '它們都無法處理被遮擋的物體。'
      },
      correctAnswer: 'C',
      explanation: '兩者的共同點在於它們都是像素級的預測任務，目標是為圖像中的每一個像素點分配一個類別標籤。它們的區別在於，實例分割在此基礎上，還需要區分出同類別的不同個體（instance）。'
    },
    {
      question: '下列何者不是電腦視覺在自動駕駛中的典型應用？',
      options: {
        A: '利用物件偵測識別車輛與行人。',
        B: '利用影像分割辨識車道線。',
        C: '利用語音辨識接收駕駛指令。',
        D: '利用影像分類識別交通號誌。'
      },
      correctAnswer: 'C',
      explanation: '語音辨識接收駕駛指令屬於自然語言處理（NLP）或語音處理的範疇，而非電腦視覺。電腦視覺在自動駕駛中主要負責「看懂」周遭環境。'
    }
  ],
  L21103: [
    {
      question: '下列哪項技術的核心原理，是透過一個「生成器」和一個「判別器」的相互博弈來學習數據分佈？',
      options: {
        A: '擴散模型 (Diffusion Models)',
        B: '大型語言模型 (LLMs)',
        C: '生成對抗網路 (GANs)',
        D: '卷積神經網路 (CNNs)'
      },
      correctAnswer: 'C',
      explanation: '生成對抗網路（GANs）的標誌性結構就是由一個負責創造假數據的生成器和一個負責分辨真假的判別器組成，兩者在競爭中共同進化。'
    },
    {
      question: '目前頂尖的文生圖（Text-to-Image）模型，如DALL-E 2、Stable Diffusion，其核心技術主要基於下列何者？',
      options: {
        A: '生成對抗網路 (GANs)',
        B: '擴散模型 (Diffusion Models)',
        C: '循環神經網路 (RNNs)',
        D: '決策樹 (Decision Trees)'
      },
      correctAnswer: 'B',
      explanation: '擴散模型透過一個「去噪」的過程，從隨機噪聲中逐步生成高品質的圖像，其生成圖像的品質和穩定性在近年來已經超越了GANs，成為SOTA文生圖模型的首選架構。'
    },
    {
      question: '大型語言模型（LLMs）如GPT系列，其驚人的語言能力主要來自於下列何者？',
      options: {
        A: '在高品質的人工標註數據集上進行監督學習。',
        B: '透過與人類進行大量對話來進行強化學習。',
        C: '在網際網路級別的海量文本上進行無監督的「預測下一個詞」任務。',
        D: '內建了完整的語法規則和知識圖譜。'
      },
      correctAnswer: 'C',
      explanation: 'LLMs的核心是預訓練（Pre-training）階段。在這個階段，模型透過一個看似簡單的自監督任務——預測文本序列中的下一個詞——從而從海量的無標籤文本中學到了豐富的語言模式、世界知識和一定的推理能力。'
    },
    {
      question: '「模型有時會一本正經地胡說八道，生成看似合理但事實上完全錯誤的資訊。」這個現象被稱為什麼？',
      options: {
        A: '模型偏見 (Bias)',
        B: '模式崩潰 (Mode Collapse)',
        C: '事實性錯誤或幻覺 (Hallucination)',
        D: '深度偽造 (Deepfake)'
      },
      correctAnswer: 'C',
      explanation: 'Hallucination（幻覺）是大型語言模型的一個主要問題，指的是模型生成了與事實不符、脫離現實或與源文本矛盾的內容。'
    },
    {
      question: 'GitHub Copilot這類AI程式碼助手，其背後的核心技術是什麼？',
      options: {
        A: '在大量演算法教科書上訓練的專家系統。',
        B: '將程式碼問題轉化為圖像進行分析的電腦視覺模型。',
        C: '在海量公開程式碼庫上訓練的大型語言模型。',
        D: '一個基於規則的語法檢查和修正引擎。'
      },
      correctAnswer: 'C',
      explanation: 'GitHub Copilot的核心是一個在數十億行公開程式碼上進行預訓練的大型語言模型（是GPT系列的一個變體）。它學會了程式碼的語法、模式和上下文，從而能夠根據註解或現有程式碼生成新的程式碼片段。'
    },
    {
      question: '下列何者是生成式AI帶來的倫理風險？',
      options: {
        A: '模型訓練需要消耗大量電力。',
        B: '生成逼真的偽造影像（Deepfake）可能被用於詐騙。',
        C: '模型可能會記住訓練數據中的個人隱私資訊。',
        D: '以上皆是。'
      },
      correctAnswer: 'D',
      explanation: '生成式AI的倫理風險是多方面的，A是環境與資源問題，B是濫用與社會安全問題，C是隱私問題。這些都是規劃和部署生成式AI應用時必須審慎考慮的因素。'
    },
    {
      question: '在生成對抗網路(GAN)中，生成器(Generator)和判別器(Discriminator)的角色是什麼？',
      options: {
        A: '生成器負責分類，判別器負責生成圖像。',
        B: '生成器試圖創造逼真的假數據，判別器試圖分辨真假。',
        C: '兩者合作，共同完成一個圖像修復任務。',
        D: '生成器是CNN，判別器是RNN。'
      },
      correctAnswer: 'B',
      explanation: 'GAN的運作機制是一個minimax賽局。生成器的目標是生成讓判別器無法分辨的假數據，而判別器的目標是盡可能準確地分辨出真實數據和生成器生成的假數據。'
    },
    {
      question: '擴散模型(Diffusion Model)生成圖像的基本過程是什麼？',
      options: {
        A: '從一張大圖中裁剪出一小塊。',
        B: '將多張現有圖片拼接組合而成。',
        C: '從一個隨機噪聲圖像開始，逐步去除噪聲來還原出一張清晰圖像。',
        D: '先生成圖像的輪廓，然後再逐步填充顏色和紋理。'
      },
      correctAnswer: 'C',
      explanation: '擴散模型的核心思想是一個反向的「去噪」過程。它學習如何從一個完全無序的隨機噪聲分佈中，一步步地、有控制地移除噪聲，最終生成一個結構清晰、內容豐富的圖像。'
    },
    {
      question: '關於生成式AI的智慧財產權問題，目前的普遍共識是什麼？',
      options: {
        A: 'AI生成的內容版權完全歸屬於AI模型本身。',
        B: 'AI生成的內容版權完全歸屬於AI公司的開發者。',
        C: 'AI生成的內容不受版權保護，屬於公共領域。',
        D: '版權歸屬在法律上仍是模糊地帶，各國規定不一。'
      },
      correctAnswer: 'D',
      explanation: '生成式AI內容的版權歸屬是一個非常複雜且懸而未決的法律問題。目前全球尚未形成統一的法律共識，不同國家的法院和版權局對此有不同的看法和判例，仍處於積極的討論和發展階段。'
    },
    {
      question: '下列哪一項不是生成式AI的典型應用？',
      options: {
        A: '根據文字描述生成圖像。',
        B: '自動撰寫新聞報導。',
        C: '從病歷中預測病人是否會再次入院。',
        D: '創作一首新的古典樂曲。'
      },
      correctAnswer: 'C',
      explanation: '「預測病人是否會再次入院」是一個典型的監督式學習中的分類問題，其目標是「判斷」而非「創造」，屬於鑑別式AI的範疇。A、B、D都是從無到有創造新內容，是生成式AI的應用。'
    }
  ],
  L21104: [
    {
      question: '多模態人工智慧（Multimodal AI）最核心的特點是什麼？',
      options: {
        A: '它能比單模態AI更快地處理數據。',
        B: '它能處理來自多種不同來源的數據類型，如圖像和文本。',
        C: '它只專注於處理非結構化數據。',
        D: '它不需要進行模型訓練。'
      },
      correctAnswer: 'B',
      explanation: '多模態AI的定義就是能夠同時處理和融合多種不同模態（如視覺、聽覺、文字）的資訊，以獲得比任何單一模態更全面的理解。'
    },
    {
      question: '在多模態學習中，CLIP (Contrastive Language-Image Pre-training) 模型的主要貢獻是什麼？',
      options: {
        A: '它提出了一種新的圖像分割演算法。',
        B: '它透過對比學習，成功地建立了一個語義對齊的圖文聯合嵌入空間。',
        C: '它是第一個能夠生成影片的多模態模型。',
        D: '它大幅降低了處理語音數據的計算成本。'
      },
      correctAnswer: 'B',
      explanation: 'CLIP的核心貢獻是構建了一個共享的向量空間，在這個空間裡，語義相關的圖片和文字的向量表示非常接近。這為後續的零樣本圖像分類、圖像檢索等任務奠定了堅實的基礎。'
    },
    {
      question: '一個AI系統接收一張圖片和一個關於圖片的問題（例如，「圖中的人穿著什麼顏色的上衣？」），並輸出文字答案。這個任務被稱為什麼？',
      options: {
        A: '影像字幕生成 (Image Captioning)',
        B: '文本到圖像生成 (Text-to-Image)',
        C: '視覺問答 (Visual Question Answering, VQA)',
        D: '物件偵測 (Object Detection)'
      },
      correctAnswer: 'C',
      explanation: '視覺問答（VQA）是一個典型的多模態任務，模型需要同時理解圖像的視覺內容和問題的文本語義，並將兩者結合進行推理才能得出答案。'
    },
    {
      question: '在融合多模態特徵時，將來自不同模態的數據在輸入層就直接拼接起來，送入單一模型處理，這種策略被稱為什麼？',
      options: {
        A: '早期融合 (Early Fusion)',
        B: '晚期融合 (Late Fusion)',
        C: '混合融合 (Hybrid Fusion)',
        D: '交叉注意力融合 (Cross-Attention Fusion)'
      },
      correctAnswer: 'A',
      explanation: '早期融合（也稱特徵級融合）是在數據處理流程的早期階段就將不同模態的特徵結合起來。它的優點是簡單，但要求模態間的數據能夠很好地對齊。'
    },
    {
      question: '自動駕駛汽車為了精準感知周圍環境，通常會結合攝影機、光達（LiDAR）和雷達的數據。這體現了多模態AI的哪項主要優勢？',
      options: {
        A: '降低開發成本',
        B: '提升系統的穩健性和可靠性',
        C: '加快模型訓練速度',
        D: '減少數據儲存需求'
      },
      correctAnswer: 'B',
      explanation: '不同的感測器（模態）各有優劣。例如，攝影機在惡劣天氣下性能會下降，但雷達不受影響。融合多種感測器的數據可以互補長短，大大提升感知系統在各種複雜環境下的穩健性和可靠性。'
    },
    {
      question: '下列哪一項是文本到圖像生成（Text-to-Image）的典型例子？',
      options: {
        A: '輸入一張貓的圖片，系統輸出「一隻貓坐在墊子上」。',
        B: '輸入文字「一隻正在太空中騎著摩托車的宇航員貓」，系統生成一張對應的圖片。',
        C: '輸入一段語音，系統將其轉換為文字。',
        D: '輸入一張風景照，系統將其變為梵谷的油畫風格。'
      },
      correctAnswer: 'B',
      explanation: '文本到圖像生成的核心是將文字描述（一種模態）作為輸入，生成圖像（另一種模態）作為輸出。A是圖像字幕生成，C是語音辨識，D是風格遷移。'
    },
    {
      question: '在分析一段影片的情感時，多模態模型相比單純的文本分析，其主要優勢是什麼？',
      options: {
        A: '分析速度更快。',
        B: '可以處理更長的文本。',
        C: '能夠結合語音語調、臉部表情等非語言資訊，做出更準確的判斷。',
        D: '需要的訓練數據更少。'
      },
      correctAnswer: 'C',
      explanation: '人類的情感表達是多模態的。一個人在說「太好了」的時候，可能是真誠的，也可能是諷刺的。單從文字無法分辨，但結合其諷刺的語調和不屑的表情，多模態模型就能做出更準確的情感判斷。'
    },
    {
      question: '「將來自不同模態的數據，投影到一個共享的、語義對齊的向量空間中。」這描述了多模態學習中的哪種核心思想？',
      options: {
        A: '特徵融合 (Feature Fusion)',
        B: '晚期融合 (Late Fusion)',
        C: '聯合嵌入空間 (Joint Embedding Space)',
        D: '跨模態生成 (Cross-modal Generation)'
      },
      correctAnswer: 'C',
      explanation: '建立一個聯合嵌入空間是多模態學習的關鍵技術之一。其目標是學習一種映射，使得語義相關的不同模態內容（如「狗」的圖片和「dog」的文字）在該共享空間中的向量表示是相近的。'
    },
    {
      question: '下列何者是多模態AI面臨的主要挑戰之一？',
      options: {
        A: '模型通常過於簡單，無法學習複雜模式。',
        B: '很難找到能夠同時處理圖像和文本的硬體。',
        C: '獲取大量成對、標註良好的多模態數據集是困難且昂貴的。',
        D: '多模態模型無法應用於商業領域。'
      },
      correctAnswer: 'C',
      explanation: '數據是多模態學習的基礎。要訓練一個強大的圖文模型，就需要數以億計的高質量「圖像-文本」對。獲取和標註這種規模的多模態數據集是一個巨大的挑戰。'
    },
    {
      question: '下列哪個應用場景最不適合使用多模態AI？',
      options: {
        A: '根據電影的影片畫面、聲音和字幕來自動生成電影摘要。',
        B: '分析一段客服通話的錄音和對應的文字記錄來判斷客戶滿意度。',
        C: '從大量的公司財務報表（表格數據）中預測其未來的股價。',
        D: '為視障人士開發一個應用，能描述他們用手機攝像頭拍到的周圍環境。'
      },
      correctAnswer: 'C',
      explanation: '預測股價主要依賴的是結構化的時間序列數據（財務報表、交易數據），這是一個典型的單模態（表格數據）機器學習問題。而A、B、D都顯著地涉及到融合多種不同數據類型（視覺、聽覺、文字）的需求。'
    }
  ],
  L21201: [
    {
      question: '一個成功的AI專案，其起點應該是什麼？',
      options: {
        A: '找到一個最新的、最先進的AI演算法。',
        B: '組建一個頂尖的數據科學家團隊。',
        C: '定義一個清晰的、有價值的業務問題。',
        D: '購買一套最強大的GPU伺服器。'
      },
      correctAnswer: 'C',
      explanation: '所有成功的AI專案都始於對業務需求的深刻理解。技術、團隊和硬體都是為了解決業務問題而服務的工具。脫離了業務價值，技術本身是沒有意義的。'
    },
    {
      question: '在進行數據成熟度評估時，下列哪項不是「5R原則」之一？',
      options: {
        A: '相關性 (Relevance)',
        B: '可靠性 (Reliability)',
        C: '合規性 (Rights)',
        D: '即時性 (Real-time)'
      },
      correctAnswer: 'D',
      explanation: '數據成熟度評估的5R原則通常指：相關性(Relevance)、可靠性(Reliability)、可用量(Recent & Range)、合規性(Rights)和資源(Resources)。即時性是應用需求，而非數據本身的成熟度評估維度。'
    },
    {
      question: '某製造企業希望導入AI進行預測性維護，以減少設備無預警停機。這個業務痛點最適合轉化為下列哪一類AI問題？',
      options: {
        A: '圖像分類問題',
        B: '時間序列預測或異常偵測問題',
        C: '自然語言處理問題',
        D: '聚類分析問題'
      },
      correctAnswer: 'B',
      explanation: '預測性維護的核心是根據設備感測器過去一段時間的運行數據（時間序列），來預測其在未來某個時間點發生故障的機率，或者偵測出與正常運行模式不符的異常狀態。'
    },
    {
      question: '在評估AI專案的投資回報率(ROI)時，下列何者屬於「效益(Return)」的範疇？',
      options: {
        A: '購買GPU伺服器的費用。',
        B: '數據科學家團隊的薪資。',
        C: '因智慧推薦系統帶來的銷售額提升。',
        D: '雲端運算平台的使用費。'
      },
      correctAnswer: 'C',
      explanation: 'ROI的效益(Return)指的是專案實施後帶來的價值增長，如增加營收、降低成本或規避風險。A、B、D都屬於專案的「投資(Investment)」或成本。'
    },
    {
      question: '「數據孤島 (Data Silos)」指的是什麼問題？',
      options: {
        A: '數據量太小，不足以訓練模型。',
        B: '數據品質太差，充滿錯誤和缺失。',
        C: '解決問題所需的數據分散在不同部門的系統中，難以整合。',
        D: '數據的儲存格式過於老舊。'
      },
      correctAnswer: 'C',
      explanation: '數據孤島是企業在進行數據分析時常見的組織和技術障礙，指的是有價值的數據被鎖在各個獨立的部門或系統中，無法被有效地共享和利用。'
    },
    {
      question: '在AI導入評估的「技術可行性分析」階段，下列哪項不是需要考慮的重點？',
      options: {
        A: '該問題是否有成熟的演算法可以解決？',
        B: '模型的預期準確率能否滿足業務需求？',
        C: '公司是否有足夠的行銷預算來推廣AI產品？',
        D: '組織內部是否擁有具備相關技能的人才？'
      },
      correctAnswer: 'C',
      explanation: '技術可行性分析專注於評估技術、演算法、人才和基礎設施是否能支撐專案的實現。行銷預算是商業推廣層面的考量，不屬於技術可行性分析的範疇。'
    },
    {
      question: '評估數據的「合規性(Rights)」時，最需要關注的是什麼？',
      options: {
        A: '數據的總量是否夠大。',
        B: '數據的格式是否統一。',
        C: '數據的獲取與使用是否符合GDPR、個資法等隱私法規。',
        D: '數據的更新頻率是否夠高。'
      },
      correctAnswer: 'C',
      explanation: '合規性評估的核心是確保數據的整個生命週期（從收集、儲存到分析應用）都嚴格遵守相關的法律法規，特別是關於個人隱私保護的條款，以避免法律風險。'
    },
    {
      question: '為何在評估AI導入時，預估投資回報率(ROI)非常重要？',
      options: {
        A: '它可以幫助決定使用哪種程式語言。',
        B: '它是爭取管理層支持和評估專案成功與否的重要依據。',
        C: '它可以直接決定模型的最終準確率。',
        D: '它可以幫助選擇雲端服務提供商。'
      },
      correctAnswer: 'B',
      explanation: '企業的所有投資最終都需要以商業價值來衡量。一個清晰的ROI預估，能將AI專案的技術價值轉化為管理層可以理解的商業語言，證明專案的投資是合理且值得的，也是後續衡量專案是否成功的重要標竿。'
    },
    {
      question: '一家金融公司想利用AI來自動化信貸審批流程。在數據成熟度評估階段，除了數據量和準確性，他們還必須特別關注什麼？',
      options: {
        A: '數據是否包含用戶的社群媒體貼文。',
        B: '數據中是否存在可能導致歧視的歷史偏見。',
        C: '數據是否都是最近一個月內產生的。',
        D: '數據是否可以用Excel打開。'
      },
      correctAnswer: 'B',
      explanation: '在信貸、招聘等高風險領域，數據中潛在的歷史偏見是一個極其重要的問題。如果用帶有偏見的數據訓練模型，模型將會學到並固化這些偏見，做出歧視性的決策，引發嚴重的法律和倫理風險。'
    },
    {
      question: '將「客服人力成本過高」這個業務痛點，轉化為「建立一個能自動回答80%常見問題的聊天機器人」，這個過程屬於AI導入評估的哪個環節？',
      options: {
        A: '問題定義與業務對齊',
        B: '數據成熟度評估',
        C: '技術可行性分析',
        D: '投資回報率(ROI)預估'
      },
      correctAnswer: 'A',
      explanation: '這個過程是AI專案的起點，即將一個模糊的、高層次的業務痛點，轉化為一個清晰的、可被AI技術解決的具體問題，並確保它與企業的戰略目標一致。'
    }
  ],
  L21202: [
    {
      question: '在AI專案管理中，採用「敏捷開發」與「最小可行性產品 (MVP)」策略的主要目的是什麼？',
      options: {
        A: '一次性交付一個功能最完美的最終產品。',
        B: '嚴格遵循預先制定的長期開發計畫，不做任何變更。',
        C: '以最小成本快速驗證核心假設，並根據市場反饋進行迭代，以降低開發風險。',
        D: '為了最大限度地延長專案的開發週期。'
      },
      correctAnswer: 'C',
      explanation: 'AI專案充滿不確定性。MVP策略的核心思想是「小步快跑，快速試錯」，優先開發最核心的功能，快速推向市場進行驗證，然後根據真實的用戶反饋來指導後續的開發方向，這能有效避免在錯誤的方向上投入過多資源。'
    },
    {
      question: '一個理想的最小化AI專案團隊「AI三劍客」通常不包含下列哪個角色？',
      options: {
        A: '數據科學家 (Data Scientist)',
        B: '數據工程師 (Data Engineer)',
        C: '機器學習工程師 (ML Engineer)',
        D: '市場行銷經理 (Marketing Manager)'
      },
      correctAnswer: 'D',
      explanation: '「AI三劍客」指的是AI專案核心的技術鐵三角：數據科學家負責建模，數據工程師負責數據管道，ML工程師負責部署。市場行銷經理是重要的利害關係人，但不是核心技術團隊的成員。'
    },
    {
      question: '下列何者最能描述AI專案的生命週期？',
      options: {
        A: '一個嚴格的、線性的瀑布模型，每個階段完成後才能進入下一階段。',
        B: '一個一次性的過程，模型部署後專案即告結束。',
        C: '一個類似CRISP-DM的循環迭代框架，包含持續的監控與優化。',
        D: '完全沒有固定的流程，每次都隨機進行。'
      },
      correctAnswer: 'C',
      explanation: 'AI專案的生命週期是高度迭代和循環的。模型部署上線只是開始，還需要持續監控其性能，並根據數據漂移或業務變化，回到前面的階段（如數據準備、模型建立）進行再訓練和優化，形成一個閉環。'
    },
    {
      question: '在規劃AI專案時程時，為何需要預留緩衝時間？',
      options: {
        A: '因為數據標註通常比預期快。',
        B: '因為AI專案的研發和數據探索階段充滿不確定性。',
        C: '因為GPU伺服器通常會提前到貨。',
        D: '因為管理層喜歡看到更長的專案時程。'
      },
      correctAnswer: 'B',
      explanation: '與傳統的確定性軟體開發不同，AI專案中的模型訓練和數據分析具有很強的探索性質，其結果和所需時間難以精確預估。因此，在規劃時程時預留緩衝時間，是應對這種不確定性的必要做法。'
    },
    {
      question: '在AI專案團隊中，「機器學習工程師 (ML Engineer)」的主要職責是什麼？',
      options: {
        A: '進行探索性數據分析，找出數據洞見。',
        B: '設計和進行模型演算法的實驗。',
        C: '將數據科學家開發好的模型進行產品化、部署上線並建立MLOps流程。',
        D: '提供關於業務流程的專業知識。'
      },
      correctAnswer: 'C',
      explanation: 'ML工程師是連接數據科學與軟體工程的橋樑，他們專注於將模型從實驗室環境，轉變為一個穩定、可擴展、可維護的生產級服務。'
    },
    {
      question: '「一個在Jupyter Notebook中表現良好的模型，要變成一個穩定的線上服務，中間有巨大的工程鴻溝。」這句話描述了AI專案規劃中的哪項主要挑戰？',
      options: {
        A: '跨部門溝通障礙',
        B: '模型部署的鴻溝',
        C: '冷啟動問題',
        D: '缺乏領域專家'
      },
      correctAnswer: 'B',
      explanation: '這精準地描述了從模型原型到產品化部署的挑戰。原型開發關注的是模型性能，而生產部署需要考慮服務的穩定性、延遲、擴展性、監控、版本控制等一系列複雜的工程問題。'
    },
    {
      question: '對於推薦系統等應用，新用戶或新商品因缺乏歷史數據而難以做出準確推薦，這個問題被稱為什麼？',
      options: {
        A: '數據漂移 (Data Drift)',
        B: '過擬合 (Overfitting)',
        C: '數據孤島 (Data Silos)',
        D: '冷啟動問題 (Cold Start Problem)'
      },
      correctAnswer: 'D',
      explanation: '冷啟動問題是協同過濾等依賴歷史互動數據的推薦系統的固有挑戰，指的是如何為系統中的新實體（新用戶或新商品）提供有效的推薦。'
    },
    {
      question: '在AI專案規劃中，建立定期的跨部門溝通機制的主要目的是什麼？',
      options: {
        A: '為了增加會議的數量。',
        B: '為了讓技術團隊可以專心開發，不受業務方干擾。',
        C: '確保所有利害關係人對專案進度、挑戰和成果保持透明和同步。',
        D: '為了取代所有的技術文件。'
      },
      correctAnswer: 'C',
      explanation: '有效的溝通是專案成功的關鍵。定期的溝通可以確保技術團隊的開發方向與業務目標始終保持一致，及時暴露風險，並讓業務方對AI專案的價值有持續的、切實的感受。'
    },
    {
      question: '某團隊在開發AI質檢專案時，決定第一階段先在一條產線上部署模型，並與人工複檢並行，以驗證模型的穩定性和準確性。這種策略屬於？',
      options: {
        A: '瀑布模型',
        B: '最小可行性產品 (MVP)',
        C: '大爆炸式上線',
        D: '一次性交付'
      },
      correctAnswer: 'B',
      explanation: '這是一個典型的MVP策略應用。團隊沒有試圖一開始就打造一個覆蓋所有產線的完美系統，而是選擇了一個最小的、可驗證的範圍（一條產線），以受控的方式來驗證其核心價值和技術可行性。'
    },
    {
      question: '在AI專案生命週期的「模型部署 (Deployment)」階段之後，緊接著的關鍵階段是什麼？',
      options: {
        A: '專案結束與團隊解散',
        B: '撰寫最終報告',
        C: '申請專利',
        D: '持續的監控與維護 (Monitoring & Maintenance)'
      },
      correctAnswer: 'D',
      explanation: '模型部署上線絕不是終點。由於數據漂移等因素，模型的性能會隨時間衰退。因此，持續地監控模型性能，並在必要時進行再訓練和重新部署，是確保AI系統長期有效的關鍵。'
    }
  ],
  L21203: [
    {
      question: '當生產環境的數據分佈發生變化，與訓練數據不再一致時（例如，因疫情導致用戶消費行為改變），這種現象被稱為什麼？',
      options: {
        A: '概念漂移 (Concept Drift)',
        B: '數據漂移 (Data Drift)',
        C: '模型衰退 (Model Decay)',
        D: '對抗性攻擊 (Adversarial Attack)'
      },
      correctAnswer: 'B',
      explanation: '數據漂移指的是輸入特徵(X)的分佈P(X)發生了變化，這是導致已部署模型性能下降的最常見原因之一。'
    },
    {
      question: '下列哪一項是針對AI模型「可解釋性不足」風險的主要緩解措施？',
      options: {
        A: '使用更大規模的數據集進行訓練。',
        B: '使用更複雜的深度學習模型。',
        C: '在需要解釋的場景中，優先選擇決策樹、線性迴歸等白箱模型，或使用LIME、SHAP等XAI工具。',
        D: '對模型進行更頻繁的再訓練。'
      },
      correctAnswer: 'C',
      explanation: '應對可解釋性風險，要麼選擇本身就易於解釋的模型（白箱模型），要麼使用XAI（可解釋AI）工具來解釋黑箱模型的決策。增加數據量或模型複雜度通常會讓可解釋性變得更差。'
    },
    {
      question: '一個在歷史數據上訓練的招聘模型，可能會因為過去男性工程師佔多數，而對女性風格的履歷產生不公平的偏見。這屬於哪一類AI風險？',
      options: {
        A: '模型風險',
        B: '數據風險',
        C: '倫理與公平性風險',
        D: '營運風險'
      },
      correctAnswer: 'C',
      explanation: '這是典型的演算法偏見問題，源於訓練數據中存在的歷史性偏見，屬於倫理與公平性風險的範疇。模型本身沒有歧視的意圖，但它忠實地學習了數據中的不公平模式。'
    },
    {
      question: '為了實現AI應用的持續交付與生命週期管理，業界提出了一套旨在實現機器學習工作流程自動化的文化與實踐，稱之為？',
      options: {
        A: 'DevOps',
        B: 'Agile',
        C: 'MLOps',
        D: 'DataOps'
      },
      correctAnswer: 'C',
      explanation: 'MLOps（機器學習維運）是DevOps在機器學習領域的延伸，它專注於打通從數據、模型到部署的整個工作流，實現CI/CD/CT（持續整合/交付/訓練）的自動化管道。'
    },
    {
      question: '攻擊者故意向訓練數據中注入惡意樣本，以破壞模型的性能或植入後門，這種攻擊手法被稱為什麼？',
      options: {
        A: '數據漂移',
        B: '數據中毒攻擊 (Data Poisoning)',
        C: '對抗性攻擊',
        D: '模型竊取攻擊'
      },
      correctAnswer: 'B',
      explanation: '數據中毒攻擊直接污染了模型的「食物」——訓練數據，是一種非常隱蔽且危害巨大的攻擊方式，它從源頭上破壞了模型的可靠性。'
    },
    {
      question: '在AI風險管理中，「概念漂移 (Concept Drift)」指的是什麼？',
      options: {
        A: '輸入數據的分佈發生了變化。',
        B: '輸入特徵與目標變數之間的關係發生了改變。',
        C: '模型的程式碼出現了錯誤。',
        D: '用戶對產品的理解發生了變化。'
      },
      correctAnswer: 'B',
      explanation: '概念漂移指的是變數之間的底層關係 P(Y|X) 發生了變化。例如，金融市場的規則改變，導致同樣的經濟指標預示著完全不同的股市走向。這比數據漂移更難被檢測。'
    },
    {
      question: '下列何者不是營運風險的範疇？',
      options: {
        A: '模型服務的系統穩定性不足。',
        B: '缺乏有效的模型性能監控機制。',
        C: '模型可能對特定族群產生歧視。',
        D: '模型更新的流程過於冗長。'
      },
      correctAnswer: 'C',
      explanation: '模型產生歧視屬於倫理與公平性風險。營運風險主要關注AI系統在部署、上線、維運階段的技術和流程問題，如穩定性、監控、MLOps流程等。'
    },
    {
      question: '在金融風控模型的風險管理中，建立自動化監控系統，持續追蹤模型的準確率和關鍵變數的分佈，主要是為了應對哪種風險？',
      options: {
        A: '數據隱私風險',
        B: '數據漂移與模型性能衰退',
        C: '對抗性攻擊',
        D: '公平性風險'
      },
      correctAnswer: 'B',
      explanation: '持續監控模型的性能指標（如準確率）和輸入數據的分佈，是及時發現數據漂移或概念漂移，並觸發模型再訓練流程的關鍵，旨在解決模型上線後性能下降的問題。'
    },
    {
      question: '根據歐盟的GDPR法規，當AI系統做出對個人有重大影響的自動化決策（如拒絕貸款申請）時，用戶擁有哪些權利？',
      options: {
        A: '有權要求分紅。',
        B: '有權要求獲得該AI模型的原始碼。',
        C: '有權要求對決策進行解釋，並進行人工複核。',
        D: '有權刪除該模型。'
      },
      correctAnswer: 'C',
      explanation: 'GDPR等法規強調對自動化決策的知情權和解釋權，旨在保護個人免受純粹由演算法做出的、不透明且可能不公平的決策的影響。'
    },
    {
      question: '在高風險的AI應用（如自動駕駛）中，設計多重冗餘備份和失效安全（Fail-safe）機制，是為了緩解哪一類風險？',
      options: {
        A: '模型風險',
        B: '數據風險',
        C: '倫理風險',
        D: '營運風險'
      },
      correctAnswer: 'D',
      explanation: '冗餘備份和失效安全機制是系統工程中的概念，旨在確保即使部分組件發生故障，整個系統依然能夠保持運行或安全地終止，這屬於確保系統穩定性和可靠性的營運風險管理範疇。'
    }
  ],
  L21301: [
    {
      question: '「Garbage in, garbage out」這句名言，在AI專案中最能凸顯下列哪個階段的重要性？',
      options: {
        A: '模型部署',
        B: '數據準備與特徵工程',
        C: '使用者介面設計',
        D: '專案時程規劃'
      },
      correctAnswer: 'B',
      explanation: '這句話精準地說明了數據品質對模型性能的決定性作用。如果輸入給模型的數據是充滿錯誤和噪聲的「垃圾」，那麼即使使用最先進的演算法，輸出的結果也必然是不可靠的「垃圾」。'
    },
    {
      question: '在處理客戶流失預測的數據時，數據科學家從原始的「用戶最後登入日期」特徵，創造出一個新的「最近登入距今天數」特徵。這個過程稱為什麼？',
      options: {
        A: '數據清洗',
        B: '數據標註',
        C: '特徵工程',
        D: '數據標準化'
      },
      correctAnswer: 'C',
      explanation: '特徵工程是從原始數據中提取或構建出對模型更有預測能力的特徵的過程。這裡，將一個日期轉換為一個更有意義的、表示用戶活躍度的數值，是一個典型的特徵創造案例。'
    },
    {
      question: '對於監督式學習任務，下列哪個環節通常是AI專案中成本和時間投入最大的部分之一？',
      options: {
        A: '選擇優化器',
        B: '數據標註',
        C: '模型推論',
        D: '安裝開發環境'
      },
      correctAnswer: 'B',
      explanation: '獲取大量高質量的標註數據是監督式學習的基礎，而這個過程，無論是僱用內部團隊還是外包，通常都需要大量的人力和時間成本，其品質直接決定了模型的上限。'
    },
    {
      question: '在選擇機器學習模型時，若業務場景（如醫療診斷）高度要求模型能夠解釋其決策原因，應優先考慮下列哪類模型？',
      options: {
        A: '深度神經網路',
        B: '梯度提升機 (XGBoost)',
        C: '支援向量機 (SVM)',
        D: '邏輯迴歸或決策樹'
      },
      correctAnswer: 'D',
      explanation: '邏輯迴歸和決策樹是典型的「白箱模型」，其決策邏輯和規則是透明且易於人類理解的。而深度神經網路、XGBoost等模型雖然性能強大，但通常是「黑箱模型」，可解釋性較差。'
    },
    {
      question: '將一個包含「地區」特徵（如「台北」、「台中」、「高雄」）的欄位，轉換為多個二元（0/1）特徵欄位（如is_Taipei, is_Taichung, is_Kaohsiung），這種處理類別特徵的方法被稱為什麼？',
      options: {
        A: '標籤編碼 (Label Encoding)',
        B: '獨熱編碼 (One-Hot Encoding)',
        C: '數據標準化 (Standardization)',
        D: '降維 (Dimensionality Reduction)'
      },
      correctAnswer: 'B',
      explanation: '獨熱編碼是處理無序類別變數的標準方法，它將一個類別特徵轉換為一組互斥的二元特徵，避免了為類別引入不應有的大小關係。'
    },
    {
      question: '為何在將數據輸入到某些模型（如線性迴歸、SVM）之前，需要進行特徵縮放（如標準化或歸一化）？',
      options: {
        A: '為了增加數據的維度。',
        B: '為了讓數據更容易被人類讀懂。',
        C: '為了避免模型被那些數值尺度較大的特徵所主導。',
        D: '這是所有機器學習模型的強制要求。'
      },
      correctAnswer: 'C',
      explanation: '許多模型（特別是基於距離計算或梯度下降的模型）對輸入特徵的尺度很敏感。如果不進行縮放，一個尺度很大的特徵（如年收入）相對於一個尺度很小的特徵（如年齡），會在模型中佔據不成比例的主導地位，影響模型的學習效果。'
    },
    {
      question: '在模型選擇的過程中，建立一個簡單、快速的「基準模型 (Baseline Model)」的主要目的是什麼？',
      options: {
        A: '為了向管理層展示最酷炫的技術。',
        B: '為了盡可能地延長專案時間。',
        C: '為了提供一個性能底線，任何更複雜的模型都必須顯著優於它才有價值。',
        D: '基準模型就是最終要上線的模型。'
      },
      correctAnswer: 'C',
      explanation: '基準模型為模型性能提供了一個客觀的參考點。如果一個複雜的、耗費大量資源的模型，其性能僅僅略微優於（甚至不如）一個簡單的基準模型，那麼這個複雜模型就是沒有價值的。'
    },
    {
      question: '從所有可用特徵中，選出與預測目標最相關的特徵子集，以提升模型性能並降低計算複雜度，這個過程稱為什麼？',
      options: {
        A: '特徵提取 (Feature Extraction)',
        B: '特徵創造 (Feature Creation)',
        C: '特徵選擇 (Feature Selection)',
        D: '特徵縮放 (Feature Scaling)'
      },
      correctAnswer: 'C',
      explanation: '特徵選擇的目標是「少即是多」，通過移除無關或冗餘的特徵，來簡化模型、防止過擬合，並可能提升模型的泛化能力。'
    },
    {
      question: '下列哪項是處理數據中「離群值 (Outliers)」時應採取的謹慎態度？',
      options: {
        A: '只要發現離群值，就應立即刪除。',
        B: '離群值對所有模型都有害，必須處理。',
        C: '需要仔細甄別，因為它們可能是重要的罕見事件，而不僅僅是噪聲。',
        D: '離群值只存在於數值數據中，類別數據沒有。'
      },
      correctAnswer: 'C',
      explanation: '處理離群值必須非常小心。一個極端值可能是輸入錯誤，但也可能是一個真實的、極具價值的信號（如信用卡交易中的一次詐欺行為）。輕易刪除可能導致重要資訊的丟失。'
    },
    {
      question: '下列哪一項關於數據準備的敘述是錯誤的？',
      options: {
        A: '處理缺失值時，可以用特徵的均值或中位數進行簡單插補。',
        B: '特徵工程極度依賴領域知識，是數據科學中的一門藝術。',
        C: '在深度學習時代，由於有端到端學習，手動特徵工程已完全不再重要。',
        D: '數據清洗的目標是處理數據中的錯誤、不一致和不準確之處。'
      },
      correctAnswer: 'C',
      explanation: '儘管深度學習模型能自動學習特徵，減少了部分手動特徵工程的需求，但富有洞察力的、基於領域知識的特徵工程，依然能夠顯著提升模型的性能，尤其是在數據量不是特別巨大的情況下。'
    }
  ],
  L21302: [
    {
      question: '將AI模型、程式碼及其所有依賴的函式庫、環境配置打包成一個輕量、可移植的標準化單元，這種技術稱為什麼？',
      options: {
        A: '虛擬化 (Virtualization)',
        B: '容器化 (Containerization)',
        C: '序列化 (Serialization)',
        D: '編譯 (Compilation)'
      },
      correctAnswer: 'B',
      explanation: '容器化（以Docker為代表）解決了軟體開發和部署中「在我電腦上可以跑」的經典問題。它將應用及其所有依賴打包在一起，確保了從開發到生產的環境一致性，是現代軟體部署和MLOps的基石。'
    },
    {
      question: '下列哪種模型部署模式最適合需要即時反饋的應用，如線上推薦系統或信用卡詐欺偵測？',
      options: {
        A: '批次預測 (Batch Prediction)',
        B: '線上即時預測 (Online Prediction)',
        C: '離線訓練 (Offline Training)',
        D: '邊緣部署 (Edge Deployment)'
      },
      correctAnswer: 'B',
      explanation: '線上即時預測模式將模型部署為一個持續運行的API服務，能夠隨時接收單筆請求並在毫秒級內返回預測結果，滿足了對低延遲有嚴格要求的應用場景。'
    },
    {
      question: 'MLOps的核心目標是什麼？',
      options: {
        A: '最大化單個模型的準確率。',
        B: '撰寫最詳細的技術文件。',
        C: '實現機器學習工作流程的自動化、標準化和可持續性。',
        D: '減少對GPU資源的使用。'
      },
      correctAnswer: 'C',
      explanation: 'MLOps旨在將DevOps的最佳實踐應用於機器學習領域，通過建立自動化的CI/CD/CT管道，來加速模型的迭代、提高部署的可靠性，並實現對已部署模型的全生命週期管理。'
    },
    {
      question: '將AI模型直接部署在手機、攝影機等終端設備上，在本地進行預測，這種模式被稱為什麼？',
      options: {
        A: '雲端部署 (Cloud Deployment)',
        B: '批次部署 (Batch Deployment)',
        C: '邊緣部署 (Edge Deployment)',
        D: 'API部署 (API Deployment)'
      },
      correctAnswer: 'C',
      explanation: '邊緣部署將計算推向數據產生的源頭，其主要優勢包括極低的延遲、節省網路頻寬以及更好地保護用戶隱私（因為數據無需上傳到雲端）。'
    },
    {
      question: '在MLOps中，CT (Continuous Training) 指的是什麼？',
      options: {
        A: '持續的程式碼測試 (Continuous Testing)',
        B: '持續的團隊溝通 (Continuous Talking)',
        C: '自動化的模型再訓練流程 (Continuous Training)',
        D: '持續的成本追蹤 (Continuous Tracking)'
      },
      correctAnswer: 'C',
      explanation: '持續訓練（CT）是MLOps相對於傳統DevOps所特有的概念。它指的是建立一個自動化的管道，能夠在監測到數據漂移或模型性能下降時，自動觸發模型的再訓練、驗證和重新部署流程。'
    },
    {
      question: 'Kubernetes (K8s) 在AI系統部署中扮演什麼角色？',
      options: {
        A: '一個用來編寫Python程式碼的IDE。',
        B: '一個用於自動化部署、擴展和管理大規模容器化應用的平台。',
        C: '一個專門用於訓練深度學習模型的函式庫。',
        D: '一個數據庫管理系統。'
      },
      correctAnswer: 'B',
      explanation: 'Kubernetes是一個容器編排平台。在AI系統中，它負責管理運行著AI模型的成百上千個Docker容器，處理負載均衡、服務發現、自動擴展和故障恢復等複雜的維運工作。'
    },
    {
      question: '對已部署的模型進行監控時，除了CPU使用率、延遲等系統指標，更重要的是監控哪類指標？',
      options: {
        A: '程式碼的行數。',
        B: '模型的預測準確率、數據分佈漂移等性能指標。',
        C: '開發團隊成員的數量。',
        D: '專案的總預算。'
      },
      correctAnswer: 'B',
      explanation: '一個系統運行正常的「殭屍模型」可能正在持續地做出錯誤的預測。因此，對模型本身的性能指標（如準確率）和輸入數據的統計分佈進行監控，是及時發現模型因數據漂移而失效的關鍵。'
    },
    {
      question: '下列何者是手動、非自動化的模型部署流程可能帶來的最大問題？',
      options: {
        A: '可以確保最高的模型準確率。',
        B: '效率低下、容易出錯，且難以追溯和重現。',
        C: '完全不需要任何人力成本。',
        D: '可以非常快速地響應業務變化。'
      },
      correctAnswer: 'B',
      explanation: '手動部署流程充滿了人為錯誤的風險（如拷錯文件、配錯環境），整個過程耗時且不透明。當出現問題時，很難追溯是哪個環節出錯。MLOps的自動化管道正是為了解決這些問題。'
    },
    {
      question: '某銀行每晚利用AI模型對當天所有客戶的行為數據重新計算信用評分，並更新到資料庫中。這屬於哪種部署模式？',
      options: {
        A: '線上即時預測',
        B: '邊緣部署',
        C: '批次預測',
        D: '模型服務化'
      },
      correctAnswer: 'C',
      explanation: '批次預測的特點是定期、對累積的一大批數據進行處理，不要求即時性。這種按計畫運行的、高吞吐量的處理模式非常適合報表生成、數據同步、批量評分等場景。'
    },
    {
      question: '下列哪一項不是容器化技術（如Docker）為AI模型部署帶來的好處？',
      options: {
        A: '保證了開發、測試和生產環境的一致性。',
        B: '簡化了對複雜依賴庫的管理。',
        C: '自動提升模型的預測準確率。',
        D: '使得模型可以輕鬆地在不同雲平台之間遷移。'
      },
      correctAnswer: 'C',
      explanation: '容器化是一項解決環境配置和依賴問題的部署技術，它能確保模型穩定運行，但它本身不會對模型的演算法或預測準確率產生任何影響。模型的準確率取決於數據和訓練過程。'
    }
  ]
};
