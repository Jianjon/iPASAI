
import type { PracticeQuestion } from '../../types';

export const L21_PRACTICE: Record<string, PracticeQuestion[]> = {
  L21101: [
    {
      question: '關於Transformer模型中的自注意力機制(Self-Attention)，下列敘述何者正確？',
      options: {
        A: '只能處理序列中相鄰詞彙的關係。',
        B: '計算成本隨序列長度呈線性增長。',
        C: '使得模型可以進行大規模平行運算。',
        D: '主要用於自然語言生成，而非理解。'
      },
      correctAnswer: 'C',
      explanation: '自注意力機制的核心優勢在於它能一步到位地計算序列中所有詞彙之間的相互影響，這種計算可以大規模並行化，極大地提高了訓練效率。它能捕捉長距離依賴，不僅限於相鄰詞彙，且計算成本随序列長度呈二次方增長。'
    },
    {
      question: '某客服中心希望從大量的客戶通話錄音轉譯文本中，自動識別出客戶提到的產品型號與問題類型。此任務最核心的NLP技術是？',
      options: {
        A: '情感分析 (Sentiment Analysis)',
        B: '機器翻譯 (Machine Translation)',
        C: '命名實體識別 (Named Entity Recognition)',
        D: '文本摘要 (Text Summarization)'
      },
      correctAnswer: 'C',
      explanation: '命名實體識別（NER）專門用於從文本中識別和分類預先定義好的實體，如人名、地名、組織名，以及此處的「產品型號」和「問題類型」。'
    },
    {
      question: '在比較傳統詞向量(Word Embedding)如Word2Vec與基於Transformer的BERT模型時，BERT最主要的優勢為何？',
      options: {
        A: '訓練速度更快。',
        B: '能處理一詞多義的問題，根據上下文生成不同的詞向量。',
        C: '模型參數較少，對硬體要求較低。',
        D: '不需要大量的訓練數據。'
      },
      correctAnswer: 'B',
      explanation: 'BERT是基於上下文的動態詞向量模型。與Word2Vec為每個詞生成固定向量不同，BERT會根據詞彙在句子中的具體上下文，生成不同的向量表示，從而有效地解決了「bank」可以指銀行也可以指河岸這樣的一詞多義問題。'
    },
    {
      question: '自然語言理解 (NLU) 與自然語言生成 (NLG) 的主要區別是什麼？',
      options: {
        A: 'NLU負責將文本轉為語音，NLG負責將語音轉為文本。',
        B: 'NLU是關於理解語言的意義，NLG是關於創造自然的語言文本。',
        C: 'NLU使用Transformer，NLG使用RNN。',
        D: '兩者沒有本質區別，只是應用的名稱不同。'
      },
      correctAnswer: 'B',
      explanation: 'NLU (Natural Language Understanding) 的核心是「讀懂」，即將非結構化的語言輸入轉化為結構化的意義表示；而NLG (Natural Language Generation) 的核心是「寫作」或「說話」，即將結構化的資訊轉化為人類可讀的自然語言。'
    },
    {
      question: '在中文自然語言處理中，通常第一個關鍵步驟是什麼？',
      options: {
        A: '命名實體識別 (NER)',
        B: '情感分析',
        C: '斷詞 (Tokenization)',
        D: '詞性標註 (POS Tagging)'
      },
      correctAnswer: 'C',
      explanation: '與英文不同，中文句子中的詞與詞之間沒有空格分隔，因此在進行任何後續分析之前，必須先將連續的句子切分成有意義的詞彙單位，這個過程稱為斷詞。'
    },
    {
      question: '聊天機器人(Chatbot)為了理解使用者的主要目的（例如，查詢訂單、預約服務），最需要依賴下列哪項NLU技術？',
      options: {
        A: '詞向量 (Word Embedding)',
        B: '意圖識別 (Intent Recognition)',
        C: '文本摘要',
        D: '機器翻譯'
      },
      correctAnswer: 'B',
      explanation: '意圖識別是聊天機器人系統的核心，它專門用來判斷用戶輸入的一段話背後的主要意圖或目的，以便系統能觸發對應的處理流程。'
    },
    {
      question: '下列何者是範本式(Template-based)自然語言生成的主要缺點？',
      options: {
        A: '生成速度非常慢',
        B: '需要大量的計算資源',
        C: '生成的文本缺乏靈活性和多樣性',
        D: '無法保證語法的正確性'
      },
      correctAnswer: 'C',
      explanation: '範本式生成依賴預先定義好的句子框架，雖然可靠且語法正確，但生成的內容非常固定，缺乏變化和自然的感覺，無法應對複雜或未預料到的情況。'
    },
    {
      question: '「模型可能從訓練數據中學到並放大了社會上已存在的性別或種族偏見。」這個問題描述了NLP領域的哪一項主要挑戰？',
      options: {
        A: '語言歧義性',
        B: '計算資源限制',
        C: '演算法偏見',
        D: '缺乏常識'
      },
      correctAnswer: 'C',
      explanation: '這正是演算法偏見（Algorithmic Bias）的典型例子。如果訓練數據本身就帶有偏見，AI模型會忠實地學習這些偏見，並可能在應用中重現甚至加劇不公平的現象。'
    },
    {
      question: '下列哪一項技術最能體現「將詞彙映射到高維向量空間，使語義相近的詞在空間中也相近」的概念？',
      options: {
        A: '詞性標註 (POS Tagging)',
        B: '命名實體識別 (NER)',
        C: '斷詞 (Tokenization)',
        D: '詞向量 (Word Embedding)'
      },
      correctAnswer: 'D',
      explanation: '詞向量（如Word2Vec, GloVe）的核心思想就是為每個詞學習一個數值向量，這個向量能夠捕捉詞的語義資訊。在向量空間中，「國王」和「皇后」的向量會比「國王」和「香蕉」的向量更接近。'
    },
    {
      question: '為何說大型預訓練語言模型（PLM）的出現，改變了NLP領域的研究與應用範式？',
      options: {
        A: '它們完全解決了語言歧義性問題。',
        B: '它們可以透過在特定任務上進行微調（Fine-tuning），只需少量標籤數據就能達到很好的效果。',
        C: '它們的訓練完全不需要GPU。',
        D: '它們的體積非常小，可以輕鬆部署在任何設備上。'
      },
      correctAnswer: 'B',
      explanation: '預訓練-微調（Pre-train and Fine-tune）範式是現代NLP的核心。大型模型在海量無標籤數據上學到通用語言知識後，可以像一個知識淵博的「通才」，只需少量特定領域的數據就能快速適應新任務，大大降低了對大量標籤數據的依賴。'
    },
    {
        question: '在詞向量(Word Embedding)技術中，Word2Vec, GloVe, 和 fastText這類演算法的主要貢獻是什麼？',
        options: {
            A: '它們能將詞彙轉換為獨熱編碼(One-Hot Encoding)。',
            B: '它們能捕捉詞彙之間的語義關係，將詞彙表示為密集向量。',
            C: '它們專門用於計算句子的文法結構。',
            D: '它們能完美解決所有語言的歧義性問題。'
        },
        correctAnswer: 'B',
        explanation: '詞向量技術的核心是將詞彙從稀疏的獨熱表示，轉換為低維、密集的向量，這個向量能夠捕捉到詞彙的語義資訊（例如，「國王」-「男人」+「女人」≈「皇后」）。'
    },
    {
        question: '一個法律科技(LegalTech)公司開發AI工具，自動從合約中抽取「賠償上限」、「保密期限」等關鍵條款，這主要應用了哪項NLP技術？',
        options: {
            A: '關係抽取 (Relation Extraction)',
            B: '意圖識別 (Intent Recognition)',
            C: '句法分析 (Syntactic Parsing)',
            D: '命名實體識別 (Named Entity Recognition)'
        },
        correctAnswer: 'D',
        explanation: '此場景中，「賠償上限」、「保密期限」等都是預先定義好的特定實體類型，因此使用NER技術來識別和抽取它們是最直接有效的方法。'
    },
    {
        question: '在NLU的多層次分析中，哪一層專注於分析句子的文法結構，例如建構依存句法樹？',
        options: {
            A: '詞法分析 (Lexical Analysis)',
            B: '句法分析 (Syntactic Parsing)',
            C: '語義分析 (Semantic Analysis)',
            D: '語用分析 (Pragmatic Analysis)'
        },
        correctAnswer: 'B',
        explanation: '句法分析專門處理句子的文法結構，確定詞語之間的修飾、主從等關係，是理解句子結構的關鍵步驟。'
    },
    {
        question: '下列關於大型語言模型(LLM)的敘述何者錯誤？',
        options: {
            A: '它們通常基於Transformer架構。',
            B: '它們的訓練需要極其龐大的計算資源。',
            C: '它們完全沒有演算法偏見的問題。',
            D: '它們可能產生與事實不符的內容(幻覺)。'
        },
        correctAnswer: 'C',
        explanation: '大型語言模型是從海量的網路文本中學習的，這些文本不可避免地包含了人類社會的各種偏見。因此，LLM不僅存在偏見問題，還可能將其放大，這是AI倫理中的一個重大挑戰。'
    },
    {
        question: '從「蘋果公司在加州成立」這句話中，抽取出（蘋果公司，成立於，加州）這樣的資訊三元組，這個任務被稱為什麼？',
        options: {
            A: '情感分析',
            B: '主題模型',
            C: '關係抽取',
            D: '文本分類'
        },
        correctAnswer: 'C',
        explanation: '關係抽取是在識別出命名實體（如蘋果公司、加州）之後，進一步判斷這些實體之間存在的語義關係，是構建知識圖譜的關鍵技術。'
    },
    {
        question: '自然語言生成(NLG)的技術中，哪種方法效果最好，是當前的主流？',
        options: {
            A: '範本式生成',
            B: '統計式生成',
            C: '基於規則的生成',
            D: '基於神經網路的生成'
        },
        correctAnswer: 'D',
        explanation: '基於神經網路（特別是Transformer模型）的生成方法，能夠端到端地學習數據到文本的複雜映射，生成的文本在流暢度、多樣性和語義準確性上都遠超傳統方法。'
    },
    {
        question: '文本摘要(Summarization)技術可以分為抽取式和生成式，兩者的主要區別是什麼？',
        options: {
            A: '抽取式速度快，生成式準確率高。',
            B: '抽取式從原文中挑選關鍵句子，生成式用自己的話重新生成摘要。',
            C: '抽取式需要大量標註數據，生成式不需要。',
            D: '抽取式用於長文本，生成式用於短文本。'
        },
        correctAnswer: 'B',
        explanation: '這是兩者最根本的區別。抽取式摘要的內容完全來自原文，而生成式摘要則涉及對原文的深度理解和轉述，更接近人類的摘要方式。'
    },
    {
        question: '一個AI系統能夠將使用者「幫我訂一張明天到高雄的高鐵票」的語音指令，轉換為結構化的訂票請求 { "交通工具": "高鐵", "目的地": "高雄", "日期": "明天" }。這個過程主要屬於？',
        options: {
            A: '自然語言理解 (NLU)',
            B: '自然語言生成 (NLG)',
            C: '語音合成 (TTS)',
            D: '文本摘要'
        },
        correctAnswer: 'A',
        explanation: '這個過程的核心是「理解」非結構化的自然語言，並將其轉換為電腦可以處理的結構化格式，是典型的NLU任務。'
    },
    {
        question: '下列何者是NLP技術在醫療領域的典型應用？',
        options: {
            A: '自動控制手術機器人。',
            B: '從電子病歷中自動抽取出症狀、藥品等關鍵資訊。',
            C: '分析醫療影像判斷是否有腫瘤。',
            D: '預測醫院的電力消耗。'
        },
        correctAnswer: 'B',
        explanation: '醫療領域存在大量的非結構化文本資料（如病歷、研究論文），利用NLP的NER和關係抽取等技術可以從中挖掘巨大價值，輔助臨床研究與診斷。'
    },
    {
        question: 'BERT (Bidirectional Encoder Representations from Transformers) 模型特別擅長於哪一類NLP任務？',
        options: {
            A: '文本生成 (Text Generation)',
            B: '自然語言理解 (Natural Language Understanding)',
            C: '機器翻譯 (Machine Translation)',
            D: '語音識別 (Speech Recognition)'
        },
        correctAnswer: 'B',
        explanation: 'BERT採用了僅編碼器(Encoder-only)架構和遮罩語言模型(MLM)任務，使其能夠在預訓練中同時考慮上下文的左右兩側資訊，這種雙向學習的能力讓它在各種理解類任務（如分類、NER）上表現極其出色。'
    },
    {
        question: '下列哪項不是NLP技術面臨的主要挑戰？',
        options: {
            A: '語言的歧義性和模糊性。',
            B: '缺乏足夠的硬體計算能力。',
            C: '模型缺乏真實世界的常識和推理能力。',
            D: '對於資源較少的語言，缺乏足夠的訓練數據。'
        },
        correctAnswer: 'B',
        explanation: '雖然訓練大型模型需要大量資源，但NLP面臨的根本挑戰更多是在於語言本身的複雜性、常識推理的困難以及數據的可用性，而非硬體計算能力的缺乏。'
    },
    {
        question: '一個HR部門使用AI工具分析視訊面試的錄音轉譯稿，來評估候選人的用詞和情緒。這主要應用了NLP的哪些技術？',
        options: {
            A: '機器翻譯和文本摘要',
            B: '語音識別(ASR)和情感分析(Sentiment Analysis)',
            C: '意圖識別和關係抽取',
            D: '斷詞和詞性標註'
        },
        correctAnswer: 'B',
        explanation: '這個應用首先需要將語音轉為文字（ASR），然後再對文字內容進行情感傾向的分析（情感分析），是一個典型的多步驟NLP應用流程。'
    },
    {
        question: 'GPT (Generative Pre-trained Transformer) 系列模型採用了哪種Transformer架構？',
        options: {
            A: '僅編碼器 (Encoder-only)',
            B: '僅解碼器 (Decoder-only)',
            C: '編碼器-解碼器 (Encoder-Decoder)',
            D: '卷積-解碼器 (CNN-Decoder)'
        },
        correctAnswer: 'B',
        explanation: 'GPT系列模型的核心是文本生成，因此它們採用了僅解碼器架構，這種架構非常適合自回歸式的、從左到右的文本生成任務。'
    },
    {
        question: '為什麼需要對詞向量進行降維？',
        options: {
            A: '高維向量無法表示語義關係。',
            B: '高維向量計算成本高，且容易導致維度災難。',
            C: '降維後可以提升模型的準確率。',
            D: '降維是為了讓人類更容易理解。'
        },
        correctAnswer: 'B',
        explanation: '詞向量的維度通常很高（如300維），直接使用可能帶來巨大的計算負擔並增加過擬合風險。透過降維技術可以保留主要語義資訊，同時降低複雜度。'
    },
    {
        question: '情感分析(Sentiment Analysis)的主要目標是什麼？',
        options: {
            A: '分析文本的作者是誰。',
            B: '分析文本的主題是什麼。',
            C: '分析文本所表達的情感傾向（如正面、負面、中性）。',
            D: '分析文本的語法是否正確。'
        },
        correctAnswer: 'C',
        explanation: '情感分析，或稱意見探勘，是NLP的一個重要分支，專門用來自動化地判斷文本中的主觀情感色彩。'
    },
    {
        question: '「可解釋性」在NLP領域為何重要？',
        options: {
            A: '它能讓模型運行得更快。',
            B: '在高風險決策場景（如法律、金融），我們需要理解模型為何做出特定判斷。',
            C: '可解釋的模型更容易被駭客攻擊。',
            D: '它能自動修正模型中的偏見。'
        },
        correctAnswer: 'B',
        explanation: '當NLP模型被用於影響人的重要決策時，其決策過程不能是一個黑箱。可解釋性是建立信任、進行除錯和確保問責性的關鍵。'
    },
    {
        question: '下列何者是T5 (Text-to-Text Transfer Transformer)模型的主要特點？',
        options: {
            A: '它只能用於文本分類任務。',
            B: '它將所有NLP任務都統一為文本到文本的格式。',
            C: '它是一個非常小的模型，適合在邊緣設備上運行。',
            D: '它完全拋棄了注意力機制。'
        },
        correctAnswer: 'B',
        explanation: 'T5模型的創新之處在於提出了一個統一的框架，將分類、摘要、翻譯等所有不同的NLP任務，都轉換為輸入一段文本、輸出一端文本的形式，簡化了模型設計。'
    },
    {
        question: '在製造業中，建立一個基於NLP的智能搜尋引擎來查詢設備維修手冊，主要的好處是什麼？',
        options: {
            A: '可以完全取代維修工程師。',
            B: '可以有效傳承隱性知識，縮短故障排除時間。',
            C: '可以讓維修手冊的內容變得更複雜。',
            D: '可以增加設備的故障率。'
        },
        correctAnswer: 'B',
        explanation: '這種應用可以將老師傅的經驗和分散的文件知識，轉化為一個可被快速檢索的知識庫，讓新進工程師也能快速上手，實現知識的有效傳承。'
    },
    {
        question: '一個NLP模型在處理「The cat sat on the mat」這句話時，標示出「The」是冠詞，「cat」是名詞，「sat」是動詞。這個過程稱為什麼？',
        options: {
            A: '斷詞 (Tokenization)',
            B: '詞性標註 (POS Tagging)',
            C: '命名實體識別 (NER)',
            D: '句法分析 (Syntactic Parsing)'
        },
        correctAnswer: 'B',
        explanation: '詞性標註（Part-of-Speech Tagging）的任務就是為句子中的每個詞彙標示其對應的詞性，這是進行後續句法和語義分析的基礎步驟。'
    },
    {
        question: 'NLP中的「語言模型(Language Model)」最基礎的任務是什麼？',
        options: {
            A: '判斷一句話的情感。',
            B: '計算一個句子出現的機率，或預測下一個最可能出現的詞。',
            C: '將一個句子翻譯成另一種語言。',
            D: '識別句子中的專有名詞。'
        },
        correctAnswer: 'B',
        explanation: '語言模型的核心是學習語言的統計規律。透過計算一個詞序列的機率，它可以被用於各種任務，最基礎的就是預測下一個詞，這也是大型語言模型預訓練的核心任務。'
    },
    {
        question: '下列哪項是NLP在金融業的應用？',
        options: {
            A: '分析CT掃描影像。',
            B: '控制產線上的機器手臂。',
            C: '監控社群媒體對特定股票的情緒，輔助投資決策。',
            D: '預測天氣。'
        },
        correctAnswer: 'C',
        explanation: '金融市場的情緒對價格有很大影響。利用NLP的情感分析技術，可以大規模、即時地分析新聞和社群媒體上的輿情，將其量化為投資信號，是量化交易中的一個重要應用。'
    },
    {
        question: '為何說Transformer架構的出現是NLP領域的革命性突破？',
        options: {
            A: '因為它的程式碼最少。',
            B: '因為它能更有效地捕捉長距離依賴關係，且能大規模並行計算。',
            C: '因為它是由一位著名的科學家發明的。',
            D: '因為它完全解決了AI倫理問題。'
        },
        correctAnswer: 'B',
        explanation: 'Transformer透過自注意力機制解決了RNN難以處理長距離依賴的問題，同時其非序列化的計算方式又極大地提升了訓練效率，這兩個優勢的結合，直接催生了後續所有大型語言模型的發展。'
    }
  ],
  L21102: [
    {
      question: '下列哪一項電腦視覺任務，旨在對影像中的每一個像素點都進行分類，並區分出同類別的不同實例（例如，標示出圖中的「第一隻貓」和「第二隻貓」）？',
      options: {
        A: '影像分類 (Image Classification)',
        B: '物件偵測 (Object Detection)',
        C: '語意分割 (Semantic Segmentation)',
        D: '實例分割 (Instance Segmentation)'
      },
      correctAnswer: 'D',
      explanation: '實例分割是電腦視覺中最精細的任務，它不僅需要像語意分割那樣為每個像素分類，還需要區分開屬於同一類別的不同個體。'
    },
    {
      question: '一個需要部署在邊緣設備（如無人機）上進行即時障礙物識別的系統，在選擇物件偵測模型時，應優先考量下列何者？',
      options: {
        A: '模型的偵測精確率（mAP）',
        B: '模型的推論速度（FPS）',
        C: '模型的可解釋性',
        D: '模型的訓練資料量'
      },
      correctAnswer: 'B',
      explanation: '對於邊緣設備和即時應用場景，模型的推論速度（每秒能處理的幀數，FPS）是關鍵限制因素。像YOLO這樣的單階段模型因其高速度而常被選用，即使其精確率可能略低於某些兩階段模型。'
    },
    {
      question: '關於卷積神經網路（CNN）的核心特性，下列敘述何者錯誤？',
      options: {
        A: '透過權重共享（Weight Sharing）大幅減少模型參數。',
        B: '擅長捕捉圖像的局部空間特徵。',
        C: 'ResNet透過殘差學習解決了深度網路的梯度消失問題。',
        D: 'CNN的性能與網路深度成反比，越淺越好。'
      },
      correctAnswer: 'D',
      explanation: '一般來說，在一定範圍內，增加CNN的深度可以讓模型學習到更複雜、更抽象的特徵，從而提升性能。ResNet的出現更是讓訓練非常深的網路成為可能。因此「越淺越好」是錯誤的。'
    },
    {
      question: 'YOLO (You Only Look Once) 系列演算法屬於下列哪一類物件偵測方法？',
      options: {
        A: '兩階段 (Two-stage) 方法',
        B: '單階段 (One-stage) 方法',
        C: '基於候選區域的方法',
        D: '基於影像分割的方法'
      },
      correctAnswer: 'B',
      explanation: 'YOLO是單階段偵測器的代表，它將物件偵測視為一個單一的迴歸問題，直接從整個圖像中預測邊界框和類別機率，因此速度非常快。'
    },
    {
      question: '在醫療影像分析中，U-Net模型特別適用於下列哪項任務？',
      options: {
        A: '計算影像中的細胞數量',
        B: '判斷X光片是否有骨折',
        C: '從CT掃描中精確分割出腫瘤區域',
        D: '對醫療報告進行分類'
      },
      correctAnswer: 'C',
      explanation: 'U-Net是一種專為生物醫學影像分割設計的CNN架構，其獨特的U形結構和跳躍連接能很好地結合深層語義特徵和淺層細節特徵，實現像素級的精確分割。'
    },
    {
      question: '下列哪個經典CNN模型，透過引入「殘差連接」(Residual Connection) 成功解決了深度網路訓練時的梯度消失問題？',
      options: {
        A: 'AlexNet',
        B: 'VGGNet',
        C: 'LeNet-5',
        D: 'ResNet'
      },
      correctAnswer: 'D',
      explanation: 'ResNet（殘差網路）的核心創新是引入了「捷徑連接」或「殘差塊」，允許梯度在反向傳播時可以「跳過」某些層直接向後傳遞，極大地緩解了梯度消失問題，使得訓練數百甚至上千層的超深度網路成為可能。'
    },
    {
      question: '物件偵測 (Object Detection) 與影像分類 (Image Classification) 最主要的區別是什麼？',
      options: {
        A: '物件偵測只能識別一種物體，影像分類可以識別多種。',
        B: '物件偵測不僅要識別物體類別，還要標示出其在圖像中的位置。',
        C: '物件偵測使用CNN，影像分類使用RNN。',
        D: '兩者在任務目標上沒有區別。'
      },
      correctAnswer: 'B',
      explanation: '影像分類的任務是回答「圖中有什麼？」（例如，貓），而物件偵測更進一步，需要回答「圖中的物體在哪裡，以及它們是什麼？」（例如，在左上角有一隻貓）。因此，物件偵測的輸出包含了類別標籤和位置邊界框。'
    },
    {
      question: '在圖像中加入人眼無法察覺的微小擾動，卻能導致模型做出完全錯誤的判斷，這種現象被稱為什麼？',
      options: {
        A: '遮擋 (Occlusion)',
        B: '數據偏見 (Data Bias)',
        C: '對抗性攻擊 (Adversarial Attack)',
        D: '模型退化 (Model Degradation)'
      },
      correctAnswer: 'C',
      explanation: '對抗性攻擊是深度學習模型的一個重要安全漏洞。攻擊者可以精心設計微小的、有針對性的噪聲疊加到原始圖像上，生成一個「對抗樣本」，這個樣本在人眼看來與原圖無異，但能讓模型產生高信心的錯誤預測。'
    },
    {
      question: '語意分割 (Semantic Segmentation) 和實例分割 (Instance Segmentation) 的共同點是什麼？',
      options: {
        A: '它們都能區分同類別的不同個體。',
        B: '它們的輸出都只是物體的邊界框。',
        C: '它們都對圖像中的每個像素進行分類。',
        D: '它們都無法處理被遮擋的物體。'
      },
      correctAnswer: 'C',
      explanation: '兩者的共同點在於它們都是像素級的預測任務，目標是為圖像中的每一個像素點分配一個類別標籤。它們的區別在於，實例分割在此基礎上，還需要區分出同類別的不同個體（instance）。'
    },
    {
      question: 'GoogLeNet (Inception) 模型架構最主要的創新是什麼？',
      options: {
        A: '使用了非常深的網路結構。',
        B: '引入了殘差連接。',
        C: '在同一層中並行使用不同尺寸的卷積核來提取特徵，提高了網路的效率和性能。',
        D: '它是第一個使用ReLU激活函數的模型。'
      },
      correctAnswer: 'C',
      explanation: 'Inception模組的核心思想是在網路的同一層級中，同時使用1x1、3x3、5x5等多種不同尺度的卷積核，並將它們的輸出拼接起來，讓網路可以自適應地學習要使用哪種尺度的特徵，從而提升了性能和計算效率。'
    },
    {
        question: '在製造業的自動光學檢測(AOI)中，利用電腦視覺即時檢測產品是否有微小瑕疵，這取代了傳統的哪項工作？',
        options: {
            A: '產品設計',
            B: '人工目視檢測',
            C: '產線排程',
            D: '供應鏈管理'
        },
        correctAnswer: 'B',
        explanation: '傳統的品質檢測高度依賴人工目檢，這項工作耗時、易疲勞且標準不一。AI驅動的AOI可以實現24小時不間斷、高精度、高一致性的自動化檢測。'
    },
    {
        question: '下列何者是電腦視覺面臨的主要技術挑戰？',
        options: {
            A: '處理器的計算速度不夠快。',
            B: '儲存圖像的硬碟空間不足。',
            C: '視角、光照、遮擋等因素導致同一物體成像差異巨大。',
            D: '缺乏足夠的開源模型。'
        },
        correctAnswer: 'C',
        explanation: '真實世界的視覺環境是複雜多變的。如何讓模型學習到對這些無關變換保持不變的、穩健的物體特徵，是電腦視覺領域一個長期且核心的挑戰。'
    },
    {
        question: '電腦視覺在農業科技的應用，不包含下列何者？',
        options: {
            A: '利用無人機影像監測作物生長狀況。',
            B: '自動計數果樹上的水果數量以預估產量。',
            C: '利用影像分割區分作物與雜草，以實現精準除草。',
            D: '分析土壤的化學成分。'
        },
        correctAnswer: 'D',
        explanation: '分析土壤的化學成分需要化學感測器，而非電腦視覺技術。A, B, C 都是典型的利用視覺資訊來優化農業生產的應用。'
    },
    {
        question: 'Mask R-CNN 是一個代表性的電腦視覺模型，它主要用於完成哪項任務？',
        options: {
            A: '影像分類',
            B: '物件偵測',
            C: '語意分割',
            D: '實例分割'
        },
        correctAnswer: 'D',
        explanation: 'Mask R-CNN 是實例分割領域的里程碑式工作。它在物件偵測模型（Faster R-CNN）的基礎上，巧妙地增加了一個用於生成像素級遮罩(mask)的分支，從而能同時完成偵測和分割任務。'
    },
    {
        question: '下列哪一項關於人臉辨識的倫理議題是正確的？',
        options: {
            A: '人臉辨識技術完全沒有偏見。',
            B: '大規模部署人臉辨識可能引發對個人隱私和政府監控的擔憂。',
            C: '人臉辨識的數據標註成本非常低。',
            D: '該技術的準確率與訓練數據的族群分佈無關。'
        },
        correctAnswer: 'B',
        explanation: '人臉辨識技術的濫用，可能導致無處不在的監控，侵犯個人隱私。此外，訓練數據的偏見可能導致模型對特定族群的識別率較低，產生歧視性後果。這些都是該技術面臨的嚴峻倫理挑戰。'
    },
    {
        question: '在CNN中，卷積核(Filter)的作用是什麼？',
        options: {
            A: '對圖像進行壓縮。',
            B: '作為一個特徵偵測器，用來識別圖像中的特定模式（如邊緣、紋理）。',
            C: '調整圖像的亮度和對比度。',
            D: '為圖像添加彩色。'
        },
        correctAnswer: 'B',
        explanation: '每個卷積核（或稱濾波器）都是一個小的權重矩陣，它在訓練過程中學會去偵測圖像中的某一種局部特徵。'
    },
    {
        question: '下列哪一項任務，其數據標註的成本通常是最高的？',
        options: {
            A: '影像分類',
            B: '物件偵測',
            C: '影像分割',
            D: '三者成本相近'
        },
        correctAnswer: 'C',
        explanation: '影像分類只需為整張圖標註一個類別。物件偵測需要標註物體的邊界框。而影像分割需要對圖像中的每一個像素進行精細的標註，其人力和時間成本遠高於前兩者。'
    },
    {
        question: '全景分割 (Panoptic Segmentation) 的目標是什麼？',
        options: {
            A: '只分割出圖像中的背景部分。',
            B: '結合了語意分割和實例分割，為每個像素都賦予類別和實例ID。',
            C: '專門用於分割全景照片。',
            D: '比物件偵測更快的偵測方法。'
        },
        correctAnswer: 'B',
        explanation: '全景分割旨在提供最全面的場景理解，它無縫地結合了語意分割（標出所有東西，如天空、道路）和實例分割（標出所有物體，如第一輛車、第二輛車），對圖像中的每一個像素都進行了全面的解析。'
    },
    {
        question: '下列哪個CNN模型以其極簡的設計（僅使用3x3卷積核）和非常深的結構而聞名？',
        options: {
            A: 'AlexNet',
            B: 'VGGNet',
            C: 'GoogLeNet',
            D: 'ResNet'
        },
        correctAnswer: 'B',
        explanation: 'VGGNet的設計哲學非常統一和優雅，它證明了透過堆疊非常小的3x3卷積核來構建深度網路，是一種非常有效的提升性能的策略。'
    },
    {
        question: '一個零售商店利用店內攝影機分析顧客的移動路線和在貨架前的停留時間，以優化商品陳列。這主要應用了電腦視覺的哪項技術？',
        options: {
            A: '影像分類',
            B: '物件偵測與追蹤',
            C: '光學字元辨識(OCR)',
            D: '人臉辨識'
        },
        correctAnswer: 'B',
        explanation: '這個應用需要先在影像中偵測到「顧客」這個物體，然後在連續的影像幀之間追蹤他們的移動軌跡，才能進行後續的行為分析。'
    },
    {
        question: 'Anchor-Free的物件偵測方法，與YOLO、SSD等基於Anchor的方法相比，其主要區別是什麼？',
        options: {
            A: 'Anchor-Free方法速度更快。',
            B: 'Anchor-Free方法不需要預設密密麻麻的錨框(Anchor Box)，而是直接預測物體的關鍵點。',
            C: 'Anchor-Free方法準確率更高。',
            D: 'Anchor-Free方法只能偵測小物件。'
        },
        correctAnswer: 'B',
        explanation: '傳統的偵測器依賴大量預設的、不同尺寸和比例的錨框來回歸物體位置，這引入了許多需要調整的超參數。Anchor-Free方法（如CenterNet）則試圖簡化這個流程，直接預測物體的中心點等關鍵資訊，使得設計更為簡潔。'
    },
    {
        question: '電腦視覺在安全監控領域的應用是什麼？',
        options: {
            A: '自動為監控影片配上背景音樂。',
            B: '自動偵測如人員跌倒、未戴安全帽、區域入侵等異常事件。',
            C: '提升監控攝影機的畫素。',
            D: '壓縮監控影片以節省儲存空間。'
        },
        correctAnswer: 'B',
        explanation: '智慧安防是電腦視覺的重要應用方向，它將傳統被動的錄影監控，變為主動的、即時的異常事件偵測與警報系統，大大提升了安全管理的效率。'
    },
    {
        question: '在CNN的架構中，哪一層負責減少特徵圖的空間尺寸（寬和高）？',
        options: {
            A: '卷積層 (Convolutional Layer)',
            B: '池化層 (Pooling Layer)',
            C: '全連接層 (Fully Connected Layer)',
            D: '激活函數層 (Activation Layer)'
        },
        correctAnswer: 'B',
        explanation: '池化層（如最大池化或平均池化）透過下採樣操作來降低特徵圖的維度，這有助於減少計算量並增加模型的平移不變性。'
    },
    {
        question: '下列何者不是CNN的典型應用？',
        options: {
            A: '人臉辨識',
            B: '自動駕駛中的車道線偵測',
            C: '醫療影像分析',
            D: '預測股票價格'
        },
        correctAnswer: 'D',
        explanation: 'CNN專門用於處理具有網格結構的數據（如圖像）。股票價格是時間序列數據，通常使用RNN、LSTM或Transformer等模型來處理。'
    },
    {
        question: 'VGGNet、GoogLeNet、ResNet等深度學習模型在哪個著名的圖像識別競賽中大放異彩？',
        options: {
            A: 'Kaggle',
            B: 'ImageNet Large Scale Visual Recognition Challenge (ILSVRC)',
            C: 'RoboCup',
            D: 'ACM ICPC'
        },
        correctAnswer: 'B',
        explanation: 'ImageNet競賽是推動電腦視覺領域發展的最重要的學術競賽之一，這些經典模型都是在該競賽中取得了突破性的成果。'
    },
    {
        question: '一個全卷積網路(FCN)的主要特點是什麼？',
        options: {
            A: '它只包含全連接層。',
            B: '它用卷積層取代了傳統CNN末尾的全連接層，使其能接受任意尺寸的輸入並輸出像素級的預測圖。',
            C: '它是一個非常淺的網路。',
            D: '它只能用於影像分類。'
        },
        correctAnswer: 'B',
        explanation: 'FCN是語意分割領域的開創性工作，其核心思想是將分類網路改造成一個端到端的、全卷積的網路，從而實現了像素到像素的密集預測。'
    },
    {
        question: '「權重共享(Weight Sharing)」是CNN的一個關鍵概念，其主要好處是什麼？',
        options: {
            A: '讓模型變得更深。',
            B: '大幅減少模型的參數數量，使其更容易訓練。',
            C: '讓模型可以處理彩色圖像。',
            D: '讓模型的訓練速度變慢。'
        },
        correctAnswer: 'B',
        explanation: '透過讓一個卷積核在整個圖像上共享同一組權重來偵測特徵，CNN避免了為每個像素位置都學習一組獨立的權重，從而極大地降低了模型的複雜度和參數數量。'
    },
    {
        question: '在一個物件偵測任務中，mAP (mean Average Precision) 是用來衡量什麼的指標？',
        options: {
            A: '模型的推論速度。',
            B: '模型的偵測精確率。',
            C: '模型的記憶體佔用。',
            D: '模型的訓練時間。'
        },
        correctAnswer: 'B',
        explanation: 'mAP是物件偵測領域最核心的性能評估指標，它綜合考慮了模型在所有類別上的精確率(Precision)和召回率(Recall)，能夠全面地衡量模型的偵測能力。'
    },
    {
        question: '下列哪項技術最適合用於從掃描的文件圖像中提取文字？',
        options: {
            A: '物件偵測',
            B: '實例分割',
            C: '光學字元辨識 (OCR)',
            D: '人臉辨識'
        },
        correctAnswer: 'C',
        explanation: 'OCR是電腦視覺的一個專門分支，致力於將圖像中的文字轉換為可編輯和可搜索的機器編碼文本。'
    },
    {
        question: 'AlexNet在2012年的成功，關鍵的貢獻不包含下列何者？',
        options: {
            A: '使用了更深的網路結構。',
            B: '使用了ReLU激活函數來加速訓練。',
            C: '使用了Dropout來防止過擬合。',
            D: '使用了殘差連接(Residual Connection)。'
        },
        correctAnswer: 'D',
        explanation: '殘差連接是ResNet在2015年提出的創新，用於解決更深網路的訓練問題。AlexNet的貢獻主要在於其深層架構、ReLU、Dropout和GPU的使用。'
    },
    {
        question: 'R-CNN系列的物件偵測方法被稱為「兩階段」方法，其第一階段的任務是什麼？',
        options: {
            A: '對整張圖像進行分類。',
            B: '找出可能包含物體的候選區域(Region Proposal)。',
            C: '對圖像進行分割。',
            D: '增強圖像的對比度。'
        },
        correctAnswer: 'B',
        explanation: '兩階段方法的第一步是透過一個快速的網路（如RPN）來篩選出數千個可能包含物體的區域，第二步再對這些區域進行精細的分類和定位，這種分而治之的策略通常能達到更高的精度。'
    },
    {
        question: '無人商店的自動結帳系統，需要精確識別顧客從貨架上拿取或放回了哪些商品，這最適合使用哪項電腦視覺技術？',
        options: {
            A: '影像分類',
            B: '實例分割',
            C: '人臉辨識',
            D: '情感分析'
        },
        correctAnswer: 'B',
        explanation: '這個場景需要像素級的精確識別，不僅要區分商品類別，還要區分同類商品的不同個體（例如，顧客拿的是第一瓶可樂還是第二瓶），這正是實例分割的應用場景。'
    }
  ],
  L21103: [
    {
      question: '下列哪項技術的核心原理，是透過一個「生成器」和一個「判別器」的相互博弈來學習數據分佈？',
      options: {
        A: '擴散模型 (Diffusion Models)',
        B: '大型語言模型 (LLMs)',
        C: '生成對抗網路 (GANs)',
        D: '卷積神經網路 (CNNs)'
      },
      correctAnswer: 'C',
      explanation: '生成對抗網路（GANs）的標誌性結構就是由一個負責創造假數據的生成器和一個負責分辨真假的判別器組成，兩者在競爭中共同進化。'
    },
    {
      question: '目前頂尖的文生圖（Text-to-Image）模型，如DALL-E 2、Stable Diffusion，其核心技術主要基於下列何者？',
      options: {
        A: '生成對抗網路 (GANs)',
        B: '擴散模型 (Diffusion Models)',
        C: '循環神經網路 (RNNs)',
        D: '決策樹 (Decision Trees)'
      },
      correctAnswer: 'B',
      explanation: '擴散模型透過一個「去噪」的過程，從隨機噪聲中逐步生成高品質的圖像，其生成圖像的品質和穩定性在近年來已經超越了GANs，成為SOTA文生圖模型的首選架構。'
    },
    {
      question: '大型語言模型（LLMs）如GPT系列，其驚人的語言能力主要來自於下列何者？',
      options: {
        A: '在高品質的人工標註數據集上進行監督學習。',
        B: '透過與人類進行大量對話來進行強化學習。',
        C: '在網際網路級別的海量文本上進行無監督的「預測下一個詞」任務。',
        D: '內建了完整的語法規則和知識圖譜。'
      },
      correctAnswer: 'C',
      explanation: 'LLMs的核心是預訓練（Pre-training）階段。在這個階段，模型透過一個看似簡單的自監督任務——預測文本序列中的下一個詞——從而從海量的無標籤文本中學到了豐富的語言模式、世界知識和一定的推理能力。'
    },
    {
      question: '「模型有時會一本正經地胡說八道，生成看似合理但事實上完全錯誤的資訊。」這個現象被稱為什麼？',
      options: {
        A: '模型偏見 (Bias)',
        B: '模式崩潰 (Mode Collapse)',
        C: '事實性錯誤或幻覺 (Hallucination)',
        D: '深度偽造 (Deepfake)'
      },
      correctAnswer: 'C',
      explanation: 'Hallucination（幻覺）是大型語言模型的一個主要問題，指的是模型生成了與事實不符、脫離現實或與源文本矛盾的內容。'
    },
    {
      question: 'GitHub Copilot這類AI程式碼助手，其背後的核心技術是什麼？',
      options: {
        A: '在大量演算法教科書上訓練的專家系統。',
        B: '將程式碼問題轉化為圖像進行分析的電腦視覺模型。',
        C: '在海量公開程式碼庫上訓練的大型語言模型。',
        D: '一個基於規則的語法檢查和修正引擎。'
      },
      correctAnswer: 'C',
      explanation: 'GitHub Copilot的核心是一個在數十億行公開程式碼上進行預訓練的大型語言模型（是GPT系列的一個變體）。它學會了程式碼的語法、模式和上下文，從而能夠根據註解或現有程式碼生成新的程式碼片段。'
    },
    {
      question: '下列何者是生成式AI帶來的倫理風險？',
      options: {
        A: '模型訓練需要消耗大量電力。',
        B: '生成逼真的偽造影像（Deepfake）可能被用於詐騙。',
        C: '模型可能會記住訓練數據中的個人隱私資訊。',
        D: '以上皆是。'
      },
      correctAnswer: 'D',
      explanation: '生成式AI的倫理風險是多方面的，A是環境與資源問題，B是濫用與社會安全問題，C是隱私問題。這些都是規劃和部署生成式AI應用時必須審慎考慮的因素。'
    },
    {
      question: '在生成對抗網路(GAN)中，生成器(Generator)和判別器(Discriminator)的角色是什麼？',
      options: {
        A: '生成器負責分類，判別器負責生成圖像。',
        B: '生成器試圖創造逼真的假數據，判別器試圖分辨真假。',
        C: '兩者合作，共同完成一個圖像修復任務。',
        D: '生成器是CNN，判別器是RNN。'
      },
      correctAnswer: 'B',
      explanation: 'GAN的運作機制是一個minimax賽局。生成器的目標是生成讓判別器無法分辨的假數據，而判別器的目標是盡可能準確地分辨出真實數據和生成器生成的假數據。'
    },
    {
      question: '擴散模型(Diffusion Model)生成圖像的基本過程是什麼？',
      options: {
        A: '從一張大圖中裁剪出一小塊。',
        B: '將多張現有圖片拼接組合而成。',
        C: '從一個隨機噪聲圖像開始，逐步去除噪聲來還原出一張清晰圖像。',
        D: '先生成圖像的輪廓，然後再逐步填充顏色和紋理。'
      },
      correctAnswer: 'C',
      explanation: '擴散模型的核心思想是一個反向的「去噪」過程。它學習如何從一個完全無序的隨機噪聲分佈中，一步步地、有控制地移除噪聲，最終生成一個結構清晰、內容豐富的圖像。'
    },
    {
      question: '關於生成式AI的智慧財產權問題，目前的普遍共識是什麼？',
      options: {
        A: 'AI生成的內容版權完全歸屬於AI模型本身。',
        B: 'AI生成的內容版權完全歸屬於AI公司的開發者。',
        C: 'AI生成的內容不受版權保護，屬於公共領域。',
        D: '版權歸屬在法律上仍是模糊地帶，各國規定不一。'
      },
      correctAnswer: 'D',
      explanation: '生成式AI內容的版權歸屬是一個非常複雜且懸而未決的法律問題。目前全球尚未形成統一的法律共識，不同國家的法院和版權局對此有不同的看法和判例，仍處於積極的討論和發展階段。'
    },
    {
      question: 'CycleGAN是一種特殊的GAN模型，其主要應用是什麼？',
      options: {
        A: '生成超高解析度的圖像。',
        B: '實現非成對的圖像到圖像翻譯，例如將斑馬變為馬。',
        C: '從文字生成圖像。',
        D: '提升模型的訓練穩定性。'
      },
      correctAnswer: 'B',
      explanation: 'CycleGAN的創新在於它不需要成對的訓練數據（例如，一張斑馬圖和一張對應的馬的圖），就能學習到兩個不同圖像域之間的映射關係，實現風格轉換或物體轉換。'
    },
    {
        question: '下列何者是DCGAN (深度卷積GAN) 的主要貢獻？',
        options: {
            A: '首次提出了GAN的概念。',
            B: '將CNN的架構引入GAN，大幅穩定訓練過程並提升了生成圖像的品質。',
            C: '實現了文字到圖像的生成。',
            D: '解決了模式崩潰(Mode Collapse)問題。'
        },
        correctAnswer: 'B',
        explanation: 'DCGAN是GAN發展史上的一個重要里程碑，它成功地將卷積神經網路的強大特徵提取能力與GAN的生成框架相結合，為後續更複雜的GAN架構奠定了基礎。'
    },
    {
        question: '在工業設計領域，生成式AI可以如何輔助設計師？',
        options: {
            A: '完全取代設計師的工作。',
            B: '只能生成2D的草圖，無法生成3D模型。',
            C: '根據功能需求和風格描述，快速產生多種不同的設計方案作為靈感。',
            D: '只能修改現有的設計，無法創造新的。'
        },
        correctAnswer: 'C',
        explanation: '生成式AI可以作為一個強大的「創意發想」工具，在設計的早期階段，快速、大規模地探索各種可能性，極大地擴展了設計師的創意廣度。'
    },
    {
        question: '生成式AI在教育領域的潛在應用是什麼？',
        options: {
            A: '取代所有的老師。',
            B: '為每個學生生成符合其學習進度的個人化練習題和解釋。',
            C: '自動為學生考試打分。',
            D: '監控學生是否在課堂上專心聽講。'
        },
        correctAnswer: 'B',
        explanation: '生成式AI有望實現真正的個人化教育，它可以根據每個學生的知識弱點和學習風格，動態地生成最適合他們的學習材料，實現因材施教。'
    },
    {
        question: '什麼是「深度偽造 (Deepfake)」？',
        options: {
            A: '一種非常逼真的繪畫風格。',
            B: '利用生成式AI，將一個人的臉或聲音合成到另一個人的影片或音訊中。',
            C: '一個專門用於檢測假新聞的AI模型。',
            D: '一個編寫得非常糟糕的電腦程式。'
        },
        correctAnswer: 'B',
        explanation: 'Deepfake是生成式AI最主要的負面應用之一，它透過生成逼真的偽造影像或音訊，可能被用於詐騙、誹謗、製造假新聞等，帶來嚴重的社會風險。'
    },
    {
        question: 'StyleGAN模型的主要特點是什麼？',
        options: {
            A: '訓練速度非常快。',
            B: '能對生成圖像的風格進行精細、分層的控制。',
            C: '模型非常小，適合在手機上運行。',
            D: '它是一個開源模型。'
        },
        correctAnswer: 'B',
        explanation: 'StyleGAN在生成人臉等圖像時，可以對高層次的屬性（如髮型、年齡）和細節（如皮膚紋理）進行解耦和獨立控制，提供了前所未有的生成可控性。'
    },
    {
        question: '大型語言模型(LLM)的「更新與時效性」問題指的是什麼？',
        options: {
            A: '模型的軟體版本需要經常更新。',
            B: '模型的知識被凍結在訓練數據的時間點，無法即時獲取最新資訊。',
            C: '模型的回應速度會隨著時間變慢。',
            D: '模型需要每年重新訓練一次。'
        },
        correctAnswer: 'B',
        explanation: '大多數LLM的知識是靜態的，它們不知道其訓練數據截止日期之後發生的任何事情。這是在使用它們回答關於近期事件的問題時，必須注意的一個重要限制。'
    },
    {
        question: '在遊戲產業，生成式AI可以被用來做什麼？',
        options: {
            A: '為玩家提供外掛程式。',
            B: '即時創造獨特的遊戲場景、NPC對話和動態任務。',
            C: '預測遊戲的銷售量。',
            D: '設計遊戲主機的硬體。'
        },
        correctAnswer: 'B',
        explanation: '生成式AI為實現動態、非線性的遊戲體驗提供了可能。它可以即時生成內容，讓每個玩家的體驗都是獨一無二的，大大增加了遊戲的重玩價值。'
    },
    {
        question: '下列何者是生成式AI應用(AIGC)在內容創作與行銷領域的主要價值？',
        options: {
            A: '完全取代人類的創意。',
            B: '大幅縮短創意發想時間，提升內容生產的效率和規模。',
            C: '保證生成的內容100%原創且無版權問題。',
            D: '降低內容的品質。'
        },
        correctAnswer: 'B',
        explanation: 'AIGC工具可以作為人類創作者的「加速器」和「靈感來源」，幫助他們快速生成初稿、探索多種方案，從而從重複性的工作中解放出來，專注於更高層次的創意策略。'
    },
    {
        question: '生成式AI的「可控性」問題指的是什麼？',
        options: {
            A: '使用者無法控制模型的開關。',
            B: '生成的內容有時難以精確控制其細節、風格和語氣。',
            C: '模型的程式碼無法被修改。',
            D: '模型的訓練過程無法被中斷。'
        },
        correctAnswer: 'B',
        explanation: '雖然我們可以透過提示工程來引導模型，但要對生成內容的每一個細節都進行像素級或詞語級的精確控制，目前仍然是一個技術挑戰。'
    },
    {
        question: 'AI音樂生成工具（如Suno）可以完成什麼任務？',
        options: {
            A: '只能生成古典音樂。',
            B: '只能生成沒有人聲的伴奏。',
            C: '可以根據用戶輸入的風格和歌詞，創作出包含人聲、伴奏的完整歌曲。',
            D: '只能分析現有歌曲的曲式。'
        },
        correctAnswer: 'C',
        explanation: '現代的AI音樂生成工具已經非常強大，它們可以處理從作詞、作曲、編曲到人聲合成的全鏈路任務，大大降低了音樂創作的門檻。'
    },
    {
        question: '影片生成模型（如Sora）的出現，為哪個行業帶來了新的可能性？',
        options: {
            A: '餐飲業',
            B: '金融業',
            C: '影音媒體與電影預製作',
            D: '房地產業'
        },
        correctAnswer: 'C',
        explanation: '文生影片模型可以讓創作者快速地將劇本或概念視覺化，為短片創作、廣告製作、電影特效預覽等帶來革命性的效率提升。'
    },
    {
        question: '下列何者不是生成式AI的技術限制？',
        options: {
            A: '事實性錯誤 (Hallucination)',
            B: '可控性與一致性問題',
            C: '缺乏足夠的應用場景',
            D: '知識更新的時效性問題'
        },
        correctAnswer: 'C',
        explanation: '生成式AI的應用場景極其廣泛，幾乎涵蓋了所有知識工作和內容創作領域，挑戰不在於缺乏場景，而在於如何解決其本身的技術限制和倫理風險。'
    },
    {
        question: 'BERT 和 GPT 這兩種大型語言模型，在 Transformer 架構上有何不同？',
        options: {
            A: 'BERT 使用 Encoder-Decoder，GPT 只使用 Decoder。',
            B: 'BERT 只使用 Encoder，GPT 只使用 Decoder。',
            C: 'BERT 只使用 Decoder，GPT 只使用 Encoder。',
            D: '兩者架構完全相同。'
        },
        correctAnswer: 'B',
        explanation: '這是兩者架構上的關鍵區別。BERT 的 Encoder-only 架構使其擅長理解任務，而 GPT 的 Decoder-only 架構使其擅長生成任務。'
    },
    {
        question: '什麼是「模式崩潰 (Mode Collapse)」？',
        options: {
            A: '生成模型產生了事實性錯誤。',
            B: 'GAN 的生成器只能產生非常有限、缺乏多樣性的樣本。',
            C: '擴散模型無法完全去除噪聲。',
            D: '大型語言模型的知識過時。'
        },
        correctAnswer: 'B',
        explanation: '模式崩潰是訓練 GANs 時的一個常見問題，生成器找到了幾個可以輕易騙過判別器的樣本模式，並反覆生成它們，導致生成結果的多樣性急劇下降。'
    },
    {
        question: '在科學研究領域，生成式 AI 可以如何應用？',
        options: {
            A: '完全取代科學家的實驗。',
            B: '生成全新的、具有高潛力的藥物分子或材料結構，加速研發進程。',
            C: '撰寫無法被驗證的科學論文。',
            D: '只能用於分析實驗數據。'
        },
        correctAnswer: 'B',
        explanation: '生成式模型可以學習已知數據的規律，並在潛在的、巨大的可能性空間中進行探索，生成全新的、有希望的候選方案，這極大地加速了需要大量試錯的科學發現過程。'
    },
    {
        question: '下列哪個選項是鑑別式AI，而非生成式AI？',
        options: {
            A: 'ChatGPT',
            B: 'Midjourney',
            C: 'GitHub Copilot',
            D: 'BERT'
        },
        correctAnswer: 'D',
        explanation: '雖然 BERT 是基於 Transformer 的大型語言模型，但其設計目標和預訓練任務（遮罩語言模型）使其特別擅長自然語言「理解」(NLU) 任務，如分類、實體識別，屬於鑑別式應用。A, B, C 的核心都是「生成」新內容。'
    },
    {
        question: '生成式 AI 的「自監督學習」指的是什麼？',
        options: {
            A: '需要人類專家全程監督訓練過程。',
            B: '模型從無標籤的數據中，自動為自己創造標籤來進行學習。',
            C: '模型可以自己決定學習哪些內容。',
            D: '一種需要大量 GPU 的學習方式。'
        },
        correctAnswer: 'B',
        explanation: '自監督學習是生成式 AI 預訓練的關鍵。例如，在「預測下一個詞」任務中，數據本身（下一個詞）就成了標籤，模型可以從海量無標籤文本中進行大規模學習，而無需人工標註。'
    },
    {
        question: '下列何者是擴散模型相較於 GANs 的主要優勢？',
        options: {
            A: '訓練過程更穩定，生成圖像的多樣性更高。',
            B: '訓練速度更快。',
            C: '模型參數更少。',
            D: '不需要 GPU。'
        },
        correctAnswer: 'A',
        explanation: 'GANs 的對抗性訓練過程 notoriously 難以穩定，且容易發生模式崩潰。擴散模型的訓練過程更為穩定，且通常能生成更多樣化、更高品質的圖像，這也是其成為當前主流的原因。'
    },
    {
        question: 'T5 (Text-to-Text Transfer Transformer) 模型屬於哪一類？',
        options: {
            A: '鑑別式 AI',
            B: '生成式 AI',
            C: '它將所有 NLP 任務都視為生成任務，是一個統一的生成式框架。',
            D: '非監督式學習'
        },
        correctAnswer: 'C',
        explanation: 'T5 的核心思想是將所有 NLP 任務都統一轉換為「文本到文本」的生成格式，例如，對於分類任務，它會直接生成類別的文字標籤。這種框架使其本質上是一個生成式模型。'
    },
    {
        question: '下列哪項技術不直接隸屬於生成式AI？',
        options: {
            A: '生成對抗網路 (GANs)',
            B: '擴散模型 (Diffusion Models)',
            C: '大型語言模型 (LLMs)',
            D: '支援向量機 (SVM)'
        },
        correctAnswer: 'D',
        explanation: '支援向量機是一種經典的監督式學習演算法，用於分類和迴歸，屬於鑑別式 AI 的範疇。'
    },
    {
        question: '使用生成式 AI 進行「數據增強」的主要目的是什麼？',
        options: {
            A: '讓數據集變得更大，以增加儲存挑戰。',
            B: '為數據量不足的鑑別式任務，人工合成更多訓練樣本，以提升模型性能。',
            C: '將數據轉換為另一種格式。',
            D: '驗證生成式 AI 的創造能力。'
        },
        correctAnswer: 'B',
        explanation: '在數據稀少的場景（如醫療影像），數據增強是一個非常有價值的應用。生成式 AI 可以創造出逼真的新樣本，有效擴充訓練集，幫助下游的鑑別式模型學得更好。'
    }
  ],
  L21104: [
    {
      question: '多模態人工智慧（Multimodal AI）最核心的特點是什麼？',
      options: {
        A: '它能比單模態AI更快地處理數據。',
        B: '它能處理來自多種不同來源的數據類型，如圖像和文本。',
        C: '它只專注於處理非結構化數據。',
        D: '它不需要進行模型訓練。'
      },
      correctAnswer: 'B',
      explanation: '多模態AI的定義就是能夠同時處理和融合多種不同模態（如視覺、聽覺、文字）的資訊，以獲得比任何單一模態更全面的理解。'
    },
    {
      question: '在多模態學習中，CLIP (Contrastive Language-Image Pre-training) 模型的主要貢獻是什麼？',
      options: {
        A: '它提出了一種新的圖像分割演算法。',
        B: '它透過對比學習，成功地建立了一個語義對齊的圖文聯合嵌入空間。',
        C: '它是第一個能夠生成影片的多模態模型。',
        D: '它大幅降低了處理語音數據的計算成本。'
      },
      correctAnswer: 'B',
      explanation: 'CLIP的核心貢獻是構建了一個共享的向量空間，在這個空間裡，語義相關的圖片和文字的向量表示非常接近。這為後續的零樣本圖像分類、圖像檢索等任務奠定了堅實的基礎。'
    },
    {
      question: '一個AI系統接收一張圖片和一個關於圖片的問題（例如，「圖中的人穿著什麼顏色的上衣？」），並輸出文字答案。這個任務被稱為什麼？',
      options: {
        A: '影像字幕生成 (Image Captioning)',
        B: '文本到圖像生成 (Text-to-Image)',
        C: '視覺問答 (Visual Question Answering, VQA)',
        D: '物件偵測 (Object Detection)'
      },
      correctAnswer: 'C',
      explanation: '視覺問答（VQA）是一個典型的多模態任務，模型需要同時理解圖像的視覺內容和問題的文本語義，並將兩者結合進行推理才能得出答案。'
    },
    {
      question: '在融合多模態特徵時，將來自不同模態的數據在輸入層就直接拼接起來，送入單一模型處理，這種策略被稱為什麼？',
      options: {
        A: '早期融合 (Early Fusion)',
        B: '晚期融合 (Late Fusion)',
        C: '混合融合 (Hybrid Fusion)',
        D: '交叉注意力融合 (Cross-Attention Fusion)'
      },
      correctAnswer: 'A',
      explanation: '早期融合（也稱特徵級融合）是在數據處理流程的早期階段就將不同模態的特徵結合起來。它的優點是簡單，但要求模態間的數據能夠很好地對齊。'
    },
    {
      question: '自動駕駛汽車為了精準感知周圍環境，通常會結合攝影機、光達（LiDAR）和雷達的數據。這體現了多模態AI的哪項主要優勢？',
      options: {
        A: '降低開發成本',
        B: '提升系統的穩健性和可靠性',
        C: '加快模型訓練速度',
        D: '減少數據儲存需求'
      },
      correctAnswer: 'B',
      explanation: '不同的感測器（模態）各有優劣。例如，攝影機在惡劣天氣下性能會下降，但雷達不受影響。融合多種感測器的數據可以互補長短，大大提升感知系統在各種複雜環境下的穩健性和可靠性。'
    },
    {
      question: '下列哪一項是文本到圖像生成（Text-to-Image）的典型例子？',
      options: {
        A: '輸入一張貓的圖片，系統輸出「一隻貓坐在墊子上」。',
        B: '輸入文字「一隻正在太空中騎著摩托車的宇航員貓」，系統生成一張對應的圖片。',
        C: '輸入一段語音，系統將其轉換為文字。',
        D: '輸入一張風景照，系統將其變為梵谷的油畫風格。'
      },
      correctAnswer: 'B',
      explanation: '文本到圖像生成的核心是將文字描述（一種模態）作為輸入，生成圖像（另一種模態）作為輸出。A是圖像字幕生成，C是語音辨識，D是風格遷移。'
    },
    {
      question: '在分析一段影片的情感時，多模態模型相比單純的文本分析，其主要優勢是什麼？',
      options: {
        A: '分析速度更快。',
        B: '可以處理更長的文本。',
        C: '能夠結合語音語調、臉部表情等非語言資訊，做出更準確的判斷。',
        D: '需要的訓練數據更少。'
      },
      correctAnswer: 'C',
      explanation: '人類的情感表達是多模態的。一個人在說「太好了」的時候，可能是真誠的，也可能是諷刺的。單從文字無法分辨，但結合其諷刺的語調和不屑的表情，多模態模型就能做出更準確的情感判斷。'
    },
    {
      question: '「將來自不同模態的數據，投影到一個共享的、語義對齊的向量空間中。」這描述了多模態學習中的哪種核心思想？',
      options: {
        A: '特徵融合 (Feature Fusion)',
        B: '晚期融合 (Late Fusion)',
        C: '聯合嵌入空間 (Joint Embedding Space)',
        D: '跨模態生成 (Cross-modal Generation)'
      },
      correctAnswer: 'C',
      explanation: '建立一個聯合嵌入空間是多模態學習的關鍵技術之一。其目標是學習一種映射，使得語義相關的不同模態內容（如「狗」的圖片和「dog」的文字）在該共享空間中的向量表示是相近的。'
    },
    {
      question: '下列何者是多模態AI面臨的主要挑戰之一？',
      options: {
        A: '模型通常過於簡單，無法學習複雜模式。',
        B: '很難找到能夠同時處理圖像和文本的硬體。',
        C: '獲取大量成對、標註良好的多模態數據集是困難且昂貴的。',
        D: '多模態模型無法應用於商業領域。'
      },
      correctAnswer: 'C',
      explanation: '數據是多模態學習的基礎。要訓練一個強大的圖文模型，就需要數以億計的高質量「圖像-文本」對。獲取和標註這種規模的多模態數據集是一個巨大的挑戰。'
    },
    {
      question: '目前更先進、效果通常更好的特徵融合策略是什麼？',
      options: {
        A: '早期融合',
        B: '晚期融合',
        C: '混合/中間融合，例如使用交叉注意力機制(Cross-Attention)。',
        D: '完全不融合，讓各模態獨立運作。'
      },
      correctAnswer: 'C',
      explanation: '混合或中間融合策略，特別是基於交叉注意力的機制，允許不同模態的特徵在模型的深層次進行動態的、有選擇性的資訊交互，這比簡單的早期拼接或晚期投票能更有效地捕捉模態間的複雜關係。'
    },
    {
        question: '下列何者是「跨模態內容檢索」的例子？',
        options: {
            A: '用文字搜尋文字。',
            B: '用圖片搜尋風格或內容相似的其他圖片。',
            C: '用聲音搜尋聲音。',
            D: '以上皆非'
        },
        correctAnswer: 'B',
        explanation: '跨模態檢索允許用一種模態的查詢（如圖片），來搜尋另一種模態或相同模態的內容。以圖搜圖是其中最經典的應用，它依賴於計算圖片在聯合嵌入空間中的向量相似度來實現的。'
    },
    {
        question: '在特徵融合策略中，「晚期融合 (Late Fusion)」是如何運作的？',
        options: {
            A: '在輸入層就將特徵拼接。',
            B: '在模型的中间層進行特徵交互。',
            C: '每個模態先單獨預測，最後再整合各個模型的預測結果。',
            D: '只使用其中一種模態的特徵。'
        },
        correctAnswer: 'C',
        explanation: '晚期融合（或稱決策級融合）讓每個模態的處理相對獨立，直到最後的決策階段才進行整合（如投票、加權平均），其優點是靈活，但忽略了模態間的早期交互。'
    },
    {
        question: '影像字幕生成 (Image Captioning) 是一個什麼樣的多模態任務？',
        options: {
            A: '輸入文字，生成圖片。',
            B: '輸入圖片，生成一段描述性的文字。',
            C: '輸入圖片和問題，生成答案。',
            D: '輸入聲音，生成文字。'
        },
        correctAnswer: 'B',
        explanation: '影像字幕生成是典型的跨模態生成任務，模型需要理解圖片的視覺內容，並用另一種模態（自然語言）將其表達出來。'
    },
    {
        question: '多模態AI可能帶來更深層的偏見問題，其原因是什麼？',
        options: {
            A: '多模態模型更容易出錯。',
            B: '模型可能將不同模態中的偏見進行不當的關聯。',
            C: '多模態模型不需要訓練數據。',
            D: '多模態模型的計算成本更高。'
        },
        correctAnswer: 'B',
        explanation: '偏見可能不僅存在於單一模態中，還可能在模態的關聯中產生。例如，模型可能錯誤地將某種口音（聲音模態）與某種外貌特徵（視覺模態）進行帶有刻板印象的關聯，形成更複雜的偏見。'
    },
    {
        question: '下列哪項技術不是多模態AI的核心技術？',
        options: {
            A: '聯合嵌入空間',
            B: '特徵融合策略',
            C: '跨模態生成',
            D: '強化學習'
        },
        correctAnswer: 'D',
        explanation: '強化學習是一種獨立的機器學習範式，關注決策和控制。而A, B, C 都是處理和整合多種數據模態的核心技術。'
    },
    {
        question: '在增強現實(AR)中，使用者可以用語音指令來操作眼前的虛擬物件，這體現了多模態互動的什麼優點？',
        options: {
            A: '更低的成本',
            B: '更高的安全性',
            C: '更自然、更符合人類直覺的互動體驗',
            D: '更快的處理速度'
        },
        correctAnswer: 'C',
        explanation: '人類天生就是多模態的生物，我們習慣同時使用語言、視覺、手勢等多種方式進行互動。多模態AI能夠實現更貼近人類自然互動方式的人機介面。'
    },
    {
        question: '模態的「異質性」指的是什麼？',
        options: {
            A: '不同模態的數據都來自同一個來源。',
            B: '不同模態的數據特性（如空間 vs. 時間、稀疏 vs. 密集）差異巨大。',
            C: '所有模態的數據格式都相同。',
            D: '不同模態的數據量完全相等。'
        },
        correctAnswer: 'B',
        explanation: '異質性是多模態學習的主要挑戰之一。例如，圖像數據是空間的、密集的，而文本數據是序列的、稀疏的，如何有效地融合這些特性迥異的數據，需要精巧的模型設計。'
    },
    {
        question: '下列何者是多模態AI的最終目標？',
        options: {
            A: '只專注於處理文本數據。',
            B: '讓AI具備像人類一樣，融合多種感官資訊進行綜合理解和推理的能力。',
            C: '取代所有的人類感官。',
            D: '降低所有數據的儲存成本。'
        },
        correctAnswer: 'B',
        explanation: '多模態AI是AI邁向更通用、更接近人類智慧的關鍵一步。其目標是讓AI能像人類一樣，從多維度的資訊中獲得更全面、更深入的洞察。'
    },
    {
        question: '影片內容理解與摘要，為何是一個多模態任務？',
        options: {
            A: '因為影片檔案通常很大。',
            B: '因為它需要同時分析影片的畫面（視覺）、對話（文本）和聲音（聽覺）。',
            C: '因為影片的解析度很高。',
            D: '因為影片的播放時間很長。'
        },
        correctAnswer: 'B',
        explanation: '一段影片天然地包含了多種模態的資訊流，一個全面的理解必須要能融合這些不同來源的資訊，才能準確地識別場景、人物和主題。'
    },
    {
        question: 'AudioCLIP模型將CLIP的思想擴展到了哪個領域？',
        options: {
            A: '影片',
            B: '3D模型',
            C: '聲音',
            D: '時間序列'
        },
        correctAnswer: 'C',
        explanation: 'AudioCLIP建立了一個對齊的「圖像-文本-聲音」三模態聯合嵌入空間，使得可以用聲音來檢索圖片，或用圖片來檢索聲音，進一步擴展了跨模態應用的可能性。'
    },
    {
        question: '多維度監控可能帶來什麼倫理風險？',
        options: {
            A: '提升了監控的準確性。',
            B: '可能帶來更全面的個人隱私侵犯風險。',
            C: '降低了監控的成本。',
            D: '讓監控變得更容易被發現。'
        },
        correctAnswer: 'B',
        explanation: '融合多種感測器數據（如步態、聲音、影像）的能力，雖然提升了識別的準確性，但也意味著監控可以從更多維度收集和關聯個人資訊，從而帶來更嚴重的隱私風險。'
    },
    {
        question: '下列何者是早期融合(Early Fusion)的主要缺點？',
        options: {
            A: '模型過於複雜。',
            B: '忽略了模態間的早期交互。',
            C: '要求模態間嚴格對齊且維度不能差異過大。',
            D: '只適用於兩個以上的模態。'
        },
        correctAnswer: 'C',
        explanation: '早期融合直接在原始特徵層面進行拼接，這要求不同模態的數據能夠很好地在時間或空間上對齊，且如果一個模態的維度遠大於另一個，可能會主導整個模型，這些都是其應用的限制。'
    },
    {
        question: '下列哪種模型架構最常用於處理多模態數據？',
        options: {
            A: '決策樹',
            B: 'Transformer',
            C: '線性迴歸',
            D: 'K-Means'
        },
        correctAnswer: 'B',
        explanation: 'Transformer 架構中的交叉注意力 (Cross-Attention) 機制，非常適合用來融合來自不同模態的資訊，是當前多模態學習的主流架構。'
    },
    {
        question: '語音合成 (Text-to-Speech, TTS) 是將哪兩種模態進行轉換？',
        options: {
            A: '文本到圖像',
            B: '圖像到文本',
            C: '文本到聲音',
            D: '聲音到文本'
        },
        correctAnswer: 'C',
        explanation: 'TTS 是一個跨模態生成任務，它將文字 (Text) 模態作為輸入，生成語音波形 (Speech) 模態作為輸出。'
    },
    {
        question: '一個多模態模型，其輸入是一段影片，輸出是影片的文字摘要。這個模型需要具備什麼能力？',
        options: {
            A: '只需要理解文字的能力。',
            B: '只需要理解圖像的能力。',
            C: '需要同時理解影片的視覺、聽覺和可能的文字（字幕）內容。',
            D: '只需要生成文字的能力。'
        },
        correctAnswer: 'C',
        explanation: '要對影片進行準確的摘要，模型必須能綜合理解影片中的多種資訊流，這是一個複雜的多模態理解與生成任務。'
    },
    {
        question: '下列何者不是多模態 AI 的應用？',
        options: {
            A: '視覺問答 (VQA)',
            B: '自動駕駛中的感測器融合',
            C: '多模態情感分析',
            D: '預測單一股票的收盤價'
        },
        correctAnswer: 'D',
        explanation: '預測單一股票的收盤價通常只使用歷史價格等時間序列數據，屬於單模態分析。而 A, B, C 都明確涉及了多種不同數據類型的融合。'
    },
    {
        question: '什麼是零樣本圖像分類 (Zero-shot Image Classification)？',
        options: {
            A: '模型在沒有任何訓練數據的情況下進行分類。',
            B: '模型可以對從未在訓練集中見過的類別進行分類，僅需提供該類別的文字描述。',
            C: '模型將所有圖像都分類為「零」類別。',
            D: '一種需要大量樣本的分類方法。'
        },
        correctAnswer: 'B',
        explanation: '這是 CLIP 這類圖文聯合嵌入模型的強大能力。因為模型已經學會了視覺概念和文字概念的對應關係，所以即使沒見過「水豚」的圖片，只要給它「水豚」這個詞，它就能在圖片中識別出水豚。'
    },
    {
        question: '「交叉注意力機制 (Cross-Attention)」在多模態融合中扮演什麼角色？',
        options: {
            A: '讓模型只關注其中一種模態。',
            B: '讓一種模態的特徵作為查詢(Query)，去有選擇性地關注另一種模態特徵中的相關部分。',
            C: '將兩種模態的特徵簡單地相加。',
            D: '計算兩種模態的平均值。'
        },
        correctAnswer: 'B',
        explanation: '交叉注意力是一種動態的融合機制，它能讓模型智慧地學習不同模態特徵之間的對應關係，例如在回答「圖片中的貓是什麼顏色」時，模型會將「貓」這個文字特徵，去關注圖像中屬於貓的像素區域。'
    },
    {
        question: '為何說多模態 AI 是邁向通用人工智慧 (AGI) 的關鍵一步？',
        options: {
            A: '因為多模態 AI 的計算成本最低。',
            B: '因為人類的智慧本身就是多模態的，我們透過多種感官綜合感知世界。',
            C: '因為多模態 AI 可以解決所有問題。',
            D: '因為多模態 AI 的程式碼最少。'
        },
        correctAnswer: 'B',
        explanation: '要達到與人類同等的通用智慧，AI 必須具備類似人類的、能夠綜合處理視覺、聽覺、語言等多種資訊的能力。多模態 AI 正是在這個方向上的重要探索。'
    },
    {
        question: '下列哪項是晚期融合 (Late Fusion) 的主要優點？',
        options: {
            A: '能捕捉模態間的早期交互。',
            B: '模型結構最簡單。',
            C: '靈活，適用於模態異質性高的情況，且各模態模型可獨立訓練。',
            D: '性能總是最好的。'
        },
        correctAnswer: 'C',
        explanation: '晚期融合讓每個模態的處理相對獨立，這使得我們可以為每個模態選擇最適合的模型，並且系統的設計更具模組化和靈活性。'
    },
    {
        question: '視覺故事生成 (Visual Storytelling) 任務的輸入和輸出是什麼？',
        options: {
            A: '輸入一個故事，輸出一系列圖片。',
            B: '輸入一張圖片，輸出一個故事。',
            C: '輸入一系列圖片，輸出一篇連貫的故事情節。',
            D: '輸入一個故事，輸出一張圖片。'
        },
        correctAnswer: 'C',
        explanation: '這個任務比單純的影像字幕生成更複雜，它要求模型不僅要理解單張圖片，還要理解圖片之間的時序和邏輯關係，才能生成一個連貫的故事。'
    }
  ],
  L21201: [
    {
      question: '一個成功的AI專案，其起點應該是什麼？',
      options: {
        A: '找到一個最新的、最先進的AI演算法。',
        B: '組建一個頂尖的數據科學家團隊。',
        C: '定義一個清晰的、有價值的業務問題。',
        D: '購買一套最強大的GPU伺服器。'
      },
      correctAnswer: 'C',
      explanation: '所有成功的AI專案都始於對業務需求的深刻理解。技術、團隊和硬體都是為了解決業務問題而服務的工具。脫離了業務價值，技術本身是沒有意義的。'
    },
    {
      question: '在進行數據成熟度評估時，下列哪項不是「5R原則」之一？',
      options: {
        A: '相關性 (Relevance)',
        B: '可靠性 (Reliability)',
        C: '合規性 (Rights)',
        D: '即時性 (Real-time)'
      },
      correctAnswer: 'D',
      explanation: '數據成熟度評估的5R原則通常指：相關性(Relevance)、可靠性(Reliability)、可用量(Recent & Range)、合規性(Rights)和資源(Resources)。即時性是應用需求，而非數據本身的成熟度評估維度。'
    },
    {
      question: '某製造企業希望導入AI進行預測性維護，以減少設備無預警停機。這個業務痛點最適合轉化為下列哪一類AI問題？',
      options: {
        A: '圖像分類問題',
        B: '時間序列預測或異常偵測問題',
        C: '自然語言處理問題',
        D: '聚類分析問題'
      },
      correctAnswer: 'B',
      explanation: '預測性維護的核心是根據設備感測器過去一段時間的運行數據（時間序列），來預測其在未來某個時間點發生故障的機率，或者偵測出與正常運行模式不符的異常狀態。'
    },
    {
      question: '在評估AI專案的投資回報率(ROI)時，下列何者屬於「效益(Return)」的範疇？',
      options: {
        A: '購買GPU伺服器的費用。',
        B: '數據科學家團隊的薪資。',
        C: '因智慧推薦系統帶來的銷售額提升。',
        D: '雲端運算平台的使用費。'
      },
      correctAnswer: 'C',
      explanation: 'ROI的效益(Return)指的是專案實施後帶來的價值增長，如增加營收、降低成本或規避風險。A、B、D都屬於專案的「投資(Investment)」或成本。'
    },
    {
      question: '「數據孤島 (Data Silos)」指的是什麼問題？',
      options: {
        A: '數據量太小，不足以訓練模型。',
        B: '數據品質太差，充滿錯誤和缺失。',
        C: '解決問題所需的數據分散在不同部門的系統中，難以整合。',
        D: '數據的儲存格式過於老舊。'
      },
      correctAnswer: 'C',
      explanation: '數據孤島是企業在進行數據分析時常見的組織和技術障礙，指的是有價值的數據被鎖在各個獨立的部門或系統中，無法被有效地共享和利用。'
    },
    {
      question: '在AI導入評估的「技術可行性分析」階段，下列哪項不是需要考慮的重點？',
      options: {
        A: '該問題是否有成熟的演算法可以解決？',
        B: '模型的預期準確率能否滿足業務需求？',
        C: '公司是否有足夠的行銷預算來推廣AI產品？',
        D: '組織內部是否擁有具備相關技能的人才？'
      },
      correctAnswer: 'C',
      explanation: '技術可行性分析專注於評估技術、演算法、人才和基礎設施是否能支撐專案的實現。行銷預算是商業推廣層面的考量，不屬於技術可行性分析的範疇。'
    },
    {
      question: '評估數據的「合規性(Rights)」時，最需要關注的是什麼？',
      options: {
        A: '數據的總量是否夠大。',
        B: '數據的格式是否統一。',
        C: '數據的獲取與使用是否符合GDPR、個資法等隱私法規。',
        D: '數據的更新頻率是否夠高。'
      },
      correctAnswer: 'C',
      explanation: '合規性評估的核心是確保數據的整個生命週期（從收集、儲存到分析應用）都嚴格遵守相關的法律法規，特別是關於個人隱私保護的條款，以避免法律風險。'
    },
    {
      question: '為何在評估AI導入時，預估投資回報率(ROI)非常重要？',
      options: {
        A: '它可以幫助決定使用哪種程式語言。',
        B: '它是爭取管理層支持和評估專案成功與否的重要依據。',
        C: '它可以直接決定模型的最終準確率。',
        D: '它可以幫助選擇雲端服務提供商。'
      },
      correctAnswer: 'B',
      explanation: '企業的所有投資最終都需要以商業價值來衡量。一個清晰的ROI預估，能將AI專案的技術價值轉化為管理層可以理解的商業語言，證明專案的投資是合理且值得的，也是後續衡量專案是否成功的重要標竿。'
    },
    {
      question: '一家金融公司想利用AI來自動化信貸審批流程。在數據成熟度評估階段，除了數據量和準確性，他們還必須特別關注什麼？',
      options: {
        A: '數據是否包含用戶的社群媒體貼文。',
        B: '數據中是否存在可能導致歧視的歷史偏見。',
        C: '數據是否都是最近一個月內產生的。',
        D: '數據是否可以用Excel打開。'
      },
      correctAnswer: 'B',
      explanation: '在信貸、招聘等高風險領域，數據中潛在的歷史偏見是一個極其重要的問題。如果用帶有偏見的數據訓練模型，模型將會學到並固化這些偏見，做出歧視性的決策，引發嚴重的法律和倫理風險。'
    },
    {
      question: '將「客服人力成本過高」這個業務痛點，轉化為「建立一個能自動回答80%常見問題的聊天機器人」，這個過程屬於AI導入評估的哪個環節？',
      options: {
        A: '問題定義與業務對齊',
        B: '數據成熟度評估',
        C: '技術可行性分析',
        D: '投資回報率(ROI)預估'
      },
      correctAnswer: 'A',
      explanation: '這個過程是AI專案的起點，即將一個模糊的、高層次的業務痛點，轉化為一個清晰的、可被AI技術解決的具體問題，並確保它與企業的戰略目標一致。'
    },
    {
        question: '「概念驗證的鴻溝」指的是什麼？',
        options: {
            A: 'PoC階段的模型通常都很完美。',
            B: 'PoC階段的模型在真實生產環境中可能無法穩定運行。',
            C: 'PoC階段不需要任何數據。',
            D: 'PoC階段的成本非常高昂。'
        },
        correctAnswer: 'B',
        explanation: '這是一個常見的挑戰，實驗室環境（PoC）是受控的，而真實生產環境充滿了各種複雜和非預期的情況。將PoC的成功複製到生產環境，需要大量的工程努力。'
    },
    {
        question: '在評估模型錯誤預測的代價時，醫療診斷模型和商品推薦模型有何不同？',
        options: {
            A: '兩者沒有任何不同。',
            B: '醫療診斷模型的容錯率遠低於商品推薦模型。',
            C: '商品推薦模型的錯誤代價更高。',
            D: '只有醫療診斷模型需要評估錯誤代價。'
        },
        correctAnswer: 'B',
        explanation: '錯誤的醫療診斷可能危及生命，其代價極高。而錯誤的商品推薦最多只是讓用戶感到不快，代價相對較低。因此，不同應用的容錯率要求截然不同。'
    },
    {
        question: '在AI導入評估中，定義清晰、可量化的成功標準（KPI）的主要目的是什麼？',
        options: {
            A: '為了讓專案看起來更專業。',
            B: '為了能夠客觀地衡量專案是否成功。',
            C: '為了可以對團隊成員進行績效考核。',
            D: '這是專案管理軟體的要求。'
        },
        correctAnswer: 'B',
        explanation: '一個沒有明確成功標準的專案，就像一場沒有終點線的賽跑。可量化的KPI為專案設定了清晰的目標，讓所有利害關係人對「成功」有共同的定義。'
    },
    {
        question: '下列何者屬於評估ROI時，效益中的「規避風險」？',
        options: {
            A: '智慧推薦提升的交叉銷售額。',
            B: '自動化流程節省的人力成本。',
            C: '詐欺偵測避免的資金損失。',
            D: '動態定價帶來的利潤增長。'
        },
        correctAnswer: 'C',
        explanation: '詐欺偵測、合規審查等AI應用，其主要價值在於幫助企業預防和減少潛在的損失，這屬於規避風險帶來的效益。'
    },
    {
        question: '評估數據的「可用量(Recent & Range)」時，「Recent」指的是什麼？',
        options: {
            A: '數據的總量。',
            B: '數據的歷史跨度。',
            C: '數據的品質。',
            D: '數據是否夠新，是否能反映當前的狀況。'
        },
        correctAnswer: 'D',
        explanation: '對於有時效性的問題（如市場預測），使用過時的數據進行訓練是沒有意義的。「Recent」強調了數據的時效性。'
    },
    {
        question: '在技術可行性分析中，評估「內部能力」指的是什麼？',
        options: {
            A: '評估公司是否有足夠的預算。',
            B: '評估公司是否有足夠的數據。',
            C: '評估組織內部是否擁有具備相關技能的人才。',
            D: '評估公司的品牌知名度。'
        },
        correctAnswer: 'C',
        explanation: '內部能力評估的是「人」的因素，即組織是否擁有執行AI專案所需的數據科學家、ML工程師等專業人才。'
    },
    {
        question: '一個AI專案的成功，最關鍵的因素是什麼？',
        options: {
            A: '擁有最快的GPU。',
            B: '使用了最複雜的演算法。',
            C: '從一個有價值的業務問題出發，並擁有高品質的相關數據。',
            D: '擁有最多的數據科學家。'
        },
        correctAnswer: 'C',
        explanation: '整個導入評估流程都強調了這一點：成功的AI專案是業務需求和數據基礎共同驅動的，技術只是實現價值的手段。'
    },
    {
        question: '在ROI預估中，下列何者屬於「投資(Investment)」？',
        options: {
            A: '預測性維護減少的維修費用。',
            B: '數據標註的人力成本。',
            C: '智慧推薦提升的銷售額。',
            D: '自動化流程節省的工時。'
        },
        correctAnswer: 'B',
        explanation: '投資指的是為專案付出的所有成本和資源，數據標註是其中一項重要的人力成本投入。A, C, D 都屬於效益(Return)。'
    },
    {
        question: '將AI專案的目標與公司的OKR對齊，屬於哪個環節？',
        options: {
            A: '問題定義與業務對齊',
            B: '數據成熟度評估',
            C: '技術可行性分析',
            D: 'ROI預估'
        },
        correctAnswer: 'A',
        explanation: '確保AI專案的目標與公司的整體戰略目標（如OKR）保持一致，是確保專案具有戰略價值、能獲得高層支持的關鍵。'
    },
    {
        question: '為何說AI專案是「投資」，而非「成本」？',
        options: {
            A: '因為AI專案的開銷很大。',
            B: '因為AI專案的目的是為了創造可衡量的商業價值。',
            C: '因為所有IT專案都稱為投資。',
            D: '因為AI專案的風險很高。'
        },
        correctAnswer: 'B',
        explanation: '將AI專案視為投資，意味著我們關注的是它未來能產生的回報（ROI），而不僅僅是它當前的開銷。這種思維有助於進行更長遠的戰略規劃。'
    },
    {
        question: '評估數據的「可靠性(Reliability)」時，主要關注什麼？',
        options: {
            A: '數據的總量。',
            B: '數據是否包含大量缺失值、錯誤值或不一致。',
            C: '數據的來源。',
            D: '數據的更新頻率。'
        },
        correctAnswer: 'B',
        explanation: '可靠性評估的是數據的「品質」，一個充滿錯誤和缺失的數據集是不可靠的，無法用於訓練出好的模型。'
    },
    {
        question: '下列何者是「為了AI而AI」的典型誤區？',
        options: {
            A: '從業務痛點出發，尋找AI解決方案。',
            B: '先選擇了一個酷炫的AI技術，再去為它尋找應用場景。',
            C: '在導入前進行詳細的ROI評估。',
            D: '優先解決能創造最大價值問題。'
        },
        correctAnswer: 'B',
        explanation: '這是一種技術導向的錯誤思維，往往會導致開發出的AI應用華而不實，無法解決真正的業務問題，造成資源浪費。'
    },
    {
        question: '下列何者不是一個好的 AI 專案成功標準？',
        options: {
            A: '模型上線後，目標客群的流失率降低 15%。',
            B: '客服中心平均回應時間縮短 50%。',
            C: '我們成功導入了一個 AI 系統。',
            D: '重複性問題的人工處理量下降 60%。'
        },
        correctAnswer: 'C',
        explanation: '一個好的成功標準必須是可量化的。選項 C 是一個模糊的陳述，無法客觀衡量專案是否真的帶來了價值。A, B, D 都是清晰、可量化的 KPI。'
    },
    {
        question: '下列哪個情境最適合使用 AI 來解決？',
        options: {
            A: '將紙本文件掃描成 PDF 存檔。',
            B: '建立一個全公司共用的通訊錄。',
            C: '根據歷史天氣數據和多種感測器資訊，預測一個地區未來三天的用電量。',
            D: '設計一個網站首頁。'
        },
        correctAnswer: 'C',
        explanation: '用電量預測是一個典型的、需要從大量複雜數據中學習模式的預測問題，非常適合 AI 發揮其價值。A 和 B 屬於數位化，D 則更偏向設計。'
    },
    {
        question: '在進行 ROI 預估時，下列何者屬於隱性成本？',
        options: {
            A: '雲端服務的月費。',
            B: '購買 GPU 伺服器的費用。',
            C: '業務部門員工為了配合 AI 專案，所投入的開會與溝通時間。',
            D: 'AI 軟體授權費。'
        },
        correctAnswer: 'C',
        explanation: '業務人員的時間投入雖然沒有直接的財務支出，但也是專案佔用的一種寶貴資源，屬於應該被估算的隱性成本或機會成本。'
    },
    {
        question: '一個 AI 專案的 ROI 計算公式通常是什麼？',
        options: {
            A: '(總投資 / 總效益) * 100%',
            B: '((總效益 - 總投資) / 總投資) * 100%',
            C: '總效益 - 總投資',
            D: '總效益 / 總投資'
        },
        correctAnswer: 'B',
        explanation: '投資回報率 (ROI) 的標準計算公式是 (淨利潤 / 投資成本)，這裡的淨利潤可以理解為 (總效益 - 總投資)。'
    },
    {
        question: '在評估數據時，發現所需數據雖然存在，但分散在三個不同的老舊系統中，且格式完全不一致。這主要會增加哪個面向的挑戰？',
        options: {
            A: '數據的相關性 (Relevance)',
            B: '數據的合規性 (Rights)',
            C: '數據的資源投入 (Resources)',
            D: '數據的可用量 (Range)'
        },
        correctAnswer: 'C',
        explanation: '這種情況意味著需要投入大量的數據工程資源（時間和人力）來進行數據的抽取、整合與清洗，這會顯著增加專案的成本和難度。'
    },
    {
        question: '「這個 AI 模型能否在我們的伺服器上順利運行？」這個問題屬於哪個評估範疇？',
        options: {
            A: '數據成熟度評估',
            B: '技術可行性分析中的基礎設施評估',
            C: 'ROI 預估',
            D: '問題定義'
        },
        correctAnswer: 'B',
        explanation: '這是在評估組織是否具備運行 AI 專案所需的硬體和軟體基礎設施，是技術可行性分析的一部分。'
    },
    {
        question: '如果一個 AI 專案的 ROI 預估為負值，代表什麼？',
        options: {
            A: '專案肯定會失敗。',
            B: '專案的預期投入成本高於其能帶來的量化效益。',
            C: '專案非常有潛力。',
            D: '計算公式出錯了。'
        },
        correctAnswer: 'B',
        explanation: 'ROI 為負值意味著從財務角度看，這是一個不划算的投資。除非該專案有重大的、難以量化的質化效益（如戰略價值），否則管理層很可能不會批准。'
    },
    {
        question: '下列哪個情境，數據的「時效性(Recency)」最為重要？',
        options: {
            A: '分析莎士比亚著作的寫作風格。',
            B: '建立一個識別貓狗圖片的模型。',
            C: '預測股票市場明天的走勢。',
            D: '分析人口普查的歷史數據。'
        },
        correctAnswer: 'C',
        explanation: '金融市場瞬息萬變，使用過時的數據來預測未來是沒有意義的。對於這類動態性極強的問題，數據的時效性是第一要求。'
    },
    {
        question: '一個 AI 專案評估的最終產出應該是什麼？',
        options: {
            A: '一個訓練好的 AI 模型。',
            B: '一份詳盡的評估報告，包含對業務問題、數據、技術和 ROI 的分析，以及是否值得投入的明確建議。',
            C: '一份採購合約。',
            D: '一份員工培訓手冊。'
        },
        correctAnswer: 'B',
        explanation: '導入評估是一個決策過程，其最終產出應該是一份能夠支撐管理層做出「做」或「不做」決策的全面性分析報告。'
    },
    {
        question: '為何在問題定義階段，需要與業務部門進行深度訪談？',
        options: {
            A: '因為業務部門的人比較空閒。',
            B: '為了確保技術團隊能真正理解業務的痛點和實際運作流程。',
            C: '為了讓業務部門分擔開發的工作。',
            D: '這是公司規定的標準流程。'
        },
        correctAnswer: 'B',
        explanation: '業務部門是問題的「所有者」，他們最清楚問題的來龍去脈和細節。與他們進行深度溝通，是確保 AI 專案能「對症下藥」的關鍵。'
    }
  ],
  L21202: [
    {
      question: '在AI專案管理中，採用「敏捷開發」與「最小可行性產品 (MVP)」策略的主要目的是什麼？',
      options: {
        A: '一次性交付一個功能最完美的最終產品。',
        B: '嚴格遵循預先制定的長期開發計畫，不做任何變更。',
        C: '以最小成本快速驗證核心假設，並根據市場反饋進行迭代，以降低開發風險。',
        D: '為了最大限度地延長專案的開發週期。'
      },
      correctAnswer: 'C',
      explanation: 'AI專案充滿不確定性。MVP策略的核心思想是「小步快跑，快速試錯」，優先開發最核心的功能，快速推向市場進行驗證，然後根據真實的用戶反饋來指導後續的開發方向，這能有效避免在錯誤的方向上投入過多資源。'
    },
    {
      question: '一個理想的最小化AI專案團隊「AI三劍客」通常不包含下列哪個角色？',
      options: {
        A: '數據科學家 (Data Scientist)',
        B: '數據工程師 (Data Engineer)',
        C: '機器學習工程師 (ML Engineer)',
        D: '市場行銷經理 (Marketing Manager)'
      },
      correctAnswer: 'D',
      explanation: '「AI三劍客」指的是AI專案核心的技術鐵三角：數據科學家負責建模，數據工程師負責數據管道，ML工程師負責部署。市場行銷經理是重要的利害關係人，但不是核心技術團隊的成員。'
    },
    {
      question: '下列何者最能描述AI專案的生命週期？',
      options: {
        A: '一個嚴格的、線性的瀑布模型，每個階段完成後才能進入下一階段。',
        B: '一個一次性的過程，模型部署後專案即告結束。',
        C: '一個類似CRISP-DM的循環迭代框架，包含持續的監控與優化。',
        D: '完全沒有固定的流程，每次都隨機進行。'
      },
      correctAnswer: 'C',
      explanation: 'AI專案的生命週期是高度迭代和循環的。模型部署上線只是開始，還需要持續監控其性能，並根據數據漂移或業務變化，回到前面的階段（如數據準備、模型建立）進行再訓練和優化，形成一個閉環。'
    },
    {
      question: '在規劃AI專案時程時，為何需要預留緩衝時間？',
      options: {
        A: '因為數據標註通常比預期快。',
        B: '因為AI專案的研發和數據探索階段充滿不確定性。',
        C: '因為GPU伺服器通常會提前到貨。',
        D: '因為管理層喜歡看到更長的專案時程。'
      },
      correctAnswer: 'B',
      explanation: '與傳統的確定性軟體開發不同，AI專案中的模型訓練和數據分析具有很強的探索性質，其結果和所需時間難以精確預估。因此，在規劃時程時預留緩衝時間，是應對這種不確定性的必要做法。'
    },
    {
      question: '在AI專案團隊中，「機器學習工程師 (ML Engineer)」的主要職責是什麼？',
      options: {
        A: '進行探索性數據分析，找出數據洞見。',
        B: '設計和進行模型演算法的實驗。',
        C: '將數據科學家開發好的模型進行產品化、部署上線並建立MLOps流程。',
        D: '提供關於業務流程的專業知識。'
      },
      correctAnswer: 'C',
      explanation: 'ML工程師是連接數據科學與軟體工程的橋樑，他們專注於將模型從實驗室環境，轉變為一個穩定、可擴展、可維護的生產級服務。'
    },
    {
      question: '「一個在Jupyter Notebook中表現良好的模型，要變成一個穩定的線上服務，中間有巨大的工程鴻溝。」這句話描述了AI專案規劃中的哪項主要挑戰？',
      options: {
        A: '跨部門溝通障礙',
        B: '模型部署的鴻溝',
        C: '冷啟動問題',
        D: '缺乏領域專家'
      },
      correctAnswer: 'B',
      explanation: '這精準地描述了從模型原型到產品化部署的挑戰。原型開發關注的是模型性能，而生產部署需要考慮服務的穩定性、延遲、擴展性、監控、版本控制等一系列複雜的工程問題。'
    },
    {
      question: '對於推薦系統等應用，新用戶或新商品因缺乏歷史數據而難以做出準確推薦，這個問題被稱為什麼？',
      options: {
        A: '數據漂移 (Data Drift)',
        B: '過擬合 (Overfitting)',
        C: '數據孤島 (Data Silos)',
        D: '冷啟動問題 (Cold Start Problem)'
      },
      correctAnswer: 'D',
      explanation: '冷啟動問題是協同過濾等依賴歷史互動數據的推薦系統的固有挑戰，指的是如何為系統中的新實體（新用戶或新商品）提供有效的推薦。'
    },
    {
      question: '在AI專案規劃中，建立定期的跨部門溝通機制的主要目的是什麼？',
      options: {
        A: '為了增加會議的數量。',
        B: '為了讓技術團隊可以專心開發，不受業務方干擾。',
        C: '確保所有利害關係人對專案進度、挑戰和成果保持透明和同步。',
        D: '為了取代所有的技術文件。'
      },
      correctAnswer: 'C',
      explanation: '有效的溝通是專案成功的關鍵。定期的溝通可以確保技術團隊的開發方向與業務目標始終保持一致，及時暴露風險，並讓業務方對AI專案的價值有持續的、切實的感受。'
    },
    {
      question: '某團隊在開發AI質檢專案時，決定第一階段先在一條產線上部署模型，並與人工複檢並行，以驗證模型的穩定性和準確性。這種策略屬於？',
      options: {
        A: '瀑布模型',
        B: '最小可行性產品 (MVP)',
        C: '大爆炸式上線',
        D: '一次性交付'
      },
      correctAnswer: 'B',
      explanation: '這是一個典型的MVP策略應用。團隊沒有試圖一開始就打造一個覆蓋所有產線的完美系統，而是選擇了一個最小的、可驗證的範圍（一條產線），以受控的方式來驗證其核心價值和技術可行性。'
    },
    {
      question: '在AI專案生命週期的「模型部署 (Deployment)」階段之後，緊接著的關鍵階段是什麼？',
      options: {
        A: '專案結束與團隊解散',
        B: '撰寫最終報告',
        C: '申請專利',
        D: '持續的監控與維護 (Monitoring & Maintenance)'
      },
      correctAnswer: 'D',
      explanation: '模型部署上線絕不是終點。由於數據漂移等因素，模型的性能會隨時間衰退。因此，持續地監控模型性能，並在必要時進行再訓練和重新部署，是確保AI系統長期有效的關鍵。'
    },
    {
        question: 'PoC (概念驗證) 和 MVP (最小可行性產品) 的主要區別是什麼？',
        options: {
            A: '兩者沒有任何區別。',
            B: 'PoC主要驗證技術可行性，通常是拋棄式的；MVP是產品的第一個版本，需要在真實環境中運行並持續迭代。',
            C: 'PoC成本更高，MVP成本更低。',
            D: 'PoC由業務團隊主導，MVP由技術團隊主導。'
        },
        correctAnswer: 'B',
        explanation: 'PoC的目的是回答「我們能做嗎？」，而MVP的目的是回答「我們應該做嗎？」。PoC是內部實驗，MVP是外部市場驗證的第一步。'
    },
    {
        question: '在AI專案團隊中，「領域專家(Domain Expert)」的主要價值是什麼？',
        options: {
            A: '編寫高效的程式碼。',
            B: '提供深刻的業務知識和數據的業務解讀。',
            C: '管理雲端伺服器。',
            D: '設計使用者介面。'
        },
        correctAnswer: 'B',
        explanation: '領域專家是連接技術與業務的橋樑，他們知道哪些問題是真正有價值的，哪些數據特徵是真正有意義的，他們的參與對專案的成功至關重要。'
    },
    {
        question: '在資源規劃中，「雲端服務的預算」屬於哪一類資源？',
        options: {
            A: '人力資源',
            B: '運算資源',
            C: '軟體工具資源',
            D: '數據資源'
        },
        correctAnswer: 'B',
        explanation: '雲端服務（如AWS SageMaker, GCP Vertex AI）提供了模型訓練和部署所需的GPU/TPU等計算能力，屬於運算資源的範疇。'
    },
    {
        question: '為何說AI專案的成功高度依賴於「跨職能」的協作？',
        options: {
            A: '因為需要更多的人來分擔責任。',
            B: '因為單靠技術人員無法理解複雜的業務需求，單靠業務人員無法實現技術方案。',
            C: '因為跨職能團隊的會議比較多。',
            D: '因為這是現代企業的流行趨勢。'
        },
        correctAnswer: 'B',
        explanation: 'AI專案的本質是將技術應用於解決業務問題，這決定了它必須是一個技術與業務緊密結合的過程，需要不同背景的專家共同努力。'
    },
    {
        question: '在AI專案生命週期中，哪個階段通常佔用最多的時間？',
        options: {
            A: '業務理解',
            B: '數據準備 (Data Preparation)',
            C: '模型建立 (Modeling)',
            D: '模型部署 (Deployment)'
        },
        correctAnswer: 'B',
        explanation: '業界普遍的共識是，數據的收集、清理、標註和特徵工程等數據準備工作，往往會佔據整個AI專案60%到80%的時間和精力。'
    },
    {
        question: '在規劃溝通機制時，「每日站會」通常是為誰設計的？',
        options: {
            A: '高階管理層',
            B: '技術團隊內部',
            C: '客戶',
            D: '所有部門'
        },
        correctAnswer: 'B',
        explanation: '每日站會是敏捷開發中的一個實踐，旨在讓技術開發團隊的成員之間，能夠快速同步進度、暴露問題，是一種高頻率的內部溝通機制。'
    },
    {
        question: '下列何者是「數據工程師(Data Engineer)」的主要職責？',
        options: {
            A: '選擇最佳的機器學習演算法。',
            B: '建立穩定的數據管道（Data Pipeline）和ETL流程。',
            C: '向管理層報告專案進度。',
            D: '設計產品的使用者體驗。'
        },
        correctAnswer: 'B',
        explanation: '數據工程師是數據的「建築師」和「管道工」，他們負責確保數據能夠穩定、可靠、高效地從源頭流向數據科學家和AI模型。'
    },
    {
        question: '為何不建議AI專案採用傳統的瀑布式開發模型？',
        options: {
            A: '因為瀑布模型太老舊了。',
            B: '因為AI專案充滿了探索性和不確定性，需要不斷的反饋和調整，而瀑布模型的線性流程過於僵化。',
            C: '因為瀑布模型只適用於硬體開發。',
            D: '因為瀑布模型的開發速度更快。'
        },
        correctAnswer: 'B',
        explanation: '瀑布模型適用於需求非常明確、變動很少的專案。而AI專案的本質是實驗和探索，敏捷開發的迭代模式更能適應這種不確定性。'
    },
    {
        question: '下列何者是「AI產品經理(AI Product Manager)」的職責？',
        options: {
            A: '訓練模型。',
            B: '部署模型。',
            C: '定義AI產品的規格、使用者體驗和商業模式。',
            D: '建立數據管道。'
        },
        correctAnswer: 'C',
        explanation: 'AI產品經理是產品的「靈魂」，他們負責定義「做什麼」和「為何做」，確保最終開發出的AI產品能夠滿足市場需求並創造商業價值。'
    },
    {
        question: '下列何者不是敏捷開發的核心價值？',
        options: {
            A: '個人與互動 高於 流程與工具',
            B: '可工作的軟體 高於 詳盡的文件',
            C: '客戶合作 高於 合約協商',
            D: '遵循計畫 高於 回應變化'
        },
        correctAnswer: 'D',
        explanation: '敏捷開發的核心價值之一是「回應變化 高於 遵循計畫」，強調了在面對不確定性時，適應性和靈活性比死守計畫更重要。'
    },
    {
        question: '一個AI專案的時程規劃，應該包含明確的什麼？',
        options: {
            A: '每日的詳細工作內容。',
            B: '所有團隊成員的休假計畫。',
            C: '里程碑（Milestones）和交付成果（Deliverables）。',
            D: '競爭對手的專案時程。'
        },
        correctAnswer: 'C',
        explanation: '一個好的時程規劃應該是基於目標的，透過設定清晰的里程碑和每個階段的可交付成果，可以讓專案進度更可控、更透明。'
    },
    {
        question: '缺乏「MLOps文化」的組織，在AI導入上會遇到什麼問題？',
        options: {
            A: '模型準確率無法提升。',
            B: '模型上線後快速劣化，難以維護和迭代。',
            C: '無法找到合適的數據科學家。',
            D: '數據儲存成本過高。'
        },
        correctAnswer: 'B',
        explanation: 'MLOps文化強調自動化和流程化。缺乏這種文化，會導致模型部署和維護高度依賴手動操作，效率低下且容易出錯，無法實現AI應用的規模化和可持續發展。'
    },
    {
        question: '在 AI 專案中，哪位角色的主要工作是探索數據、建立模型和驗證假設？',
        options: {
            A: '數據工程師',
            B: '數據科學家',
            C: '機器學習工程師',
            D: '專案經理'
        },
        correctAnswer: 'B',
        explanation: '數據科學家是模型的核心建立者，他們負責從數據中挖掘洞見、進行特徵工程、選擇和訓練演算法，並評估模型的性能。'
    },
    {
        question: '敏捷開發中的「衝刺 (Sprint)」通常持續多長時間？',
        options: {
            A: '一天',
            B: '2-4 週',
            C: '3-6 個月',
            D: '一年'
        },
        correctAnswer: 'B',
        explanation: '衝刺是一個短週期的、有固定時間盒的開發循環，通常為 2-4 週。在每個衝刺結束時，團隊需要交付一個可用的、增量的產品。'
    },
    {
        question: '下列哪個情境最適合採用 MVP 策略？',
        options: {
            A: '建造一座橋樑。',
            B: '開發一個全新的、市場不確定的社交 App。',
            C: '升級公司內部的薪資發放系統。',
            D: '修復一個已知的軟體錯誤。'
        },
        correctAnswer: 'B',
        explanation: 'MVP 策略最適合用於充滿不確定性的新產品開發。透過快速推出核心功能版本，可以以最小的成本來驗證市場需求和商業模式，避免大規模投入後的失敗。'
    },
    {
        question: '在 AI 專案規劃中，為何需要建立一個清晰的溝通規劃？',
        options: {
            A: '為了增加會議記錄的數量。',
            B: '為了管理期望、及時發現問題，並確保技術與業務目標一致。',
            C: '為了讓專案經理可以練習簡報技巧。',
            D: '這是敏捷開發禁止的。'
        },
        correctAnswer: 'B',
        explanation: '清晰、透明的溝通是管理複雜專案的生命線。定期的溝通可以確保所有利害關係人都處於同一頁面上，從而減少誤解、加速決策。'
    },
    {
        question: '下列何者不是 AI 專案規劃階段需要盤點的資源？',
        options: {
            A: '人力',
            B: '運算資源',
            C: '數據資源',
            D: '競爭對手的股價'
        },
        correctAnswer: 'D',
        explanation: '資源規劃盤點的是執行專案所需的「內部」資源，包括人力、硬體、軟體和數據。競爭對手的股價屬於外部市場資訊，而非專案資源。'
    },
    {
        question: '一個 AI 專案的「交付成果 (Deliverables)」可以是什麼？',
        options: {
            A: '只有最終的 AI 模型。',
            B: '只有專案的原始碼。',
            C: '可以是數據清洗腳本、一個訓練好的模型、一個可供測試的 API 端點等。',
            D: '只有一份結案報告。'
        },
        correctAnswer: 'C',
        explanation: '交付成果是專案在每個里程碑結束時，產出的具體的、可驗證的成果。它可以是多種形式的，標誌著專案取得了階段性的進展。'
    },
    {
        question: '在一個 AI 專案團隊中，如果缺乏數據工程師，最可能發生什麼問題？',
        options: {
            A: '模型演算法選擇不當。',
            B: '數據科學家需要花費大量時間處理數據的獲取、清洗和儲存問題，效率低下。',
            C: '模型無法被部署到生產環境。',
            D: '專案無法與業務目標對齊。'
        },
        correctAnswer: 'B',
        explanation: '數據工程師負責建立穩定可靠的數據基礎設施。如果沒有他們，數據科學家就不得不身兼數職，處理大量繁瑣的數據工程任務，這會嚴重影響他們在核心建模工作上的效率。'
    },
    {
        question: '下列哪個工具最常用於 AI 專案的工作流編排？',
        options: {
            A: 'Jupyter Notebook',
            B: 'Git',
            C: 'Docker',
            D: 'Airflow / Kubeflow Pipelines'
        },
        correctAnswer: 'D',
        explanation: 'Airflow 和 Kubeflow Pipelines 是專門用於定義、調度和監控複雜數據工作流（包括 ETL 和模型訓練）的工具，是 MLOps 中的核心組件。'
    },
    {
        question: '下列哪個選項最能體現「AI 專案的探索性」？',
        options: {
            A: '專案的需求和規格在開始時就完全確定，不會改變。',
            B: '專案的結果和所需時間可以被精確地預估。',
            C: '專案過程中可能需要進行多次實驗，模型性能可能無法達到預期，需要不斷嘗試和調整。',
            D: '專案的部署流程是固定的。'
        },
        correctAnswer: 'C',
        explanation: 'AI 專案更像是一場科學實驗，而非傳統的建築工程。其結果充滿不確定性，需要團隊具備容忍失敗、快速試錯的敏捷思維。'
    }
  ],
  L21203: [
    {
      question: '當生產環境的數據分佈發生變化，與訓練數據不再一致時（例如，因疫情導致用戶消費行為改變），這種現象被稱為什麼？',
      options: {
        A: '概念漂移 (Concept Drift)',
        B: '數據漂移 (Data Drift)',
        C: '模型衰退 (Model Decay)',
        D: '對抗性攻擊 (Adversarial Attack)'
      },
      correctAnswer: 'B',
      explanation: '數據漂移指的是輸入特徵(X)的分佈P(X)發生了變化，這是導致已部署模型性能下降的最常見原因之一。'
    },
    {
      question: '下列哪一項是針對AI模型「可解釋性不足」風險的主要緩解措施？',
      options: {
        A: '使用更大規模的數據集進行訓練。',
        B: '使用更複雜的深度學習模型。',
        C: '在需要解釋的場景中，優先選擇決策樹、線性迴歸等白箱模型，或使用LIME、SHAP等XAI工具。',
        D: '對模型進行更頻繁的再訓練。'
      },
      correctAnswer: 'C',
      explanation: '應對可解釋性風險，要麼選擇本身就易於解釋的模型（白箱模型），要麼使用XAI（可解釋AI）工具來解釋黑箱模型的決策。增加數據量或模型複雜度通常會讓可解釋性變得更差。'
    },
    {
      question: '一個在歷史數據上訓練的招聘模型，可能會因為過去男性工程師佔多數，而對女性風格的履歷產生不公平的偏見。這屬於哪一類AI風險？',
      options: {
        A: '模型風險',
        B: '數據風險',
        C: '倫理與公平性風險',
        D: '營運風險'
      },
      correctAnswer: 'C',
      explanation: '這是典型的演算法偏見問題，源於訓練數據中存在的歷史性偏見，屬於倫理與公平性風險的範疇。模型本身沒有歧視的意圖，但它忠實地學習了數據中的不公平模式。'
    },
    {
      question: '為了實現AI應用的持續交付與生命週期管理，業界提出了一套旨在實現機器學習工作流程自動化的文化與實踐，稱之為？',
      options: {
        A: 'DevOps',
        B: 'Agile',
        C: 'MLOps',
        D: 'DataOps'
      },
      correctAnswer: 'C',
      explanation: 'MLOps（機器學習維運）是DevOps在機器學習領域的延伸，它專注於打通從數據、模型到部署的整個工作流，實現CI/CD/CT（持續整合/交付/訓練）的自動化管道。'
    },
    {
      question: '攻擊者故意向訓練數據中注入惡意樣本，以破壞模型的性能或植入後門，這種攻擊手法被稱為什麼？',
      options: {
        A: '數據漂移',
        B: '數據中毒攻擊 (Data Poisoning)',
        C: '對抗性攻擊',
        D: '模型竊取攻擊'
      },
      correctAnswer: 'B',
      explanation: '數據中毒攻擊直接污染了模型的「食物」——訓練數據，是一種非常隱蔽且危害巨大的攻擊方式，它從源頭上破壞了模型的可靠性。'
    },
    {
      question: '在AI風險管理中，「概念漂移 (Concept Drift)」指的是什麼？',
      options: {
        A: '輸入數據的分佈發生了變化。',
        B: '輸入特徵與目標變數之間的關係發生了改變。',
        C: '模型的程式碼出現了錯誤。',
        D: '用戶對產品的理解發生了變化。'
      },
      correctAnswer: 'B',
      explanation: '概念漂移指的是變數之間的底層關係 P(Y|X) 發生了變化。例如，金融市場的規則改變，導致同樣的經濟指標預示著完全不同的股市走向。這比數據漂移更難被檢測。'
    },
    {
      question: '下列何者不是營運風險的範疇？',
      options: {
        A: '模型服務的系統穩定性不足。',
        B: '缺乏有效的模型性能監控機制。',
        C: '模型可能對特定族群產生歧視。',
        D: '模型更新的流程過於冗長。'
      },
      correctAnswer: 'C',
      explanation: '模型產生歧視屬於倫理與公平性風險。營運風險主要關注AI系統在部署、上線、維運階段的技術和流程問題，如穩定性、監控、MLOps流程等。'
    },
    {
      question: '在金融風控模型的風險管理中，建立自動化監控系統，持續追蹤模型的準確率和關鍵變數的分佈，主要是為了應對哪種風險？',
      options: {
        A: '數據隱私風險',
        B: '數據漂移與模型性能衰退',
        C: '對抗性攻擊',
        D: '公平性風險'
      },
      correctAnswer: 'B',
      explanation: '持續監控模型的性能指標（如準確率）和輸入數據的分佈，是及時發現數據漂移或概念漂移，並觸發模型再訓練流程的關鍵，旨在解決模型上線後性能下降的問題。'
    },
    {
      question: '根據歐盟的GDPR法規，當AI系統做出對個人有重大影響的自動化決策（如拒絕貸款申請）時，用戶擁有哪些權利？',
      options: {
        A: '有權要求分紅。',
        B: '有權要求獲得該AI模型的原始碼。',
        C: '有權要求對決策進行解釋，並進行人工複核。',
        D: '有權刪除該模型。'
      },
      correctAnswer: 'C',
      explanation: 'GDPR等法規強調對自動化決策的知情權和解釋權，旨在保護個人免受純粹由演算法做出的、不透明且可能不公平的決策的影響。'
    },
    {
      question: '在高風險的AI應用（如自動駕駛）中，設計多重冗餘備份和失效安全（Fail-safe）機制，是為了緩解哪一類風險？',
      options: {
        A: '模型風險',
        B: '數據風險',
        C: '倫理風險',
        D: '營運風險'
      },
      correctAnswer: 'D',
      explanation: '冗餘備份和失效安全機制是系統工程中的概念，旨在確保即使部分組件發生故障，整個系統依然能夠保持運行或安全地終止，這屬於確保系統穩定性和可靠性的營運風險管理範疇。'
    },
    {
        question: '下列何者是「代理變數歧視」的例子？',
        options: {
            A: '模型因申請人的性別而拒絕其貸款。',
            B: '模型因申請人的郵遞區號（與種族高度相關）而拒絕其貸款。',
            C: '模型因申請人的信用分數低而拒絕其貸款。',
            D: '模型因申請文件不齊全而拒絕其貸款。'
        },
        correctAnswer: 'B',
        explanation: '即使移除了敏感特徵（如種族），模型也可能利用其他高度相關的代理變數（如郵遞區號）來間接實現歧視，這是一種更隱蔽的公平性風險。'
    },
    {
        question: '聯邦學習(Federated Learning)技術主要是為了解決哪一類數據風險？',
        options: {
            A: '數據標註品質風險',
            B: '數據隱私風險',
            C: '數據中毒攻擊',
            D: '數據來源合規性風險'
        },
        correctAnswer: 'B',
        explanation: '聯邦學習透過讓原始數據保留在本地，只交換模型的更新參數，極大地降低了在模型訓練過程中數據洩漏的風險，是一種強大的隱私保護技術。'
    },
    {
        question: '為何說AI風險管理是一個「持續性動態過程」？',
        options: {
            A: '因為風險只在專案初期存在。',
            B: '因為新的攻擊手法和數據漂移模式層出不窮，風險管理不是一次性的工作。',
            C: '因為風險管理流程每年都需要重新設計。',
            D: '因為風險是固定不變的。'
        },
        correctAnswer: 'B',
        explanation: 'AI系統和其運行的環境都是動態變化的，因此風險管理也必須是一個持續的、與時俱進的過程，需要不斷地監控、評估和調整。'
    },
    {
        question: '在生成式AI應用中，透過指令微調和RLHF來降低模型產生不實內容的機率，是為了緩解哪種風險？',
        options: {
            A: '數據隱私風險',
            B: '深度偽造風險',
            C: '事實性錯誤 (Hallucination) 風險',
            D: '版權風險'
        },
        correctAnswer: 'C',
        explanation: '指令微調和人類反饋強化學習(RLHF)是提升大型語言模型可控性和事實性的關鍵技術，旨在讓模型的輸出更符合人類的期望，減少「胡說八道」的現象。'
    },
    {
        question: '將AI定位為「輔助」而非「取代」工具，並建立清晰的人機協作流程，主要是在管理哪方面的風險？',
        options: {
            A: '數據安全風險',
            B: '營運風險與責任歸屬問題',
            C: '模型可解釋性風險',
            D: '演算法偏見風險'
        },
        correctAnswer: 'B',
        explanation: '在醫療、金融等高風險領域，將AI作為輔助工具，並由人類做最終決策，可以建立清晰的責任歸屬，並利用人類的專業判斷來彌補AI的不足，是重要的營運風險管理策略。'
    },
    {
        question: '公平性、可解釋性、穩健性之間的關係是什麼？',
        options: {
            A: '它們是完全獨立、互不相干的概念。',
            B: '它們之間可能存在權衡關係，例如提升可解釋性有時會犧牲一些準確性。',
            C: '只要做好了公平性，其他兩者自然會好。',
            D: '只要做好了穩健性，其他兩者自然會好。'
        },
        correctAnswer: 'B',
        explanation: '在AI治理中，不同的目標之間往往存在權衡。例如，一個簡單的、可解釋的決策樹模型，其準確性可能不如一個複雜的、難以解釋的深度網路。需要在不同目標之間找到符合業務需求的平衡點。'
    },
    {
        question: '「模型債(Model Debt)」指的是什麼？',
        options: {
            A: '購買AI模型所欠的錢。',
            B: '因缺乏持續監控和維護，導致已部署模型性能持續下降所積累的技術債務。',
            C: '模型訓練所消耗的電力成本。',
            D: '開發AI模型所需的時間。'
        },
        correctAnswer: 'B',
        explanation: '模型債是一個比喻，指的是在AI系統的整個生命週期中，為了走捷徑而忽略的長期維護成本。缺乏MLOps流程、版本控制混亂、監控不足等都會累積模型債，最終導致系統崩潰。'
    },
    {
        question: '一個AI系統過度依賴單一的第三方AI服務提供商，這會帶來什麼風險？',
        options: {
            A: '模型風險',
            B: '數據風險',
            C: '倫理風險',
            D: '營運風險中的供應鏈風險'
        },
        correctAnswer: 'D',
        explanation: '過度依賴單一供應商，會讓企業的營運受制於人。一旦該供應商服務中斷、漲價或倒閉，將對自身業務造成重大衝擊，這屬於供應鏈風險管理的範疇。'
    },
    {
        question: '下列何者是組織文化層面的AI風險管理挑戰？',
        options: {
            A: '模型的可解釋性不足。',
            B: '數據中毒攻擊。',
            C: '缺乏風險意識，過於關注快速上線而忽略風險評估。',
            D: '數據漂移。'
        },
        correctAnswer: 'C',
        explanation: '成功的AI風險管理不僅需要技術工具，更需要組織文化的變革。如果組織文化不容忍試錯、不重視風險，那麼任何風險管理框架都將形同虛設。'
    },
    {
        question: '在風險管理的四個維度中，下列哪個維度最關注AI決策是否帶有歧視性？',
        options: {
            A: '模型風險',
            B: '數據風險',
            C: '倫理與公平性風險',
            D: '營運風險'
        },
        correctAnswer: 'C',
        explanation: '倫理與公平性風險專門處理AI可能對社會產生的負面影響，其中最重要的就是演算法偏見可能導致的歧視性後果。'
    },
    {
        question: '下列何者不是AI風險管理框架的核心活動？',
        options: {
            A: '風險識別',
            B: '風險評估',
            C: '風險緩解',
            D: '風險最大化'
        },
        correctAnswer: 'D',
        explanation: '風險管理的目標是系統性地識別、評估、緩解和監控風險，以將其控制在可接受的範圍內，而不是最大化風險。'
    },
    {
        question: '對AI模型進行版本控制，主要是為了什麼？',
        options: {
            A: '為了讓模型檔案更大。',
            B: '為了確保實驗的可追溯性和可重複性。',
            C: '為了讓模型運行得更快。',
            D: '為了增加模型的複雜度。'
        },
        correctAnswer: 'B',
        explanation: '嚴格的版本控制（不僅是程式碼，還包括數據和模型）是科學實驗和工程實踐的基礎。它確保了當問題出現時，我們能夠準確地回溯到哪個版本出了問題，並能重現當時的結果。'
    }
  ],
  L21301: [
    {
      question: '「Garbage in, garbage out」這句名言，在AI專案中最能凸顯下列哪個階段的重要性？',
      options: {
        A: '模型部署',
        B: '數據準備與特徵工程',
        C: '使用者介面設計',
        D: '專案時程規劃'
      },
      correctAnswer: 'B',
      explanation: '這句話精準地說明了數據品質對模型性能的決定性作用。如果輸入給模型的數據是充滿錯誤和噪聲的「垃圾」，那麼即使使用最先進的演算法，輸出的結果也必然是不可靠的「垃圾」。'
    },
    {
      question: '在處理客戶流失預測的數據時，數據科學家從原始的「用戶最後登入日期」特徵，創造出一個新的「最近登入距今天數」特徵。這個過程稱為什麼？',
      options: {
        A: '數據清洗',
        B: '數據標註',
        C: '特徵工程',
        D: '數據標準化'
      },
      correctAnswer: 'C',
      explanation: '特徵工程是從原始數據中提取或構建出對模型更有預測能力的特徵的過程。這裡，將一個日期轉換為一個更有意義的、表示用戶活躍度的數值，是一個典型的特徵創造案例。'
    },
    {
      question: '對於監督式學習任務，下列哪個環節通常是AI專案中成本和時間投入最大的部分之一？',
      options: {
        A: '選擇優化器',
        B: '數據標註',
        C: '模型推論',
        D: '安裝開發環境'
      },
      correctAnswer: 'B',
      explanation: '獲取大量高質量的標註數據是監督式學習的基礎，而這個過程，無論是僱用內部團隊還是外包，通常都需要大量的人力和時間成本，其品質直接決定了模型的上限。'
    },
    {
      question: '在選擇機器學習模型時，若業務場景（如醫療診斷）高度要求模型能夠解釋其決策原因，應優先考慮下列哪類模型？',
      options: {
        A: '深度神經網路',
        B: '梯度提升機 (XGBoost)',
        C: '支援向量機 (SVM)',
        D: '邏輯迴歸或決策樹'
      },
      correctAnswer: 'D',
      explanation: '邏輯迴歸和決策樹是典型的「白箱模型」，其決策邏輯和規則是透明且易於人類理解的。而深度神經網路、XGBoost等模型雖然性能強大，但通常是「黑箱模型」，可解釋性較差。'
    },
    {
      question: '將一個包含「地區」特徵（如「台北」、「台中」、「高雄」）的欄位，轉換為多個二元（0/1）特徵欄位（如is_Taipei, is_Taichung, is_Kaohsiung），這種處理類別特徵的方法被稱為什麼？',
      options: {
        A: '標籤編碼 (Label Encoding)',
        B: '獨熱編碼 (One-Hot Encoding)',
        C: '數據標準化 (Standardization)',
        D: '降維 (Dimensionality Reduction)'
      },
      correctAnswer: 'B',
      explanation: '獨熱編碼是處理無序類別變數的標準方法，它將一個類別特徵轉換為一組互斥的二元特徵，避免了為類別引入不應有的大小關係。'
    },
    {
      question: '為何在將數據輸入到某些模型（如線性迴歸、SVM）之前，需要進行特徵縮放（如標準化或歸一化）？',
      options: {
        A: '為了增加數據的維度。',
        B: '為了讓數據更容易被人類讀懂。',
        C: '為了避免模型被那些數值尺度較大的特徵所主導。',
        D: '這是所有機器學習模型的強制要求。'
      },
      correctAnswer: 'C',
      explanation: '許多模型（特別是基於距離計算或梯度下降的模型）對輸入特徵的尺度很敏感。如果不進行縮放，一個尺度很大的特徵（如年收入）相對於一個尺度很小的特徵（如年齡），會在模型中佔據不成比例的主導地位，影響模型的學習效果。'
    },
    {
      question: '在模型選擇的過程中，建立一個簡單、快速的「基準模型 (Baseline Model)」的主要目的是什麼？',
      options: {
        A: '為了向管理層展示最酷炫的技術。',
        B: '為了盡可能地延長專案時間。',
        C: '為了提供一個性能底線，任何更複雜的模型都必須顯著優於它才有價值。',
        D: '基準模型就是最終要上線的模型。'
      },
      correctAnswer: 'C',
      explanation: '基準模型為模型性能提供了一個客觀的參考點。如果一個複雜的、耗費大量資源的模型，其性能僅僅略微優於（甚至不如）一個簡單的基準模型，那麼這個複雜模型就是沒有價值的。'
    },
    {
      question: '從所有可用特徵中，選出與預測目標最相關的特徵子集，以提升模型性能並降低計算複雜度，這個過程稱為什麼？',
      options: {
        A: '特徵提取 (Feature Extraction)',
        B: '特徵創造 (Feature Creation)',
        C: '特徵選擇 (Feature Selection)',
        D: '特徵縮放 (Feature Scaling)'
      },
      correctAnswer: 'C',
      explanation: '特徵選擇的目標是「少即是多」，通過移除無關或冗餘的特徵，來簡化模型、防止過擬合，並可能提升模型的泛化能力。'
    },
    {
      question: '下列哪項是處理數據中「離群值 (Outliers)」時應採取的謹慎態度？',
      options: {
        A: '只要發現離群值，就應立即刪除。',
        B: '離群值對所有模型都有害，必須處理。',
        C: '需要仔細甄別，因為它們可能是重要的罕見事件，而不僅僅是噪聲。',
        D: '離群值只存在於數值數據中，類別數據沒有。'
      },
      correctAnswer: 'C',
      explanation: '處理離群值必須非常小心。一個極端值可能是輸入錯誤，但也可能是一個真實的、極具價值的信號（如信用卡交易中的一次詐欺行為）。輕易刪除可能導致重要資訊的丟失。'
    },
    {
      question: 'L1正規化(LASSO)在特徵選擇中扮演了什麼角色？',
      options: {
        A: '它會增加所有特徵的權重。',
        B: '它會讓不重要的特徵的權重趨近於零，但不完全等於零。',
        C: '它會讓不重要的特徵的權重被壓縮到恰好為零，從而實現自動特徵選擇。',
        D: '它與特徵選擇無關，只用於防止過擬合。'
      },
      correctAnswer: 'C',
      explanation: 'L1正規化的獨特之處在於其稀疏性。它在懲罰模型複雜度的同時，會將許多貢獻不大的特徵的係數精確地變為零，因此它是一種嵌入式（Embedded）的特徵選擇方法。'
    },
    {
        question: '下列何者是「數據洩漏 (Data Leakage)」的例子？',
        options: {
            A: '在劃分訓練/測試集之後，才對訓練集進行標準化。',
            B: '在劃分訓練/測試集之前，就對整個數據集進行了標準化。',
            C: '使用交叉驗證來評估模型。',
            D: '從模型中移除不相關的特徵。'
        },
        correctAnswer: 'B',
        explanation: '這是一個典型的數據洩漏。如果在劃分前就對整個數據集進行標準化，那麼測試集的統計資訊（如均值、標準差）就已經「洩漏」到了訓練集的轉換過程中，導致模型評估結果過於樂觀。'
    },
    {
        question: '下列何者不是特徵選擇的目的？',
        options: {
            A: '簡化模型，使其更易解釋。',
            B: '減少訓練時間。',
            C: '增加模型的特徵數量。',
            D: '防止過擬合。'
        },
        correctAnswer: 'C',
        explanation: '特徵選擇的目標是從現有特徵中「篩選」出一個更小的、更有效的子集，因此其結果是減少而非增加特徵數量。'
    },
    {
        question: '從時間戳特徵中，提取出「星期幾」、「是否為節假日」等新特徵，這屬於？',
        options: {
            A: '特徵提取',
            B: '特徵選擇',
            C: '數據清洗',
            D: '數據標註'
        },
        correctAnswer: 'A',
        explanation: '特徵提取是從原始數據中抽取出更有意義的資訊的過程。將一個單一的時間戳分解為多個具有週期性或特定意義的特徵，是時間序列分析中非常重要的特徵工程步驟。'
    },
    {
        question: '主動學習(Active Learning)是一種什麼樣的數據標註策略？',
        options: {
            A: '讓標註員主動選擇他們想標註的數據。',
            B: '讓模型挑出它最不確定、最需要被標註的困難樣本，以提高標註效率。',
            C: '將所有數據都標註兩次以確保品質。',
            D: '在標註前先對數據進行主成分分析。'
        },
        correctAnswer: 'B',
        explanation: '主動學習旨在用最少的標註成本，獲得最大的模型性能提升。其核心思想是，與其隨機標註，不如讓模型自己找出它最「困惑」的樣本，優先對這些最有價值的樣本進行標註。'
    },
    {
        question: '在處理有數萬個類別的類別特徵時，獨熱編碼會導致什麼問題？',
        options: {
            A: '模型欠擬合',
            B: '維度災難',
            C: '數據洩漏',
            D: '模型偏差'
        },
        correctAnswer: 'B',
        explanation: '獨熱編碼會將一個特徵轉換為N個特徵，當N非常大時，會導致特徵空間的維度急劇膨脹，使得數據變得非常稀疏，增加計算複雜度和過擬合風險，這就是維度災難。'
    },
    {
        question: '下列何者是「包裹法(Wrapper Methods)」進行特徵選擇的例子？',
        options: {
            A: '使用相關係數篩選特徵。',
            B: '使用L1正規化。',
            C: '遞歸特徵消除(Recursive Feature Elimination, RFE)。',
            D: '使用卡方檢定篩選特徵。'
        },
        correctAnswer: 'C',
        explanation: 'RFE是一個典型的包裹法。它反覆地訓練模型，並在每一輪中剔除掉最不重要的特徵，直到達到指定的特徵數量。這個過程就像一層層地「包裹」著模型來進行搜索。'
    },
    {
        question: '在深度學習時代，特徵工程的角色發生了什麼變化？',
        options: {
            A: '手動特徵工程變得完全不重要。',
            B: '雖然端到端學習減少了對手動特徵工程的需求，但好的特徵工程依然能顯著提升模型性能。',
            C: '特徵工程完全被自動化工具取代。',
            D: '只有在小數據集上才需要特徵工程。'
        },
        correctAnswer: 'B',
        explanation: '雖然深度學習模型（如CNN）能夠自動學習特徵，但這並不意味著特徵工程過時了。在許多問題（特別是表格數據）中，富有領域洞察力的手動特徵工程，仍然是拉開模型性能差距的關鍵。'
    },
    {
        question: '使用均值插補缺失值，最適合在哪種情況下使用？',
        options: {
            A: '當數據分佈是嚴重偏態時。',
            B: '當數據分佈接近對稱且離群值不多時。',
            C: '當缺失值的比例非常高時。',
            D: '當特徵是類別型時。'
        },
        correctAnswer: 'B',
        explanation: '均值對離群值非常敏感。如果數據分佈對稱且沒有太多離群值，均值可以較好地代表中心趨勢。若是偏態分佈，使用中位數插補通常是更好的選擇。'
    },
    {
        question: '下列哪個模型對輸入特徵的尺度最不敏感？',
        options: {
            A: '線性迴歸',
            B: '支援向量機 (SVM)',
            C: 'K-均值聚類',
            D: '決策樹 / 隨機森林'
        },
        correctAnswer: 'D',
        explanation: '基於樹的模型在進行節點分裂時，只關心特徵值的順序和分裂點，而不關心其絕對大小。因此，它們對特徵的尺度不敏感，通常不需要進行特徵縮放。'
    },
    {
        question: '「維度災難」指的是什麼？',
        options: {
            A: '數據的維度太低，資訊量不足。',
            B: '當數據的維度（特徵數量）過高時，導致數據稀疏、計算困難和模型性能下降。',
            C: '數據庫無法儲存高維數據。',
            D: '高維數據無法被視覺化。'
        },
        correctAnswer: 'B',
        explanation: '在高維空間中，數據點之間的距離變得很大且意義不大，要覆蓋整個特徵空間需要指數級增長的數據量，這給機器學習帶來了巨大的挑戰。'
    },
    {
        question: '下列何者不是數據清洗的任務？',
        options: {
            A: '處理缺失值',
            B: '處理離群值',
            C: '統一數據格式',
            D: '選擇機器學習演算法'
        },
        correctAnswer: 'D',
        explanation: '選擇演算法屬於「模型選擇」階段，是在數據準備完成之後才進行的。數據清洗專注於提升數據本身的品質。'
    },
    {
        question: '在自動光學檢測(AOI)中，由品管人員精確地框出圖片中的各種瑕疵類型及其位置，這個過程稱為什麼？',
        options: {
            A: '數據清洗',
            B: '數據標註',
            C: '特徵工程',
            D: '模型選擇'
        },
        correctAnswer: 'B',
        explanation: '這是為監督式學習（物件偵測）準備訓練數據的過程，即為每個樣本（圖片）添加正確的「答案」（瑕疵的類別和位置標籤）。'
    },
    {
        question: '下列哪個選項是「過濾法(Filter Methods)」進行特徵選擇的例子？',
        options: {
            A: '遞歸特徵消除 (RFE)',
            B: 'L1 正規化 (Lasso)',
            C: '使用皮爾森相關係數(Pearson correlation)來篩選與目標變數最相關的特徵。',
            D: '主成分分析 (PCA)'
        },
        correctAnswer: 'C',
        explanation: '過濾法在模型訓練之前，獨立地使用統計指標（如相關係數、卡方檢定）來評估每個特徵的重要性，並篩選掉得分較低的特徵。'
    },
    {
        question: '在數據準備階段，處理類別型特徵時，如果一個特徵的類別過多（例如，城市名稱），獨熱編碼可能會導致什麼問題？',
        options: {
            A: '特徵空間維度過高，計算成本增加。',
            B: '模型欠擬合。',
            C: '數據洩漏。',
            D: '無法處理缺失值。'
        },
        correctAnswer: 'A',
        explanation: '高基數（high-cardinality）的類別特徵進行獨熱編碼後會產生大量新的、稀疏的特徵，導致維度災難。在這種情況下，通常需要採用其他編碼方法（如目標編碼）或將其視為實體嵌入。'
    },
    {
        question: '下列何者是「偏差-方差權衡(Bias-Variance Tradeoff)」在模型選擇中的應用？',
        options: {
            A: '總是選擇最複雜的模型，因為偏差最小。',
            B: '總是選擇最簡單的模型，因為方差最小。',
            C: '尋找一個複雜度適中的模型，使其在驗證集上的總誤差最小。',
            D: '這個概念與模型選擇無關。'
        },
        correctAnswer: 'C',
        explanation: '模型選擇的藝術，就是在欠擬合（高偏差）和過擬合（高方差）之間找到一個最佳的平衡點，這個平衡點通常對應著在未見過數據上的最佳性能。'
    },
    {
        question: '為何在選擇模型時，應考慮到專案的部署環境？',
        options: {
            A: '因為部署環境決定了數據的品質。',
            B: '因為如果需要在邊緣設備（如手機）上運行，就必須選擇輕量、推論速度快的模型。',
            C: '因為雲端部署只能使用特定品牌的模型。',
            D: '部署環境與模型選擇無關。'
        },
        correctAnswer: 'B',
        explanation: '模型選擇不僅是準確率的競賽，還必須考慮到現實的工程限制。一個在雲端 GPU 上運行的巨大模型，是無法被部署到資源受限的手機上的。'
    },
    {
        question: '在處理不平衡數據集時，下列哪種數據準備技術是常用的？',
        options: {
            A: '主成分分析 (PCA)',
            B: '過採樣 (Oversampling) 少數類或欠採樣 (Undersampling) 多數類。',
            C: '獨熱編碼 (One-Hot Encoding)',
            D: '特徵縮放 (Feature Scaling)'
        },
        correctAnswer: 'B',
        explanation: '過採樣（如 SMOTE）或欠採樣是直接在數據層面處理類別不平衡問題的常用方法，旨在讓模型在訓練時能更均衡地看待不同類別的樣本。'
    },
    {
        question: '下列何者不是特徵工程的常見任務？',
        options: {
            A: '處理缺失值',
            B: '處理類別特徵',
            C: '建立多項式特徵',
            D: '部署模型 API'
        },
        correctAnswer: 'D',
        explanation: '部署模型 API 屬於模型部署階段，是將訓練好的模型產品化的工程任務，而非數據準備或特徵工程的範疇。'
    },
    {
        question: '「特徵工程的自動化」指的是什麼？',
        options: {
            A: '讓業務人員自己動手做特徵工程。',
            B: '使用工具（如 Featuretools）或技術（如深度學習）來自動地從原始數據中生成和選擇特徵。',
            C: '將特徵工程的任務完全外包。',
            D: '不再需要任何特徵工程。'
        },
        correctAnswer: 'B',
        explanation: '隨著技術的發展，越來越多的工具和方法被提出來自動化部分繁瑣的特徵工程工作，以提升數據科學家的工作效率。'
    },
    {
        question: '在模型選擇時，如果數據量非常小，應該優先考慮哪種模型？',
        options: {
            A: '一個非常深的卷積神經網路。',
            B: '一個參數很多的梯度提升機。',
            C: '一個簡單的、高偏差的模型，如邏輯迴歸或帶有強正規化的線性迴歸。',
            D: '一個集成模型。'
        },
        correctAnswer: 'C',
        explanation: '在小數據集上，過擬合是主要的風險。選擇一個簡單的、複雜度較低的模型，或者使用強力的正規化來限制模型的複雜度，是避免過擬合的有效策略。'
    },
    {
        question: '下列哪個選項最能描述數據準備的迭代性質？',
        options: {
            A: '數據準備只需要做一次，完成後就不再變動。',
            B: '數據準備是一個線性的、按部就班的過程。',
            C: '在模型訓練和評估後，可能會發現新的數據問題或特徵工程思路，需要回到數據準備階段進行調整。',
            D: '數據準備的流程每天都會完全改變。'
        },
        correctAnswer: 'C',
        explanation: '整個機器學習流程是高度迭代的。模型的評估結果會反過來指導我們如何更好地準備數據和設計特徵，這是一個不斷循環優化的過程。'
    }
  ],
  L21302: [
    {
      question: '將AI模型、程式碼及其所有依賴的函式庫、環境配置打包成一個輕量、可移植的標準化單元，這種技術稱為什麼？',
      options: {
        A: '虛擬化 (Virtualization)',
        B: '容器化 (Containerization)',
        C: '序列化 (Serialization)',
        D: '編譯 (Compilation)'
      },
      correctAnswer: 'B',
      explanation: '容器化（以Docker為代表）解決了軟體開發和部署中「在我電腦上可以跑」的經典問題。它將應用及其所有依賴打包在一起，確保了從開發到生產的環境一致性，是現代軟體部署和MLOps的基石。'
    },
    {
      question: '下列哪種模型部署模式最適合需要即時反饋的應用，如線上推薦系統或信用卡詐欺偵測？',
      options: {
        A: '批次預測 (Batch Prediction)',
        B: '線上即時預測 (Online Prediction)',
        C: '離線訓練 (Offline Training)',
        D: '邊緣部署 (Edge Deployment)'
      },
      correctAnswer: 'B',
      explanation: '線上即時預測模式將模型部署為一個持續運行的API服務，能夠隨時接收單筆請求並在毫秒級內返回預測結果，滿足了對低延遲有嚴格要求的應用場景。'
    },
    {
      question: 'MLOps的核心目標是什麼？',
      options: {
        A: '最大化單個模型的準確率。',
        B: '撰寫最詳細的技術文件。',
        C: '實現機器學習工作流程的自動化、標準化和可持續性。',
        D: '減少對GPU資源的使用。'
      },
      correctAnswer: 'C',
      explanation: 'MLOps旨在將DevOps的最佳實踐應用於機器學習領域，通過建立自動化的CI/CD/CT管道，來加速模型的迭代、提高部署的可靠性，並實現對已部署模型的全生命週期管理。'
    },
    {
      question: '將AI模型直接部署在手機、攝影機等終端設備上，在本地進行預測，這種模式被稱為什麼？',
      options: {
        A: '雲端部署 (Cloud Deployment)',
        B: '批次部署 (Batch Deployment)',
        C: '邊緣部署 (Edge Deployment)',
        D: 'API部署 (API Deployment)'
      },
      correctAnswer: 'C',
      explanation: '邊緣部署將計算推向數據產生的源頭，其主要優勢包括極低的延遲、節省網路頻寬以及更好地保護用戶隱私（因為數據無需上傳到雲端）。'
    },
    {
      question: '在MLOps中，CT (Continuous Training) 指的是什麼？',
      options: {
        A: '持續的程式碼測試 (Continuous Testing)',
        B: '持續的團隊溝通 (Continuous Talking)',
        C: '自動化的模型再訓練流程 (Continuous Training)',
        D: '持續的成本追蹤 (Continuous Tracking)'
      },
      correctAnswer: 'C',
      explanation: '持續訓練（CT）是MLOps相對於傳統DevOps所特有的概念。它指的是建立一個自動化的管道，能夠在監測到數據漂移或性能下降時，自動觸發新的訓練任務，生成新版模型，實現模型的持續學習與自我優化。'
    },
    {
      question: 'Kubernetes (K8s) 在AI系統部署中扮演什麼角色？',
      options: {
        A: '一個用來編寫Python程式碼的IDE。',
        B: '一個用於自動化部署、擴展和管理大規模容器化應用的平台。',
        C: '一個專門用於訓練深度學習模型的函式庫。',
        D: '一個數據庫管理系統。'
      },
      correctAnswer: 'B',
      explanation: 'Kubernetes是一個容器編排平台。在AI系統中，它負責管理運行著AI模型的成百上千個Docker容器，處理負載均衡、服務發現、自動擴展和故障恢復等複雜的維運工作。'
    },
    {
      question: '對已部署的模型進行監控時，除了CPU使用率、延遲等系統指標，更重要的是監控哪類指標？',
      options: {
        A: '程式碼的行數。',
        B: '模型的預測準確率、數據分佈漂移等性能指標。',
        C: '開發團隊成員的數量。',
        D: '專案的總預算。'
      },
      correctAnswer: 'B',
      explanation: '一個系統運行正常的「殭屍模型」可能正在持續地做出錯誤的預測。因此，對模型本身的性能指標（如準確率）和輸入數據的統計分佈進行監控，是及時發現模型因數據漂移而失效的關鍵。'
    },
    {
      question: '下列何者是手動、非自動化的模型部署流程可能帶來的最大問題？',
      options: {
        A: '可以確保最高的模型準確率。',
        B: '效率低下、容易出錯，且難以追溯和重現。',
        C: '完全不需要任何人力成本。',
        D: '可以非常快速地響應業務變化。'
      },
      correctAnswer: 'B',
      explanation: '手動部署流程充滿了人為錯誤的風險（如拷錯文件、配錯環境），整個過程耗時且不透明。當出現問題時，很難追溯是哪個環節出錯。MLOps的自動化管道正是為了解決這些問題。'
    },
    {
      question: '某銀行每晚利用AI模型對當天所有客戶的行為數據重新計算信用評分，並更新到資料庫中。這屬於哪種部署模式？',
      options: {
        A: '線上即時預測',
        B: '邊緣部署',
        C: '批次預測',
        D: '模型服務化'
      },
      correctAnswer: 'C',
      explanation: '批次預測的特點是定期、對累積的一大批數據進行處理，不要求即時性。這種按計畫運行的、高吞吐量的處理模式非常適合報表生成、數據同步、批量評分等場景。'
    },
    {
      question: '下列哪一項不是容器化技術（如Docker）為AI模型部署帶來的好處？',
      options: {
        A: '保證了開發、測試和生產環境的一致性。',
        B: '簡化了對複雜依賴庫的管理。',
        C: '自動提升模型的預測準確率。',
        D: '使得模型可以輕鬆地在不同雲平台之間遷移。'
      },
      correctAnswer: 'C',
      explanation: '容器化是一項解決環境配置和依賴問題的部署技術，它能確保模型穩定運行，但它本身不會對模型的演算法或預測準確率產生任何影響。模型的準確率取決於數據和訓練過程。'
    },
    {
        question: '串流預測(Streaming Prediction)的特點是什麼？',
        options: {
            A: '每天只處理一次數據。',
            B: '對持續產生的數據流進行近乎即時的處理。',
            C: '只在本地設備上運行。',
            D: '處理延遲通常在小時級別。'
        },
        correctAnswer: 'B',
        explanation: '串流預測是為處理連續不斷的數據流（如IoT感測器數據）而設計的，它能在數據到達時立即或以微小的延遲進行處理，延遲通常在秒級或毫秒級。'
    },
    {
        question: '在部署深度學習模型時，進行模型輕量化優化（如剪枝、量化）的主要目的是什麼？',
        options: {
            A: '為了增加模型的準確率。',
            B: '為了減少模型的大小和計算量，以適應邊緣部署或提升推論速度。',
            C: '為了讓模型更容易被解釋。',
            D: '為了增加模型的參數數量。'
        },
        correctAnswer: 'B',
        explanation: '大型深度學習模型通常計算量巨大，難以直接部署在資源受限的邊緣設備上。模型輕量化技術可以在盡量不損失準確率的前提下，大幅壓縮模型，使其能夠在邊緣設備上高效運行。'
    },
    {
        question: '下列何者是「基礎設施即代碼 (Infrastructure as Code, IaC)」的例子？',
        options: {
            A: '用Word文檔記錄伺服器的配置。',
            B: '手動登入雲端控制台來創建虛擬機。',
            C: '使用Terraform等工具，以代碼來定義和管理伺服器、網路等基礎設施。',
            D: '將基礎設施外包給第三方公司管理。'
        },
        correctAnswer: 'C',
        explanation: 'IaC將基礎設施的管理變為一個可版本控制、可重複、自動化的過程，大大提高了IT基礎設施管理的效率和可靠性。'
    },
    {
        question: '在MLOps中，模型倉庫(Model Registry)的主要作用是什麼？',
        options: {
            A: '一個用來儲存訓練數據的地方。',
            B: '一個集中管理、版本控制和追蹤所有已訓練模型的系統。',
            C: '一個用來購買現成AI模型的市場。',
            D: '一個討論AI模型的線上論壇。'
        },
        correctAnswer: 'B',
        explanation: '模型倉庫是MLOps流程中的一個關鍵組件，它為模型的生命週期管理提供了一個中央樞紐，讓我們可以追蹤哪個版本的模型正在被使用、其性能如何，並能輕鬆地進行回滾或部署新版本。'
    },
    {
        question: '灰度發布或金絲雀發布(Canary Release)是一種什麼樣的部署策略？',
        options: {
            A: '一次性將新模型上線給所有用戶。',
            B: '只在晚上進行模型部署。',
            C: '先將新模型發布給一小部分用戶，觀察其表現，再逐步擴大流量。',
            D: '將新舊模型同時上線，讓用戶自己選擇。'
        },
        correctAnswer: 'C',
        explanation: '這是一種低風險的部署策略。透過先在小範圍內測試新模型的真實表現，可以在問題影響到所有用戶之前及早發現並修復，大大提高了部署的安全性。'
    },
    {
        question: 'MLflow 是一個開源工具，它主要用於解決MLOps中的哪個問題？',
        options: {
            A: '實驗追蹤和模型管理',
            B: '數據標註',
            C: '容器編排',
            D: '數據庫管理'
        },
        correctAnswer: 'A',
        explanation: 'MLflow提供了一套工具來管理機器學習的整個生命週期，包括追蹤實驗的參數和結果、打包模型以便重現、以及管理模型的部署，是MLOps流程中的常用工具。'
    },
    {
        question: '為何說「模型性能衰退」是AI系統部署後幾乎一定會發生的事？',
        options: {
            A: '因為程式碼會隨著時間老化。',
            B: '因為伺服器會變慢。',
            C: '因為真實世界的數據分佈是不斷變化的，而模型是基於過去的數據訓練的。',
            D: '因為開發人員會故意讓模型變差。'
        },
        correctAnswer: 'C',
        explanation: '這就是數據漂移和概念漂移的影響。模型學到的是過去的模式，當現實世界發生變化（如新的競爭對手、新的用戶行為），這些舊的模式就會逐漸失效。'
    },
    {
        question: '下列何者不是系統集成階段需要考慮的問題？',
        options: {
            A: '定義清晰的API合約。',
            B: '處理系統間的數據傳輸。',
            C: '處理異常情況。',
            D: '選擇模型的訓練演算法。'
        },
        correctAnswer: 'D',
        explanation: '選擇演算法是在模型建立階段完成的。系統集成階段關注的是，如何將已經訓練好的模型API，安全、可靠地對接到現有的業務系統中。'
    },
    {
        question: 'TensorFlow Serving, TorchServe, NVIDIA Triton 等框架，主要用於解決什麼問題？',
        options: {
            A: '數據清洗',
            B: '模型訓練',
            C: '模型服務化 (Model Serving)',
            D: '數據可視化'
        },
        correctAnswer: 'C',
        explanation: '這些是專門為在生產環境中提供高性能、低延遲的模型推論服務而設計的框架，它們對並發請求、模型版本管理等進行了優化。'
    },
    {
        question: '下列何者不是邊緣部署的主要優點？',
        options: {
            A: '極低的延遲。',
            B: '節省網路頻寬。',
            C: '擁有最強大的計算能力。',
            D: '更好地保護用戶隱私。'
        },
        correctAnswer: 'C',
        explanation: '邊緣設備的計算能力通常遠遠弱於雲端伺服器，這也是為何邊緣部署需要對模型進行輕量化優化的原因。其優勢在於即時性、頻寬和隱私。'
    },
    {
        question: '一個MLOps成熟的組織，其模型更新的頻率通常是？',
        options: {
            A: '每幾年一次。',
            B: '永遠不更新。',
            C: '能夠根據監控結果，實現快速、甚至自動化的更新。',
            D: '只在更換硬體時才更新。'
        },
        correctAnswer: 'C',
        explanation: '成熟的MLOps流程旨在縮短模型從開發到部署的週期，實現快速迭代。一個好的系統應該能夠在幾天甚至幾小時內，安全地完成模型的更新。'
    },
    {
        question: '在MLOps流程中，持續整合(CI)不僅包括程式碼的整合，還包括什麼？',
        options: {
            A: '數據驗證和模型測試的自動化。',
            B: '團隊成員的績效評估。',
            C: '市場行銷活動的整合。',
            D: '財務報表的整合。'
        },
        correctAnswer: 'A',
        explanation: '在ML中，CI的範疇被擴大了。除了傳統的程式碼測試，還需要自動化地驗證新數據的品質、測試新模型的性能，以確保整個管道的品質。'
    },
    {
        question: '下列哪個情境最不適合使用批次預測？',
        options: {
            A: '每天凌晨生成一次銷售日報表。',
            B: '每月計算一次客戶的信用評分。',
            C: '對用戶在網站上的點擊行為進行即時商品推薦。',
            D: '每週對用戶進行一次分群。'
        },
        correctAnswer: 'C',
        explanation: '即時商品推薦需要對用戶的當前行為做出毫秒級的回應，這必須使用線上即時預測模式。批次預測的延遲太高，無法滿足此需求。'
    },
    {
        question: '將 AI 模型部署為 REST API，這屬於哪種部署技術？',
        options: {
            A: '容器化',
            B: '模型服務化',
            C: '容器編排',
            D: '基礎設施即代碼'
        },
        correctAnswer: 'B',
        explanation: '模型服務化是將訓練好的模型封裝起來，並透過一個標準化的接口（如 REST API 或 gRPC）將其預測能力暴露出來，供其他應用程式調用。'
    },
    {
        question: 'A/B 測試是部署新 AI 模型時常用的一種策略，它與下列哪個選項關係最密切？',
        options: {
            A: '數據清洗',
            B: '灰度發布/金絲雀發布',
            C: '批次預測',
            D: '邊緣部署'
        },
        correctAnswer: 'B',
        explanation: 'A/B 測試通常與灰度發布或金絲雀發布結合使用。先將新模型（B 組）的流量切換給一小部分用戶，並與舊模型（A 組）的表現進行比較，在確認新模型效果更好後，再逐步將所有流量切換到新模型。'
    },
    {
        question: '下列何者是模型監控中，針對「數據漂移」的監控？',
        options: {
            A: '監控 API 的 QPS（每秒查詢率）。',
            B: '監控伺服器的 CPU 使用率。',
            C: '監控輸入特徵的統計分佈（如均值、標準差）是否發生顯著變化。',
            D: '監控模型的檔案大小。'
        },
        correctAnswer: 'C',
        explanation: '數據漂移監控的核心是比較當前生產環境的數據分佈與模型訓練時的數據分佈。如果兩者出現顯著差異，就意味著模型賴以學習的基礎已經改變，其預測可能不再可靠。'
    },
    {
        question: '在一個成熟的 MLOps 流程中，當監控系統偵測到模型性能下降時，理想情況下應該觸發什麼？',
        options: {
            A: '自動發送一封警告郵件給 CEO。',
            B: '自動將系統關閉。',
            C: '自動觸發一個再訓練的管道 (CT)。',
            D: '自動回滾到最初始的模型版本。'
        },
        correctAnswer: 'C',
        explanation: '這體現了 MLOps 的自動化閉環。透過將監控與再訓練流程連接起來，可以讓 AI 系統具備一定程度的自我修復和持續學習能力。'
    },
    {
        question: '為何說 MLOps 需要跨職能的合作文化？',
        options: {
            A: '因為 MLOps 的工具非常昂貴。',
            B: '因為它涉及到數據科學、軟體工程和IT維運等多個領域，需要不同角色的緊密協作。',
            C: '因為只有專案經理才懂 MLOps。',
            D: '因為 MLOps 是一個非常獨立的部門。'
        },
        correctAnswer: 'B',
        explanation: 'MLOps 打破了傳統的部門壁壘。數據科學家、ML 工程師、數據工程師和維運人員需要像一個團隊一樣工作，共同對模型的整個生命週期負責。'
    },
    {
        question: 'gRPC 相較於 REST API，在模型服務化中有什麼優勢？',
        options: {
            A: 'gRPC 更容易被人類閱讀和調試。',
            B: 'gRPC 基於 HTTP/2，使用二進制協議，通常性能更高、延遲更低。',
            C: 'gRPC 只支持 Python 語言。',
            D: 'gRPC 的應用範圍更廣。'
        },
        correctAnswer: 'B',
        explanation: '對於需要高性能、低延遲的內部微服務通信，gRPC 因其高效的序列化和傳輸機制，通常是比基於文本的 REST API 更好的選擇。'
    },
    {
        question: '「模型債 (Model Debt)」這個概念提醒我們什麼？',
        options: {
            A: 'AI 模型的開發成本非常高。',
            B: '應該盡可能多地開發新模型。',
            C: '缺乏對 AI 系統的持續維護和治理，會積累大量的技術債務，最終導致系統崩潰。',
            D: 'AI 模型會隨著時間自動變好。'
        },
        correctAnswer: 'C',
        explanation: '模型債強調了 AI 系統的長期維護成本。如果只關注模型的上線，而忽略了後續的監控、版本控制、再訓練等工作，那麼系統的複雜性和脆弱性將會隨著時間不斷累積。'
    },
    {
        question: '將 AI 模型與企業現有的 CRM 或 ERP 系統進行對接，這屬於哪個階段？',
        options: {
            A: '模型訓練',
            B: '系統集成',
            C: '數據清洗',
            D: '特徵工程'
        },
        correctAnswer: 'B',
        explanation: '系統集成是將 AI 的能力真正嵌入到現有業務流程中的關鍵一步。它涉及到 API 的調用、數據的傳輸和格式轉換，以確保不同系統間能夠順利協作。'
    }
  ]
};
