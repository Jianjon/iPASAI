import type { PracticeQuestion } from '../../types';

export const L23_PRACTICE: Record<string, PracticeQuestion[]> = {
  L23101: [
    {
      question: '樸素貝氏分類器(Naive Bayes Classifier)的核心思想基於下列哪個數學定理？',
      options: {
        A: '中央極限定理 (Central Limit Theorem)',
        B: '大數法則 (Law of Large Numbers)',
        C: '貝氏定理 (Bayes\' Theorem)',
        D: '畢氏定理 (Pythagorean Theorem)'
      },
      correctAnswer: 'C',
      explanation: '樸素貝氏分類器直接應用貝氏定理，透過計算給定特徵下的後驗機率來進行分類。其「樸素」之處在於假設特徵之間是條件獨立的。'
    },
    {
        question: '在貝氏定理 P(H|E) = [P(E|H) * P(H)] / P(E) 中，P(H)代表什麼？',
        options: {
          A: '後驗機率 (Posterior)',
          B: '概似率 (Likelihood)',
          C: '先驗機率 (Prior)',
          D: '證據 (Evidence)'
        },
        correctAnswer: 'C',
        explanation: 'P(H)代表先驗機率，即在觀測到任何證據E之前，我們對假設H的初始信念或信心程度。'
    },
    {
        question: '最大概似估計(Maximum Likelihood Estimation, MLE)的核心思想是什麼？',
        options: {
          A: '選擇一組參數，使得模型的複雜度最大。',
          B: '選擇一組參數，使得在這組參數下，觀測到的數據樣本出現的機率最大。',
          C: '選擇一組參數，使得模型的預測誤差最大。',
          D: '選擇一組參數，使得先驗機率最大。'
        },
        correctAnswer: 'B',
        explanation: 'MLE試圖回答的問題是：「什麼樣的模型參數，最有可能產生我們現在觀測到的這組數據？」它透過最大化數據的概似率來估計參數。'
    },
    {
        question: '線性迴歸中的最小二乘法，在統計上等價於假設誤差服從何種分佈時的MLE？',
        options: {
          A: '伯努利分佈',
          B: '泊松分佈',
          C: '高斯(常態)分佈',
          D: '均勻分佈'
        },
        correctAnswer: 'C',
        explanation: '這為我們為什麼常用最小化均方誤差(MSE)來訓練線性迴歸提供了理論基礎。當假設殘差是常態分佈時，最大化其概似率的數學推導結果，恰好就是最小化MSE。'
    },
    {
        question: '隨機變數的「期望值(Expected Value)」代表什麼？',
        options: {
          A: '該變數最可能出現的值。',
          B: '該變數的長期平均值。',
          C: '該變數的最大值。',
          D: '該變數的變異程度。'
        },
        correctAnswer: 'B',
        explanation: '期望值是隨機變數所有可能取值與其對應機率的加權平均，代表了在大量重複試驗下，我們預期會觀測到的平均結果。'
    },
    {
        question: '下列何者是「變異數(Variance)」的定義？',
        options: {
          A: '數據的最大值與最小值之差。',
          B: '衡量數據點偏離其平均數的平均距離。',
          C: '衡量數據點偏離其期望值的平方的期望值。',
          D: '數據的中位數。'
        },
        correctAnswer: 'C',
        explanation: '變異數Var(X) = E[(X - E[X])²]，它量化了數據的整體波動性或分散程度。其平方根就是標準差。'
    },
    {
        question: '邏輯迴歸和神經網路中常用的「交叉熵損失函數」，其最小化過程等價於在哪種分佈假設下的MLE？',
        options: {
          A: '高斯分佈',
          B: '多項分佈/伯努利分佈',
          C: '泊松分佈',
          D: '指數分佈'
        },
        correctAnswer: 'B',
        explanation: '對於分類問題，我們通常假設數據的標籤服從伯努利分佈（二元分類）或多項分佈（多元分類）。在這一假設下，最大化概似率等價於最小化交叉熵損失。'
    },
    {
        question: '線性判別分析(Linear Discriminant Analysis, LDA)演算法，對數據的潛在分佈做出了什麼假設？',
        options: {
          A: '每個類別的數據都服從均勻分佈。',
          B: '每個類別的數據都服從高斯(常態)分佈。',
          C: '數據不服從任何特定分佈。',
          D: '數據是線性可分的。'
        },
        correctAnswer: 'B',
        explanation: 'LDA是一個生成式分類模型，它假設每個類別的數據都是從一個具有相同協方差矩陣的高斯分佈中抽樣出來的，並利用貝氏定理來找到決策邊界。'
    },
    {
        question: '為何說機率與統計是機器學習的基石？',
        options: {
          A: '因為所有機器學習演算法都是由統計學家發明的。',
          B: '因為它為在不確定性中進行推理、決策和從數據中學習提供了數學框架。',
          C: '因為機器學習的計算速度依賴於機率論。',
          D: '因為只有統計學背景的人才能學習機器學習。'
        },
        correctAnswer: 'B',
        explanation: '機器學習本質上就是一個從數據中進行推斷的過程，而機率論和統計學正是處理不確定性、從樣本推斷整體的科學，因此構成了機器學習的理論核心。'
    },
    {
        question: '樸素貝氏分類器的「樸素(Naive)」之處在於它做出了什麼簡化假設？',
        options: {
          A: '假設所有數據都服從常態分佈。',
          B: '假設特徵之間是條件獨立的。',
          C: '假設數據沒有任何噪聲。',
          D: '假設模型是線性的。'
        },
        correctAnswer: 'B',
        explanation: '「條件獨立假設」是指，在給定類別的情況下，模型假設所有特徵都是相互獨立的。這在現實中通常不成立，但這個簡化大大降低了模型的計算複雜度，且在實踐中效果依然很好。'
    }
  ],
  L23102: [
    {
      question: '在神經網路中，從一層到下一層的計算，主要依賴下列哪項線性代數運算？',
      options: {
        A: '矩陣求逆 (Matrix Inversion)',
        B: '特徵值分解 (Eigen-decomposition)',
        C: '矩陣乘法 (Matrix Multiplication)',
        D: '行列式計算 (Determinant Calculation)'
      },
      correctAnswer: 'C',
      explanation: '神經網路的前向傳播可以簡潔地表示為對輸入向量進行一系列的矩陣乘法（乘以權重矩陣）和向量加法（加上偏置向量），然後通過激活函數。'
    },
    {
        question: '主成分分析 (PCA) 是一種常用的降維技術，其數學原理是找到數據的？',
        options: {
            A: '協方差矩陣的特徵向量。',
            B: '均值和中位數。',
            C: '貝氏後驗機率。',
            D: '梯度向量。'
        },
        correctAnswer: 'A',
        explanation: 'PCA通過計算數據協方差矩陣的特徵向量和特徵值，來找到數據中方差最大的方向（主成分）。將數據投影到最重要的幾個主成分上，即可達到降維的目的。'
    },
    {
        question: '在機器學習中，一個數據樣本的所有特徵，通常被表示為什麼？',
        options: {
          A: '一個純量 (Scalar)',
          B: '一個特徵向量 (Feature Vector)',
          C: '一個矩陣 (Matrix)',
          D: '一個張量 (Tensor)'
        },
        correctAnswer: 'B',
        explanation: '將一個樣本的所有特徵（如[坪數, 屋齡, 房間數]）組織成一個有序的數字列表，即向量，是機器學習中表示數據點的標準方式。'
    },
    {
        question: '兩個向量的點積(內積)在機器學習中有何用途？',
        options: {
          A: '主要用於計算兩個向量的距離。',
          B: '可用於衡量兩個向量的相似度（如餘弦相似度）或計算一個向量在另一個向量上的投影。',
          C: '主要用於將向量降維。',
          D: '點積沒有實際用途。'
        },
        correctAnswer: 'B',
        explanation: '點積是一個非常基礎且重要的運算。例如，在詞向量中，兩個詞向量的點積（或由此計算的餘弦相似度）越大，代表它們的語義越相近。'
    },
    {
        question: '為何GPU（圖形處理器）在深度學習中扮演了關鍵角色？',
        options: {
          A: '因為GPU的記憶體比CPU大。',
          B: '因為GPU能更好地顯示圖像。',
          C: '因為GPU的架構使其能大規模並行地執行矩陣運算，極大地加速了模型訓練。',
          D: '因為GPU的程式設計比CPU簡單。'
        },
        correctAnswer: 'C',
        explanation: '深度學習的核心計算是大量的矩陣乘法。GPU擁有數千個小型核心，專為並行處理這類計算而設計，因此其訓練速度遠超只有少量核心的CPU。'
    },
    {
        question: '奇異值分解 (SVD) 在哪一類機器學習應用中有著經典的應用？',
        options: {
          A: '決策樹',
          B: '推薦系統 (基於矩陣分解的協同過濾)',
          C: 'K-均值聚類',
          D: '線性迴歸'
        },
        correctAnswer: 'B',
        explanation: 'SVD可以將一個巨大且稀疏的「用戶-商品」評分矩陣，分解為低維的用戶和商品隱藏因子矩陣。透過這兩個矩陣的乘積，可以預測用戶對未評分商品的評分，是矩陣分解類推薦演算法的核心。'
    },
    {
        question: '在主成分分析(PCA)中，我們通常選擇協方差矩陣的哪些特徵向量作為新的座標軸？',
        options: {
          A: '對應最小特徵值的特徵向量。',
          B: '對應最大特徵值的特徵向量。',
          C: '隨機選擇的特徵向量。',
          D: '所有特徵向量。'
        },
        correctAnswer: 'B',
        explanation: '特徵值的大小代表了數據在對應特徵向量方向上的方差大小。PCA選擇對應最大特徵值的特徵向量（主成分），是因為這些方向保留了數據中最多的資訊。'
    },
    {
        question: '一個神經網路的權重參數，通常被組織成什麼樣的線性代數結構？',
        options: {
          A: '向量',
          B: '矩陣',
          C: '純量',
          D: '集合'
        },
        correctAnswer: 'B',
        explanation: '一個神經層的所有連接權重，可以非常自然地表示為一個權重矩陣，其中行數是輸出神經元的數量，列數是輸入神經元的數量。'
    },
    {
        question: '為何說線性代數是機器學習的「語言」？',
        options: {
          A: '因為所有機器學習的程式碼都必須用線性代數符號寫。',
          B: '因為它提供了一種極其簡潔和高效的方式來表示和操作高維數據和模型。',
          C: '因為學習機器學習前必須先成為線性代數專家。',
          D: '因為線性代數是唯一的數學工具。'
        },
        correctAnswer: 'B',
        explanation: '線性代數將複雜的數據關係和模型運算，抽象為優雅的向量和矩陣操作，不僅讓演算法的表達變得簡潔，也使得利用現代硬體進行高效計算成為可能。'
    },
    {
        question: '下列關於線性代數的敘述何者「錯誤」？',
        options: {
          A: '整個數據集可以表示為一個矩陣。',
          B: '矩陣求逆的計算成本很低。',
          C: '一張灰階圖片可以看作一個矩陣。',
          D: 'SVD可以應用於任何m x n的矩陣。'
        },
        correctAnswer: 'B',
        explanation: '矩陣求逆的計算複雜度約為O(n³)，是一個計算成本非常高的操作，在處理大矩陣時需要盡量避免。'
    }
  ],
  L23103: [
    {
      question: '在訓練機器學習模型時，梯度下降法(Gradient Descent)中的「學習率(Learning Rate)」扮演什麼角色？',
      options: {
        A: '決定模型的最終準確率。',
        B: '控制每次參數更新的步長。',
        C: '衡量損失函數的複雜度。',
        D: '模型訓練需要花費的總時間。'
      },
      correctAnswer: 'B',
      explanation: '學習率是一個關鍵的超參數，它決定了在優化過程中沿著梯度反方向前進的每一步的大小。學習率過大會導致不收斂，過小則收斂太慢。'
    },
    {
        question: '相較於批量梯度下降，隨機梯度下降 (SGD) 的主要優點是什麼？',
        options: {
            A: '梯度計算更精確。',
            B: '收斂路徑更平滑。',
            C: '在處理大規模數據集時，更新速度更快。',
            D: '保證能找到全局最優解。'
        },
        correctAnswer: 'C',
        explanation: 'SGD每次只用一個樣本來更新參數，而批量梯度下降需要計算全部數據。因此在大數據集上，SGD的迭代速度遠遠快於批量梯度下降，儘管其收斂路徑會比較抖動。'
    },
    {
        question: '在機器學習中，幾乎所有問題最終都可以被看作是解決一個什麼問題？',
        options: {
          A: '分類問題',
          B: '迴歸問題',
          C: '優化問題',
          D: '統計問題'
        },
        correctAnswer: 'C',
        explanation: '機器學習的「學習」過程，在數學上就是一個尋找一組最佳模型參數，以最小化一個預定義的目標函數（損失函數）的優化過程。'
    },
    {
        question: '現代深度學習中最常用的梯度下降變體是什麼？',
        options: {
          A: '批量梯度下降 (Batch Gradient Descent)',
          B: '隨機梯度下降 (Stochastic Gradient Descent)',
          C: '小批量梯度下降 (Mini-batch Gradient Descent)',
          D: '沒有固定的常用方法。'
        },
        correctAnswer: 'C',
        explanation: '小批量梯度下降完美地平衡了批量梯度下降（梯度準確但慢）和隨機梯度下降（梯度噪聲大但快）的優缺點，是當前最主流、最高效的訓練方法。'
    },
    {
        question: 'Adam優化器為何會成為目前深度學習中的首選？',
        options: {
          A: '因為它的計算最簡單。',
          B: '因為它結合了動量(Momentum)和自適應學習率(如RMSprop)的優點，通常表現穩健且收斂快。',
          C: '因為它不需要設定任何超參數。',
          D: '因為它只適用於CPU。'
        },
        correctAnswer: 'B',
        explanation: 'Adam是一個非常強大且通用的優化器，它既能像動量一樣幫助加速收斂和越過鞍點，又能為每個參數自動調整學習率，使其在各種不同的任務和模型上都有很好的表現。'
    },
    {
        question: '在梯度下降法中，「梯度(Gradient)」指的是什麼？',
        options: {
          A: '損失函數的最小值。',
          B: '一個指向損失函數值上升最快方向的向量。',
          C: '模型參數的數量。',
          D: '學習率的大小。'
        },
        correctAnswer: 'B',
        explanation: '梯度由損失函數對各個參數的偏導數構成，它在幾何上指向了函數在某一點上變化率最大、上升最快的方向。因此，梯度下降法沿其相反方向更新參數。'
    },
    {
        question: '如果梯度下降的學習率設定得過大，最可能發生什麼情況？',
        options: {
          A: '收斂速度會變得非常慢。',
          B: '模型會很快地收斂到全局最優解。',
          C: '參數更新的步子太大，可能在最優解附近來回震盪，甚至發散，無法收斂。',
          D: '模型會發生欠擬合。'
        },
        correctAnswer: 'C',
        explanation: '學習率過大會導致「矯枉過正」，每一步都直接跨過了谷底，導致損失值不降反升或劇烈震盪。'
    },
    {
        question: '在深度神經網路的損失函數地形中，相比於局部最小值，「鞍點(Saddle Points)」是更常見的挑戰，其特點是什麼？',
        options: {
          A: '在所有維度上都是最小值。',
          B: '在所有維度上都是最大值。',
          C: '在某些維度是最小值，但在其他維度是最大值，此處梯度為零。',
          D: '梯度非常大的點。'
        },
        correctAnswer: 'C',
        explanation: '鞍點是高維優化中的一個難題。標準的梯度下降法在此處會因梯度為零而停滯，但動量和Adam等優化器有助於「衝」過這些平坦的鞍點區域。'
    },
    {
        question: '在目標函數中加入一個懲罰模型複雜度的「正規化項」，其主要目的是什麼？',
        options: {
          A: '加快模型的收斂速度。',
          B: '防止模型過擬合。',
          C: '增加模型的準確率。',
          D: '讓損失函數變為凸函數。'
        },
        correctAnswer: 'B',
        explanation: '正規化是一種對抗過擬合的核心技術。它透過懲罰過大的參數權重，來限制模型的複雜度，使其泛化能力更好。'
    },
    {
        question: '機器學習的「訓練」過程，在數學上可以被描述為什麼？',
        options: {
          A: '一個求解線性方程組的過程。',
          B: '一個最小化目標函數的數值優化過程。',
          C: '一個計算機率分佈的過程。',
          D: '一個矩陣分解的過程。'
        },
        correctAnswer: 'B',
        explanation: '整個訓練過程，無論多麼複雜的模型，其本質都是在尋找一組能讓損失函數最小化的參數。數值優化演算法就是實現這個目標的具體方法。'
    }
  ],
  L23201: [
    {
      question: '下列哪項任務屬於「非監督式學習 (Unsupervised Learning)」的範疇？',
      options: {
        A: '根據房屋特徵預測其售價。',
        B: '判斷一封郵件是否為垃圾郵件。',
        C: '根據用戶的購買歷史，將用戶自動分為不同群組。',
        D: '識別圖片中的動物是貓還是狗。'
      },
      correctAnswer: 'C',
      explanation: '用戶分群（聚類）是一個典型的非監督式學習任務，因為數據中沒有預先定義好的「群組」標籤，演算法需要自動從數據中發現其內在結構。A、B、D都是有明確標籤的監督式學習任務。'
    },
    {
        question: '一個模型在訓練集上表現極好，但在新的測試集上表現很差。這個現象被稱為什麼？',
        options: {
            A: '欠擬合 (Underfitting)',
            B: '過擬合 (Overfitting)',
            C: '偏差 (Bias)',
            D: '數據漂移 (Data Drift)'
        },
        correctAnswer: 'B',
        explanation: '過擬合指的是模型過度學習了訓練數據中的噪聲和細節，導致其失去了泛化到新數據的能力。高方差(Variance)是過擬合的數學體現。'
    },
    {
        question: '訓練一個機器手臂玩疊積木，透過獎勵（成功疊上一塊）和懲罰（積木倒塌）來學習策略，這屬於哪一類機器學習？',
        options: {
          A: '監督式學習',
          B: '非監督式學習',
          C: '強化學習',
          D: '半監督式學習'
        },
        correctAnswer: 'C',
        explanation: '強化學習的核心是智能體透過與環境的互動和獎勵回饋，來學習一個能最大化長期獎勵的決策策略，這與機器人控制和遊戲AI的場景非常吻合。'
    },
    {
        question: '在偏差-方差權衡中，「偏差(Bias)」指的是什麼？',
        options: {
          A: '模型對訓練數據中微小波動的敏感度。',
          B: '源於模型的簡化假設，導致模型無法捕捉到數據中真實的複雜關係。',
          C: '數據本身固有的噪聲。',
          D: '模型在訓練集上的錯誤率。'
        },
        correctAnswer: 'B',
        explanation: '高偏差源於模型過於簡單，無法擬合數據的真實模式，導致欠擬合。它衡量的是模型預測的平均值與真實值之間的差距。'
    },
    {
        question: '下列哪個問題是監督式學習中的「分類(Classification)」問題？',
        options: {
          A: '預測明天的股票價格。',
          B: '根據用戶評論判斷其情感是「正面」、「負面」還是「中性」。',
          C: '將新聞文章自動分為不同的主題。',
          D: '預測下一季度的公司總營收。'
        },
        correctAnswer: 'B',
        explanation: '情感分析的目標是預測一個離散的類別標籤（正面/負面/中性），因此是一個分類問題。A和D是迴歸問題，C是非監督式聚類問題。'
    },
    {
        question: '一個過於簡單的模型，在訓練集和測試集上表現都很差，這通常是什麼問題？',
        options: {
          A: '過擬合 (Overfitting)',
          B: '高方差 (High Variance)',
          C: '欠擬合 (Underfitting)',
          D: '數據洩漏 (Data Leakage)'
        },
        correctAnswer: 'C',
        explanation: '欠擬合的特徵就是模型過於簡單（高偏差），無法捕捉數據的基本模式，因此無論是在它學習過的訓練集上，還是在新的測試集上，表現都會很糟糕。'
    },
    {
        question: '機器學習的最終目標是什麼？',
        options: {
          A: '在訓練集上達到100%的準確率。',
          B: '找到最複雜的模型。',
          C: '讓模型在未見過的新數據上表現良好，即具備良好的泛化能力。',
          D: '最小化模型的訓練時間。'
        },
        correctAnswer: 'C',
        explanation: '一個只會「背誦」訓練數據的模型是沒有用的。機器學習的真正價值在於模型能從學習中「泛化」出規律，並將其應用到新的、從未見過的場景中。'
    },
    {
        question: '主成分分析(PCA)屬於哪一類機器學習？',
        options: {
          A: '監督式學習',
          B: '非監督式學習',
          C: '強化學習',
          D: '這不是機器學習'
        },
        correctAnswer: 'B',
        explanation: 'PCA是一種降維技術，它在沒有標籤的數據上運作，旨在發現數據中方差最大的方向（內部結構），因此屬於非監督式學習。'
    },
    {
        question: '增加模型複雜度（例如，增加決策樹的深度）通常會對偏差和方差產生什麼影響？',
        options: {
          A: '偏差和方差都增加。',
          B: '偏差和方差都降低。',
          C: '偏差降低，方差增加。',
          D: '偏差增加，方差降低。'
        },
        correctAnswer: 'C',
        explanation: '這正是偏差-方差權衡的核心。更複雜的模型能更好地擬合訓練數據，從而降低偏差；但它也更容易學習到數據中的噪聲，從而增加了方差。'
    },
    {
        question: '監督式學習、非監督式學習和強化學習，其最根本的區別在於什麼？',
        options: {
          A: '使用的程式語言不同。',
          B: '對硬體的要求不同。',
          C: '解決問題的目標和學習方式（回饋信號的類型）不同。',
          D: '開發者的背景不同。'
        },
        correctAnswer: 'C',
        explanation: '三者的根本區別在於它們的學習範式：監督式學習從「標籤」中學習，非監督式學習從「數據結構」中學習，而強化學習則從「獎勵信號」中學習。'
    }
  ],
  L23202: [
    {
        question: '下列哪個演算法是透過集成學習(Ensemble Learning)中Bagging的思想，構建大量的決策樹來提升性能？',
        options: {
            A: '邏輯迴歸 (Logistic Regression)',
            B: '支援向量機 (SVM)',
            C: '隨機森林 (Random Forest)',
            D: 'K-均值聚類 (K-Means)'
        },
        correctAnswer: 'C',
        explanation: '隨機森林的核心思想就是Bagging（Bootstrap Aggregating）和特徵隨機化。它並行地訓練多棵決策樹，並透過投票或平均來匯總結果，有效降低了單棵決策樹容易過擬合的問題。'
    },
    {
        question: '支援向量機(SVM)的核心思想是什麼？',
        options: {
          A: '找到一條能穿過最多數據點的線。',
          B: '建立一個模仿人類決策流程的樹狀結構。',
          C: '找到一個能將不同類別的數據點最大化間隔(Margin)地分開的決策邊界。',
          D: '將相似的數據點自動分組。'
        },
        correctAnswer: 'C',
        explanation: 'SVM是一個最大間隔分類器。其目標不僅是找到一個能分開數據的超平面，而是要找到那個能讓兩類數據點到該平面的距離都最遠、最「安全」的超平面。'
    },
    {
        question: 'K-均值聚類(K-Means)演算法中的「K」代表什麼？',
        options: {
          A: '演算法的最大迭代次數。',
          B: '數據集的特徵數量。',
          C: '使用者預先指定的簇的數量。',
          D: '演算法作者的名字。'
        },
        correctAnswer: 'C',
        explanation: 'K是K-Means演算法的一個關鍵超參數，必須在演算法運行前由使用者指定，它決定了最終要將數據分為幾群。'
    },
    {
        question: '下列哪個演算法最適合做為一個分類問題的「基準模型(Baseline Model)」？',
        options: {
          A: '深度神經網路',
          B: '隨機森林',
          C: '邏輯迴歸',
          D: '支援向量機 (帶高斯核)'
        },
        correctAnswer: 'C',
        explanation: '邏輯迴歸模型簡單、計算速度快、可解釋性強，非常適合在專案初期作為一個基準模型，來快速驗證流程並建立一個性能的底線。'
    },
    {
        question: 'SVM中的「核技巧(Kernel Trick)」主要解決了什麼問題？',
        options: {
          A: '加快模型的訓練速度。',
          B: '解決原始特徵空間中線性不可分的問題。',
          C: '減少模型的參數數量。',
          D: '讓模型更容易解釋。'
        },
        correctAnswer: 'B',
        explanation: '核技巧透過核函數，可以巧妙地在高維特徵空間中計算點積，而無需顯式地將數據映射到高維空間。這使得SVM能夠用一個線性的超平面，來解決原始空間中的非線性分類問題。'
    },
    {
        question: '隨機森林的「隨機」體現在哪兩個方面？',
        options: {
          A: '隨機選擇演算法 和 隨機設定K值。',
          B: '隨機抽樣訓練數據 (Bootstrap) 和 隨機選取部分特徵來分裂節點。',
          C: '隨機初始化權重 和 隨機設定學習率。',
          D: '隨機丟棄一半數據 和 隨機選擇一半特徵。'
        },
        correctAnswer: 'B',
        explanation: '這兩個「隨機」的過程，確保了森林中的每一棵樹都是不同的，從而增加了模型的多樣性，這是Bagging類集成方法成功的關鍵。'
    },
    {
        question: '下列哪個演算法「不」屬於監督式學習？',
        options: {
          A: '線性迴歸',
          B: '決策樹',
          C: '支援向量機',
          D: 'K-均值聚類'
        },
        correctAnswer: 'D',
        explanation: 'K-均值聚類是在沒有標籤的數據上尋找模式，屬於非監督式學習。其他三個都是典型的監督式學習演算法。'
    },
    {
        question: '單棵決策樹的一個主要缺點是什麼？',
        options: {
          A: '模型過於簡單，容易欠擬合。',
          B: '模型容易過擬合，且對數據的微小變動很敏感。',
          C: '模型無法處理類別型特徵。',
          D: '模型的可解釋性很差。'
        },
        correctAnswer: 'B',
        explanation: '如果沒有進行剪枝等限制，單棵決策樹會傾向於不斷分裂，直到完美地擬合訓練數據，這使其非常容易過擬合，且不穩定。隨機森林正是為了解決這個問題而生。'
    },
    {
        question: '線性迴歸和邏輯迴歸的主要區別是什麼？',
        options: {
          A: '線性迴歸是監督式學習，邏輯迴歸是非監督式學習。',
          B: '線性迴歸預測連續數值，邏輯迴歸用於分類。',
          C: '線性迴歸使用梯度下降，邏輯迴歸不使用。',
          D: '線性迴歸更準確。'
        },
        correctAnswer: 'B',
        explanation: '這是兩者最根本的區別。雖然名字相似，但它們解決的問題類型完全不同：一個用於迴歸，一個用於分類。'
    },
    {
        question: '在K-Means演算法的迭代過程中，當每個簇的中心不再發生變化時，代表什麼？',
        options: {
          A: '演算法出錯了，需要重啟。',
          B: '演算法已經收斂，聚類過程完成。',
          C: '需要增加K的值。',
          D: '需要減少K的值。'
        },
        correctAnswer: 'B',
        explanation: '當簇中心和點的分配都穩定下來，不再有任何數據點會被重新分配到另一個簇時，演算法就達到了收斂狀態，找到了（可能是局部的）最優解。'
    }
  ],
  L23203: [
    {
        question: '卷積神經網路 (CNN) 特別適用於處理圖像數據，其關鍵的優勢在於？',
        options: {
            A: '能夠處理時間序列的依賴關係。',
            B: '模型結構簡單，參數非常少。',
            C: '透過權重共享和局部連接，高效地提取空間層次特徵。',
            D: '訓練過程不需要GPU。'
        },
        correctAnswer: 'C',
        explanation: 'CNN的卷積操作利用了圖像的空間局部性原理，透過權重共享的卷積核來提取局部特徵，大大減少了模型參數，並能學習到從邊緣、紋理到物體部件的層次化特徵表示。'
    },
    {
        question: '相較於傳統的循環神經網路 (RNN)，Transformer架構最主要的創新是什麼？',
        options: {
            A: '引入了卷積操作來處理文本。',
            B: '完全基於自注意力機制 (Self-Attention) 來捕捉序列中的依賴關係。',
            C: '使用了更複雜的門控單元。',
            D: '大幅減少了模型的參數數量。'
        },
        correctAnswer: 'B',
        explanation: 'Transformer的革命性在於它完全拋棄了RNN的循環結構，而是依賴自注意力機制來並行地計算序列中所有元素之間的關係，從而更有效地捕捉長距離依賴，並極大地提升了訓練的平行度。'
    },
    {
        question: '在神經網路中，為何需要使用非線性的「激活函數」(Activation Function)？',
        options: {
          A: '為了讓網路的輸出值總是在0和1之間。',
          B: '為了為網路引入非線性，使其能夠學習和擬合複雜的模式。',
          C: '為了加快網路的計算速度。',
          D: '為了減少網路的參數數量。'
        },
        correctAnswer: 'B',
        explanation: '如果沒有非線性的激活函數，那麼一個多層的神經網路，在數學上就等價於一個單層的線性模型，無論多深都無法學習非線性關係。非線性是深度學習強大能力的關鍵。'
    },
    {
        question: '傳統RNN在處理長序列時，會遇到什麼主要問題？',
        options: {
          A: '過擬合',
          B: '梯度消失/爆炸',
          C: '計算成本過高',
          D: '模型無法並行計算'
        },
        correctAnswer: 'B',
        explanation: '由於RNN的循環結構，在反向傳播時，梯度需要連乘多次。這導致梯度很容易變得極小（消失）或極大（爆炸），使得模型難以學習到序列中的長距離依賴關係。'
    },
    {
        question: 'LSTM 和 GRU 是RNN的變體，它們主要透過引入什麼機制來解決長距離依賴問題？',
        options: {
          A: '注意力機制 (Attention Mechanism)',
          B: '殘差連接 (Residual Connection)',
          C: '門控機制 (Gating Mechanism)',
          D: '池化操作 (Pooling Operation)'
        },
        correctAnswer: 'C',
        explanation: 'LSTM和GRU引入了精巧的「輸入門」、「遺忘門」、「輸出門」等門控機制，讓網路能夠有選擇地、動態地決定要記住哪些歷史資訊、遺忘哪些無關資訊，從而更好地捕捉長期依賴。'
    },
    {
        question: '下列哪個深度學習框架以其動態計算圖和Pythonic的編程風格在學術界廣受歡迎？',
        options: {
          A: 'TensorFlow',
          B: 'PyTorch',
          C: 'Keras',
          D: 'Scikit-learn'
        },
        correctAnswer: 'B',
        explanation: 'PyTorch的動態計算圖（Define-by-Run）使得模型的調試和開發更加直觀和靈活，與Python的整合也非常好，因此深受研究人員和學術界的喜愛。'
    },
    {
        question: '在CNN中，「池化層(Pooling Layer)」的主要作用是什麼？',
        options: {
          A: '增加特徵圖的維度。',
          B: '學習圖像的顏色特徵。',
          C: '減少特徵圖的維度、降低計算量，並增加特徵的平移不變性。',
          D: '為圖像添加噪聲以防止過擬合。'
        },
        correctAnswer: 'C',
        explanation: '池化層（如最大池化）透過對特徵圖的局部區域進行下採樣，可以有效地減少後續層的計算負擔，並使模型對特徵的微小位移不那麼敏感。'
    },
    {
        question: '為何說深度學習是「數據饑渴(Data-hungry)」的？',
        options: {
          A: '因為深度學習模型只能處理大數據。',
          B: '因為深度學習模型通常有大量的參數，需要大量的數據才能有效訓練並避免過擬合。',
          C: '因為深度學習的開發者喜歡收集數據。',
          D: '因為數據越多，訓練速度越快。'
        },
        correctAnswer: 'B',
        explanation: '一個擁有數百萬甚至數十億參數的深度模型，如果只在少量數據上訓練，會輕易地「記住」所有訓練樣本，導致嚴重的過擬合。需要海量的數據才能讓模型學到具有泛化能力的模式。'
    },
    {
        question: '在深度學習中，Keras扮演什麼角色？',
        options: {
          A: '一個底層的計算引擎。',
          B: '一個專門用於部署的工具。',
          C: '一個更高級、更用戶友好的API，旨在簡化和加速模型的原型設計。',
          D: '一個數據庫。'
        },
        correctAnswer: 'C',
        explanation: 'Keras的設計理念是「為人類而非為機器設計」，它將許多複雜的底層操作封裝成簡單易用的API，讓開發者可以像搭積木一樣快速地構建和測試神經網路。'
    },
    {
        question: 'Transformer模型為何能夠高度平行化計算，而RNN不行？',
        options: {
          A: '因為Transformer的參數更少。',
          B: '因為Transformer完全拋棄了RNN的「循環」結構，對序列中所有元素的處理可以同時進行。',
          C: '因為Transformer是為CPU而非GPU設計的。',
          D: '因為Transformer使用了更多的激活函數。'
        },
        correctAnswer: 'B',
        explanation: 'RNN的計算是嚴格序列化的，必須處理完前一個時間步才能處理下一個。而Transformer的自注意力機制，可以一步到位地計算序列中所有元素之間的關係，這種計算沒有序列依賴，因此可以大規模並行化。'
    }
  ],
  L23301: [
    {
      question: '將一個包含「地區」特徵（如「信義區」、「大安區」）的欄位，轉換為多個二元（0/1）特徵欄位，這種處理方法被稱為什麼？',
      options: {
          A: '特徵縮放 (Feature Scaling)',
          B: '標籤編碼 (Label Encoding)',
          C: '獨熱編碼 (One-Hot Encoding)',
          D: '主成分分析 (PCA)'
      },
      correctAnswer: 'C',
      explanation: '獨熱編碼是處理無序類別特徵的標準方法，它避免為類別引入不應有的大小順序關係，讓模型能獨立地看待每一個類別。'
    },
    {
        question: '下列何者是「特徵洩漏 (Feature Leakage)」的典型例子？',
        options: {
            A: '在數據集劃分前，先對整個數據集進行標準化。',
            B: '從模型中移除了不相關的特徵。',
            C: '對訓練數據進行了數據增強。',
            D: '使用了L1正規化來進行特徵選擇。'
        },
        correctAnswer: 'A',
        explanation: '如果在劃分訓練/測試集之前，就使用了包含測試集資訊的統計量（如整個數據集的均值和標準差）來對訓練集進行轉換，這就將測試集的資訊洩漏給了訓練過程，會導致模型評估結果過於樂觀。'
    },
    {
        question: '下列哪個特徵選擇方法，是在模型訓練的過程中自動地進行特徵選擇？',
        options: {
          A: '過濾法 (Filter Methods)',
          B: '包裹法 (Wrapper Methods)',
          C: '嵌入法 (Embedded Methods)',
          D: '所有方法都是。'
        },
        correctAnswer: 'C',
        explanation: '嵌入法將特徵選擇作為模型訓練過程的一部分。最典型的例子是L1正規化(LASSO)，它在最小化損失的同時，會將不重要的特徵的權重懲罰至零。'
    },
    {
        question: '將特徵的數值減去其平均值，再除以其標準差，這種特徵縮放方法稱為什麼？',
        options: {
          A: '歸一化 (Normalization)',
          B: '標準化 (Standardization)',
          C: '標籤編碼 (Label Encoding)',
          D: '對數轉換 (Log Transform)'
        },
        correctAnswer: 'B',
        explanation: '標準化(Standardization)會將數據轉換為均值為0、標準差為1的分佈，是目前最常用、最通用的特徵縮放方法。'
    },
    {
        question: '為何說特徵工程極度依賴「領域知識」？',
        options: {
          A: '因為只有該領域的專家才能寫程式。',
          B: '因為創造有價值的特徵，需要對該業務或問題有深刻的理解。',
          C: '因為需要閱讀大量該領域的論文。',
          D: '因為領域知識可以取代數據。'
        },
        correctAnswer: 'B',
        explanation: '一個好的特徵，往往不是從數據中憑空產生的，而是基於對業務邏輯的深刻洞察。例如，在金融風控中，創造出「收入負債比」這個特徵，就需要金融領域的專業知識。'
    },
    {
        question: '在一個擁有百萬特徵的高維數據集上，包裹法(Wrapper Methods)為何不實用？',
        options: {
          A: '因為它找不到最佳的特徵子集。',
          B: '因為它的計算成本極其高昂。',
          C: '因為它只能用於低維數據。',
          D: '因為它會導致數據洩漏。'
        },
        correctAnswer: 'B',
        explanation: '包裹法需要反覆用不同的特徵子集來訓練和評估模型。在特徵數量巨大時，可能的特徵子集數量會呈指數級增長，導致計算上不可行。'
    },
    {
        question: '下列何者屬於「特徵創造」的例子？',
        options: {
          A: '刪除數據中的缺失值。',
          B: '將身高的單位從公分轉換為公尺。',
          C: '從用戶的交易記錄中，計算出「平均每筆交易金額」。',
          D: '將「地區」這個欄位進行獨熱編碼。'
        },
        correctAnswer: 'C',
        explanation: '特徵創造是從現有特徵中衍生出全新的、可能更有預測能力的特徵的過程。「平均每筆交易金額」就是從原始的交易流水數據中，經過計算和匯總後創造出來的新特徵。'
    },
    {
        question: '下列何者是「數據和特徵決定了機器學習的上限」這句話的含義？',
        options: {
          A: '只要有好的數據，用任何模型效果都一樣。',
          B: '模型和演算法的選擇不重要。',
          C: '模型的性能，根本上受限於輸入數據的品質和資訊量。',
          D: '數據越多，模型越複雜。'
        },
        correctAnswer: 'C',
        explanation: '這句話強調了在整個機器學習流程中，數據準備和特徵工程的根本性重要地位。一個好的模型是在逼近數據所能提供的資訊上限，如果數據本身不好，再好的模型也無能為力。'
    },
    {
        question: '過濾法(Filter Methods)進行特徵選擇的主要優點是什麼？',
        options: {
          A: '它考慮了特徵之間的交互作用。',
          B: '它的性能是所有方法中最好的。',
          C: '它的計算速度快，且與後續使用的模型無關。',
          D: '它不會移除任何特徵。'
        },
        correctAnswer: 'C',
        explanation: '過濾法在模型訓練前，獨立地對每個特徵進行評分。這個過程計算量小，速度快，並且評分結果是通用的，不依賴於後續選擇哪個具體的機器學習模型。'
    },
    {
        question: '將一個有序的類別特徵，如「學歷」（國中, 高中, 大學, 碩士），轉換為數字（0, 1, 2, 3），這種方法稱為什麼？',
        options: {
          A: '獨熱編碼 (One-Hot Encoding)',
          B: '標籤編碼 (Label Encoding)',
          C: '標準化 (Standardization)',
          D: '特徵雜湊 (Feature Hashing)'
        },
        correctAnswer: 'B',
        explanation: '對於本身就具有順序關係的類別特徵，使用標籤編碼將其轉換為有序的整數，是一種簡單且能保留其順序資訊的有效方法。'
    }
  ],
  L23302: [
    {
        question: '在機器學習工作流程中，測試集 (Test Set) 的主要用途是什麼？',
        options: {
            A: '用於訓練模型參數。',
            B: '用於調整模型的超參數。',
            C: '在模型開發完成後，提供一次性的、公正的最終性能評估。',
            D: '可以被多次使用以獲得最佳性能分數。'
        },
        correctAnswer: 'C',
        explanation: '為了得到模型在真實世界中泛化能力的無偏估計，測試集必須被「封存」起來，在整個模型選擇和調參過程結束後，才能拿出來使用一次。'
    },
    {
        question: '當數據量較少時，為了得到更穩健的模型性能評估，應優先考慮使用下列哪種方法？',
        options: {
            A: '使用更大的批次大小 (Batch Size)。',
            B: 'K-摺交叉驗證 (K-Fold Cross-Validation)。',
            C: '將數據全部用於訓練。',
            D: '使用固定的驗證集。'
        },
        correctAnswer: 'B',
        explanation: '交叉驗證透過多次劃分數據，讓每個樣本都有機會成為驗證集的一部分，從而得出的性能評估結果比單次劃分的結果更穩定、更可靠，有效降低了因數據劃分的隨機性帶來的偏差。'
    },
    {
        question: '在數據集劃分中，驗證集(Validation Set)的主要作用是什麼？',
        options: {
          A: '用於訓練最終的模型。',
          B: '用於報告模型的最終性能。',
          C: '用於在訓練過程中進行模型選擇和超參數調校。',
          D: '驗證集是不必要的，可以直接用測試集調參。'
        },
        correctAnswer: 'C',
        explanation: '驗證集像是一個「模擬考」，我們用它來調整模型的各種設定（如超參數），以找到最佳配置。而測試集則是「正式大考」，只能在所有調整都完成後用一次。'
    },
    {
        question: '在處理不平衡數據時，進行數據集劃分時應採用什麼策略，以確保每個集合中各類別的比例一致？',
        options: {
          A: '隨機劃分 (Random Split)',
          B: '按時間劃分 (Time-based Split)',
          C: '分層劃分 (Stratified Split)',
          D: '交替劃分 (Alternate Split)'
        },
        correctAnswer: 'C',
        explanation: '分層劃分可以確保在抽樣後，訓練集、驗證集和測試集中的類別分佈與原始數據集保持相同，這對於不平衡分類問題的可靠評估至關重要。'
    },
    {
        question: '下列何者是使用「遷移學習(Transfer Learning)」作為模型架構設計策略的主要好處？',
        options: {
          A: '可以完全不需要任何訓練數據。',
          B: '可以極大地加速模型收斂，並在數據量較少時取得更好效果。',
          C: '可以讓模型的可解釋性變得更高。',
          D: '可以降低模型的推論速度。'
        },
        correctAnswer: 'B',
        explanation: '遷移學習利用了在大型通用數據集上預訓練好的模型的知識，如同讓模型「站在巨人的肩膀上」。這使得模型在面對新任務時，能以更少的數據、更快地學會，並達到更好的性能。'
    },
    {
        question: '在預測未來銷量的時間序列問題中，如何劃分數據集才是正確的？',
        options: {
          A: '隨機地將所有數據點劃分為訓練集和測試集。',
          B: '按時間順序劃分，用過去的數據做訓練集，用未來的數據做測試集。',
          C: '只用最近的數據做訓練集，用過去的數據做測試集。',
          D: '將奇數日的數據做訓練集，偶數日的數據做測試集。'
        },
        correctAnswer: 'B',
        explanation: '時間序列問題的評估，必須模擬真實世界的預測場景，即用歷史數據來預測未來。隨機劃分會導致模型在訓練時「偷看」到未來的數據，造成嚴重的數據洩漏。'
    },
    {
        question: '為何需要建立一個「基準模型(Baseline Model)」？',
        options: {
          A: '因為基準模型通常是性能最好的。',
          B: '因為基準模型是所有專案的強制要求。',
          C: '因為它提供了一個性能的「底線」，可以快速驗證流程，並作為評估複雜模型價值的參考。',
          D: '因為基準模型最容易部署。'
        },
        correctAnswer: 'C',
        explanation: '基準模型的主要價值在於提供一個理性的比較基準。如果一個花費大量資源的複雜模型，其性能提升相對於簡單的基準模型微不足道，那麼這個複雜模型就是不值得的。'
    },
    {
        question: 'K-摺交叉驗證中的「K」代表什麼？',
        options: {
          A: '模型的超參數數量。',
          B: '將數據集劃分的子集數量。',
          C: '模型訓練的總次數。',
          D: '測試集的樣本數量。'
        },
        correctAnswer: 'B',
        explanation: '在K-摺交叉驗證中，我們將數據分為K個「摺」（子集），然後輪流將其中一個摺作為驗證集，其餘K-1個摺作為訓練集，重複K次。'
    },
    {
        question: '下列關於數據集劃分的敘述，何者「錯誤」？',
        options: {
          A: '測試集在整個建模過程中只能使用一次。',
          B: '驗證集用於超參數調校。',
          C: '為了獲得更好的模型性能，可以反覆用測試集來調整模型的超參數。',
          D: '訓練集用於訓練模型參數。'
        },
        correctAnswer: 'C',
        explanation: '這是一個非常嚴重的錯誤，被稱為「對測試集過擬合」。如果用測試集來指導模型的調整，那麼測試集就失去了其作為公正的最終評估的意義，報告的性能將是過於樂觀且不可信的。'
    },
    {
        question: '在設計一個深度學習模型的架構時，「模型容量(Capacity)」指的是什麼？',
        options: {
          A: '模型檔案的大小。',
          B: '模型的學習能力，通常由網路的深度和寬度決定。',
          C: '模型能處理的最大數據量。',
          D: '模型訓練所需的時間。'
        },
        correctAnswer: 'B',
        explanation: '模型容量代表了模型能擬合的函數的複雜程度。容量太小會導致欠擬合，無法學習數據模式；容量太大則容易過擬合，學習到數據中的噪聲。'
    }
  ],
  L23303: [
    {
        question: '在一個極度不平衡的數據集上（如99%為負類），哪個評估指標最可能產生誤導？',
        options: {
            A: '準確率 (Accuracy)',
            B: '精確率 (Precision)',
            C: '召回率 (Recall)',
            D: 'F1-Score'
        },
        correctAnswer: 'A',
        explanation: '在這種情況下，一個簡單地將所有樣本都預測為負類的「無用」模型，其準確率也能高達99%。因此，單看準確率會極具誤導性，必須結合精確率、召回率等其他指標。'
    },
    {
        question: 'ROC曲線下的面積 (AUC) 為1，代表什麼？',
        options: {
            A: '模型的性能相當於隨機猜測。',
            B: '模型是一個完美的分類器。',
            C: '模型將所有樣本都預測為正類。',
            D: '模型將所有樣本都預測為負類。'
        },
        correctAnswer: 'B',
        explanation: 'AUC衡量的是模型區分正負樣本的整體能力。AUC為1代表模型能夠完美地將所有正樣本的預測機率排在所有負樣本之前，是一個理想的、完美的分類器。AUC為0.5則相當於隨機猜測。'
    },
    {
        question: '在癌症篩檢模型中，我們最關心的是不能漏掉任何一個真正的病人。這意味著我們希望最大化哪個指標？',
        options: {
          A: '準確率 (Accuracy)',
          B: '精確率 (Precision)',
          C: '召回率 (Recall)',
          D: '真陰性率 (True Negative Rate)'
        },
        correctAnswer: 'C',
        explanation: '召回率(Recall = TP / (TP + FN))衡量的是在所有真正的正樣本中，有多少被模型成功找出來了。在醫療篩檢中，漏診（假陰性, FN）的代價極高，因此最大化召回率是首要目標。'
    },
    {
        question: '在垃圾郵件過濾器中，我們最不希望看到的是將一封重要的工作郵件錯判為垃圾郵件。這意味著我們希望最大化哪個指標？',
        options: {
          A: '準確率 (Accuracy)',
          B: '精確率 (Precision)',
          C: '召回率 (Recall)',
          D: '假陰性率 (False Negative Rate)'
        },
        correctAnswer: 'B',
        explanation: '精確率(Precision = TP / (TP + FP))衡量的是在所有被模型預測為正的樣本中，有多少是真正的正樣本。在垃圾郵件過濾中，錯殺（假陽性, FP）的代價很高，因此最大化精確率是首要目標。'
    },
    {
        question: '下列哪個是迴歸模型最常用的評估指標之一，其單位與目標變數相同，且對大誤差較為敏感？',
        options: {
          A: '平均絕對誤差 (MAE)',
          B: '均方誤差 (MSE)',
          C: '均方根誤差 (RMSE)',
          D: '決定係數 (R²)'
        },
        correctAnswer: 'C',
        explanation: 'RMSE是MSE的平方根，它將單位還原到與目標變數相同，使其更易於解釋。同時，由於計算中包含平方項，它會對較大的預測誤差給予更高的懲罰。'
    },
    {
        question: '一個房價預測模型的R²值為0.8，這代表什麼？',
        options: {
          A: '模型的準確率是80%。',
          B: '模型能夠解釋房價變異的80%。',
          C: '模型有80%的機率會預測錯誤。',
          D: '模型比基準模型差80%。'
        },
        correctAnswer: 'B',
        explanation: 'R²（決定係數）衡量的是自變數（特徵）能在多大程度上解釋應變數（目標）的變異。R²越高，表示模型的擬合效果越好。'
    },
    {
        question: '混淆矩陣(Confusion Matrix)是評估哪類模型的基礎？',
        options: {
          A: '迴歸模型',
          B: '分類模型',
          C: '聚類模型',
          D: '降維模型'
        },
        correctAnswer: 'B',
        explanation: '混淆矩陣詳細地總結了分類模型在各個類別上的預測表現（TP, FP, TN, FN），是計算準確率、精確率、召回率、F1-Score等一系列重要指標的基礎。'
    },
    {
        question: 'F1-Score是什麼？',
        options: {
          A: '精確率和召回率的算術平均數。',
          B: '精確率和召回率的調和平均數。',
          C: '準確率的另一種說法。',
          D: 'AUC的近似值。'
        },
        correctAnswer: 'B',
        explanation: 'F1-Score是精確率和召回率的調和平均數。當我們希望在這兩個指標之間取得平衡時，F1-Score是一個很好的綜合性評估指標。'
    },
    {
        question: '在模型訓練過程中，如果訓練集上的損失持續下降，但驗證集上的損失開始上升，這通常是什麼信號？',
        options: {
          A: '模型即將收斂到最優解。',
          B: '模型開始發生過擬合。',
          C: '模型發生了欠擬合。',
          D: '應該增加學習率。'
        },
        correctAnswer: 'B',
        explanation: '這是一個典型的過擬合信號。模型開始過度學習訓練數據中的噪聲，導致其在未見過的驗證集上的泛化能力下降。此時應考慮提前停止訓練。'
    },
    {
        question: '深度學習訓練中的「反向傳播(Backpropagation)」演算法，其主要作用是什麼？',
        options: {
          A: '計算模型的預測輸出。',
          B: '高效地計算損失函數對於網路上所有參數的梯度。',
          C: '更新模型的權重參數。',
          D: '對輸入數據進行預處理。'
        },
        correctAnswer: 'B',
        explanation: '反向傳播是訓練神經網路的核心演算法。它利用微積分中的鏈式法則，從輸出層開始，逐層向後高效地計算梯度，為後續的梯度下降參數更新提供方向。'
    }
  ],
  L23304: [
    {
        question: '下列哪項技術是透過結合多個「弱」學習器的預測，來得到一個更強大、更穩健的「強」學習器？',
        options: {
            A: '正規化 (Regularization)',
            B: '超參數調校 (Hyperparameter Tuning)',
            C: '集成學習 (Ensemble Learning)',

            D: '數據增強 (Data Augmentation)'
        },
        correctAnswer: 'C',
        explanation: '集成學習的核心思想就是「群策群力」。透過Bagging、Boosting、Stacking等方法，組合多個模型的預測，通常能獲得比任何單一模型都更好、更穩健的性能。'
    },
    {
        question: '在神經網路中加入Dropout層的主要目的是什麼？',
        options: {
            A: '加快模型的訓練速度。',
            B: '減少模型所需的記憶體。',
            C: '作為一種正規化手段，防止模型過擬合。',
            D: '增加模型的可解釋性。'
        },
        correctAnswer: 'C',
        explanation: 'Dropout透過在訓練時隨機地「關閉」一部分神經元，強迫網路學習到更具冗餘性和穩健性的特徵，這是一種非常有效的、防止模型過度依賴某些特定神經元的正規化技術。'
    },
    {
        question: '下列何者是模型的「超參數(Hyperparameter)」？',
        options: {
          A: '線性迴歸模型的權重。',
          B: '神經網路的偏置項。',
          C: '隨機森林中樹的數量 (n_estimators)。',
          D: '模型的預測結果。'
        },
        correctAnswer: 'C',
        explanation: '超參數是在模型訓練開始前，由人為設定的參數，它控制著學習過程。而模型參數（如權重和偏置）是模型在訓練過程中從數據中學習到的。'
    },
    {
        question: 'L1正規化(Lasso)和L2正規化(Ridge)最主要的區別是什麼？',
        options: {
          A: 'L1是懲罰權重的平方和，L2是懲罰絕對值之和。',
          B: 'L1傾向於讓權重變為零，從而實現特徵選擇；L2傾向於讓權重變小，但不為零。',
          C: 'L1只能用於迴歸，L2只能用於分類。',
          D: 'L1會增加模型偏差，L2會增加模型方差。'
        },
        correctAnswer: 'B',
        explanation: '這是兩者最關鍵的區別。L1的稀疏性使其具有內建的特徵選擇功能，而L2則更側重於讓模型權重整體更平滑，以提高泛化能力。'
    },
    {
        question: '下列哪種集成學習方法是「串行」地訓練模型，讓每個新模型都專注於修正前一個模型的錯誤？',
        options: {
          A: 'Bagging (如隨機森林)',
          B: 'Boosting (如梯度提升機)',
          C: 'Stacking',
          D: '投票法 (Voting)'
        },
        correctAnswer: 'B',
        explanation: 'Boosting的核心思想是迭代和專注於困難樣本。模型是依次、串行地構建的，後一個模型是在前一個模型的基礎上進行改進，其主要目的是降低偏差。'
    },
    {
        question: '「提前停止(Early Stopping)」是一種防止過擬合的技巧，它依賴於監控模型在哪個數據集上的性能？',
        options: {
          A: '訓練集 (Training Set)',
          B: '驗證集 (Validation Set)',
          C: '測試集 (Test Set)',
          D: '整個數據集'
        },
        correctAnswer: 'B',
        explanation: '提前停止的依據是模型在「未見過」的驗證集上的泛化能力。當模型在驗證集上的性能不再提升時，就應停止訓練，以防止其開始對訓練集過擬合。'
    },
    {
        question: '對圖像進行隨機旋轉、裁剪、翻轉、調整亮度等操作，來人工地創造更多樣化的訓練樣本，這種技術稱為什麼？',
        options: {
          A: '特徵工程',
          B: '數據增強',
          C: '數據清洗',
          D: '數據標準化'
        },
        correctAnswer: 'B',
        explanation: '數據增強是一種非常有效的、低成本的正規化技術，它透過對現有數據進行變換來擴充數據集，讓模型學到對這些變換不變的特徵，從而提升穩健性和泛化能力。'
    },
    {
        question: '下列哪種超參數調校方法，效率最高、最智能？',
        options: {
          A: '網格搜索 (Grid Search)',
          B: '隨機搜索 (Random Search)',
          C: '手動調校 (Manual Tuning)',
          D: '貝氏優化 (Bayesian Optimization)'
        },
        correctAnswer: 'D',
        explanation: '貝氏優化會根據已有的試驗結果，來有指導性地選擇下一個最有可能提升性能的超參數組合，而不是像網格搜索或隨機搜索那樣盲目地嘗試，因此效率最高。'
    },
    {
        question: '下列哪個演算法「不」屬於集成學習？',
        options: {
          A: '隨機森林 (Random Forest)',
          B: '梯度提升機 (Gradient Boosting Machine)',
          C: '支援向量機 (Support Vector Machine)',
          D: 'AdaBoost'
        },
        correctAnswer: 'C',
        explanation: '支援向量機是一個單一的、獨立的演算法。而A、B、D都是集成學習的代表性演算法，它們都結合了多個基礎模型的預測。'
    },
    {
        question: '在超參數調校時，需要警惕在「驗證集」上過度調參，這個問題被稱為什麼？',
        options: {
          A: '數據洩漏',
          B: '對驗證集過擬合',
          C: '欠擬合',
          D: '模型偏差'
        },
        correctAnswer: 'B',
        explanation: '如果我們在驗證集上嘗試了過多的超參數組合，我們的模型和超參數選擇，實際上是在間接地「擬合」這個特定的驗證集。這就是需要一個獨立的、從未參與調參的「測試集」來進行最終評估的原因。'
    }
  ],
  L23401: [
    {
        question: '下列哪種隱私保護技術，旨在提供數學上可證明的隱私保證，使得模型的輸出結果幾乎不受任何單個用戶數據的影響？',
        options: {
            A: '數據去識別化 (De-identification)',
            B: '差分隱私 (Differential Privacy)',
            C: 'K-匿名 (K-Anonymity)',
            D: '數據加密 (Encryption)'
        },
        correctAnswer: 'B',
        explanation: '差分隱私是當前隱私保護領域的黃金標準。它透過在查詢結果或模型參數中注入經過精確計算的噪聲，來模糊化單個數據點的貢獻，從而提供強大的隱私保護。'
    },
    {
        question: '在機器學習治理中，「最小化原則」指的是什麼？',
        options: {
            A: '盡可能地減小模型的檔案大小。',
            B: '只收集為了達成特定業務目的所必需的最少量數據。',
            C: '最小化模型訓練所需的時間。',
            D: '最小化模型的預測誤差。'
        },
        correctAnswer: 'B',
        explanation: '數據最小化是GDPR等隱私法規的核心原則之一，它要求企業在設計數據收集流程時，應避免收集非必要的個人數據，以從源頭上降低隱私風險。'
    },
    {
        question: '「數據保留在本地，只有模型的更新被加密後傳回中央伺服器進行聚合」，這描述了哪種隱私保護技術？',
        options: {
          A: '差分隱私',
          B: '聯邦學習',
          C: '數據加密',
          D: '數據去識別化'
        },
        correctAnswer: 'B',
        explanation: '聯邦學習是一種分散式的機器學習方法，它的核心優勢在於，原始的、可能包含敏感資訊的數據永遠不需要離開用戶的設備或本地伺服器，從而極大地保護了數據隱私。'
    },
    {
        question: '根據GDPR，「反對自動化決策權」保障了用戶在面對何種情況下的權利？',
        options: {
          A: '當AI模型的準確率低於90%時。',
          B: '當AI系統做出對個人有重大影響的自動化決策（如拒絕貸款）時，有權要求人工複核。',
          C: '當用戶不喜歡AI的介面時。',
          D: '當AI的訓練時間過長時。'
        },
        correctAnswer: 'B',
        explanation: '這項權利旨在保護個人免受純粹由演算法做出的、不透明且可能不公平的決策的影響，確保在關鍵決策上的人工監督。'
    },
    {
        question: '實施「最小權限原則」是為了防範哪一類安全風險？',
        options: {
          A: '外部駭客的網路攻擊。',
          B: '因內部人員疏失或帳號被盜導致的未授權訪問。',
          C: '數據在傳輸過程中被竊聽。',
          D: 'AI模型的對抗性攻擊。'
        },
        correctAnswer: 'B',
        explanation: '最小權限原則透過確保每個用戶只能訪問其工作所必需的最少量數據，來限制單點故障（如某個員工帳號被盜）可能造成的損害範圍。'
    },
    {
        question: '攻擊者故意向訓練數據中注入精心設計的惡意樣本，以破壞模型的性能，這種攻擊稱為什麼？',
        options: {
          A: '數據中毒 (Data Poisoning)',
          B: '對抗性攻擊 (Adversarial Attacks)',
          C: '模型竊取 (Model Stealing)',
          D: '數據漂移 (Data Drift)'
        },
        correctAnswer: 'A',
        explanation: '數據中毒是一種從源頭污染AI的攻擊，透過污染訓練數據來破壞最終模型的準確性或植入後門，屬於數據安全議題。'
    },
    {
        question: '在機器學習治理中，「隱私與效用的權衡」指的是什麼？',
        options: {
          A: '隱私保護越強，模型就越有用。',
          B: '過於強力的隱私保護措施（如加入過多噪聲）可能會降低數據的可用性和分析模型的準確性。',
          C: '隱私和效用是兩個完全獨立、不相關的概念。',
          D: '只有在模型效用很低時才需要考慮隱私。'
        },
        correctAnswer: 'B',
        explanation: '這是一個關鍵的權衡關係。例如，在差分隱私中，注入的噪聲越多，隱私保護程度越高，但數據的信號也會被淹沒得越嚴重，導致模型準確率下降。需要在兩者之間找到平衡。'
    },
    {
        question: '對抗性訓練(Adversarial Training)是為了提升模型的什麼特性？',
        options: {
          A: '可解釋性',
          B: '準確性',
          C: '穩健性 (對抗惡意攻擊的能力)',
          D: '訓練速度'
        },
        correctAnswer: 'C',
        explanation: '對抗性訓練的核心思想是，在訓練過程中，主動地生成對抗性樣本並將其加入訓練集，讓模型學會如何應對這些惡意擾動，從而提升其在面對攻擊時的穩健性。'
    },
    {
        question: '下列何者是「告知同意」原則的正確實踐？',
        options: {
          A: '在服務條款中用非常小的字體說明。',
          B: '預設所有用戶都同意，除非他們主動反對。',
          C: '在收集個人資料前，以清晰易懂的方式告知用戶目的，並取得其明確同意。',
          D: '只在數據洩漏後才告知用戶。'
        },
        correctAnswer: 'C',
        explanation: '「明確同意」(Opt-in)是GDPR等現代隱私法規的核心要求，它強調用戶的知情權和主動授權。'
    },
    {
        question: '對所有病患數據進行徹底的去識別化處理，這主要是在落實哪個階段的隱私保護？',
        options: {
          A: '系統部署及監控階段',
          B: '模型建立及驗證階段',
          C: '系統規劃及設計階段',
          D: '資料蒐集及輸入階段'
        },
        correctAnswer: 'D',
        explanation: '在將原始資料輸入到系統或資料庫之前，進行去識別化處理，是從源頭上降低隱私風險的有效技術手段。'
    }
  ],
  L23402: [
    {
        question: '一個臉部辨識模型，如果主要使用白人男性的照片進行訓練，導致其對其他族群和性別的識別準確率很低，這屬於哪種偏見來源？',
        options: {
            A: '歷史偏見 (Historical Bias)',
            B: '樣本偏見 (Representation Bias)',
            C: '衡量偏見 (Measurement Bias)',
            D: '演算法偏見 (Algorithmic Bias)'
        },
        correctAnswer: 'B',
        explanation: '樣本偏見（或稱代表性偏見）指的是訓練數據的採樣未能均衡地代表真實世界中的所有群體，導致模型對樣本量不足的群體產生偏見。'
    },
    {
        question: '在機器學習公平性中，「機會均等 (Equal Opportunity)」的定義是什麼？',
        options: {
            A: '模型對所有群體的整體準確率應該相等。',
            B: '模型對所有群體的預測結果比例應該相等。',
            C: '在所有【真正符合條件】的樣本中，不同群體被模型正確識別的機率（真陽性率）應該相等。',
            D: '所有個體都應該被模型給予相同的預測結果。'
        },
        correctAnswer: 'C',
        explanation: '機會均等關注的是，模型是否給予了不同群體中那些「應得的」個體以公平的機會。例如，在所有有能力還款的申請者中，模型批准貸款的比例不應因其種族而異。'
    },
    {
        question: '下列哪個是緩解演算法偏見的「預處理(Pre-processing)」技術？',
        options: {
          A: '在模型訓練時，加入公平性約束的懲罰項。',
          B: '對訓練完成後的模型，為不同群體設定不同的分類閾值。',
          C: '對訓練數據中樣本量較少的群體進行過採樣(Oversampling)。',
          D: '使用一個完全公平的演算法。'
        },
        correctAnswer: 'C',
        explanation: '預處理技術是在模型訓練「前」，直接對數據進行操作。過採樣或欠採樣是其中最常用的方法，旨在平衡數據的分佈，從數據源頭上緩解偏見。'
    },
    {
        question: '演算法偏見的主要來源是什麼？',
        options: {
          A: '演算法本身具有歧視的意圖。',
          B: '主要來自於訓練數據中潛藏的社會偏見，以及不均衡的數據採樣。',
          C: '程式設計師的個人偏見。',
          D: '硬體的計算誤差。'
        },
        correctAnswer: 'B',
        explanation: '偏見的核心來源是數據。AI模型是從數據中學習的，如果數據本身就反映了現實世界的不公，模型就會忠實地學習並可能放大這種不公。'
    },
    {
        question: '在招聘場景中，「人口統計均等(Demographic Parity)」這個公平性指標，要求什麼？',
        options: {
          A: '男性和女性的錄取率應該相同。',
          B: '在所有合格的申請者中，男性和女性的錄取率應該相同。',
          C: '模型對男性和女性的預測準確率應該相同。',
          D: '最終錄取的員工中，男性和女性的比例應該相同。'
        },
        correctAnswer: 'A',
        explanation: '人口統計均等要求模型的預測結果（如錄取/不錄取）在不同群體間的比例是相等的，它不考慮個體是否真的合格，是一個較為嚴格且有時不切實際的標準。'
    },
    {
        question: '「公平性與準確性的權衡(Fairness-Accuracy Trade-off)」指的是什麼？',
        options: {
          A: '模型越公平，準確率就越高。',
          B: '實施許多公平性緩解措施，可能會以犧牲模型整體的預測準確率為代價。',
          C: '公平性和準確率是完全獨立的。',
          D: '只有不準確的模型才需要考慮公平性。'
        },
        correctAnswer: 'B',
        explanation: '這是一個在公平性實踐中常見的挑戰。為了讓模型對不同群體更公平，有時需要對其決策邊界進行「扭曲」，這可能導致其整體準確率略微下降。需要在兩者之間找到可接受的平衡。'
    },
    {
        question: '「相似的個體得到相似的對待」，這描述了哪一種公平性定義？',
        options: {
          A: '群體公平 (Group Fairness)',
          B: '個體公平 (Individual Fairness)',
          C: '機會均等 (Equal Opportunity)',
          D: '人口統計均等 (Demographic Parity)'
        },
        correctAnswer: 'B',
        explanation: '個體公平關注的是個體層面的公平性，它要求如果兩個個體在與任務相關的特徵上是相似的，那麼模型對他們的預測也應該是相似的。'
    },
    {
        question: '法律禁止保險公司直接使用「種族」作為定價因素，但模型可能利用與種族高度相關的「郵遞區號」來間接實現歧視。這個「郵遞區號」被稱為什麼？',
        options: {
          A: '敏感特徵',
          B: '代理變數',
          C: '噪聲特徵',
          D: '無關特徵'
        },
        correctAnswer: 'B',
        explanation: '代理變數（Proxy Variable）指的是那些與受保護屬性（如種族、性別）高度相關，但本身看似中立的變數。在公平性審核中，識別和處理代理變數是一個關鍵挑戰。'
    },
    {
        question: '下列何者是緩解偏見的「後處理(Post-processing)」技術？',
        options: {
          A: '對訓練數據進行重採樣。',
          B: '在訓練時修改演算法的目標函數。',
          C: '在模型訓練完成後，對其預測結果進行調整。',
          D: '收集更多元化的數據。'
        },
        correctAnswer: 'C',
        explanation: '後處理技術是在模型訓練完成、「生米煮成熟飯」之後，對其輸出進行調整。例如，為不同群體設定不同的分類閾值，以滿足特定的公平性指標。'
    },
    {
        question: '為何說「公平」在數學上沒有單一的、普適的定義？',
        options: {
          A: '因為統計學家還沒有找到最好的定義。',
          B: '因為不同的公平性數學定義（如人口統計均等、機會均等）在現實世界中往往是互不相容的。',
          C: '因為公平是一個純粹的主觀感受，無法量化。',
          D: '因為不同國家的法律對公平的定義不同。'
        },
        correctAnswer: 'B',
        explanation: '研究已經證明，滿足一種群體公平性指標，往往意味著會違反另一種。因此，在特定場景下選擇哪個（或哪些）公平性指標作為優化目標，是一個需要結合倫理和業務進行權衡的複雜決策。'
    }
  ]
};
