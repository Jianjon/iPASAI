
import type { PracticeQuestion } from '../../types';

export const L23_PRACTICE: Record<string, PracticeQuestion[]> = {
  L23101: [
    {
      question: '樸素貝氏分類器(Naive Bayes Classifier)的核心思想基於下列哪個數學定理？',
      options: {
        A: '中央極限定理 (Central Limit Theorem)',
        B: '大數法則 (Law of Large Numbers)',
        C: '貝氏定理 (Bayes\' Theorem)',
        D: '畢氏定理 (Pythagorean Theorem)'
      },
      correctAnswer: 'C',
      explanation: '樸素貝氏分類器直接應用貝氏定理，透過計算給定特徵下的後驗機率來進行分類。其「樸素」之處在於假設特徵之間是條件獨立的。'
    },
    {
        question: '在貝氏定理 P(H|E) = [P(E|H) * P(H)] / P(E) 中，P(H)代表什麼？',
        options: {
          A: '後驗機率 (Posterior)',
          B: '概似率 (Likelihood)',
          C: '先驗機率 (Prior)',
          D: '證據 (Evidence)'
        },
        correctAnswer: 'C',
        explanation: 'P(H)代表先驗機率，即在觀測到任何證據E之前，我們對假設H的初始信念或信心程度。'
    },
    {
        question: '最大概似估計(Maximum Likelihood Estimation, MLE)的核心思想是什麼？',
        options: {
          A: '選擇一組參數，使得模型的複雜度最大。',
          B: '選擇一組參數，使得在這組參數下，觀測到的數據樣本出現的機率最大。',
          C: '選擇一組參數，使得模型的預測誤差最大。',
          D: '選擇一組參數，使得先驗機率最大。'
        },
        correctAnswer: 'B',
        explanation: 'MLE試圖回答的問題是：「什麼樣的模型參數，最有可能產生我們現在觀測到的這組數據？」它透過最大化數據的概似率來估計參數。'
    },
    {
        question: '線性迴歸中的最小二乘法，在統計上等價於假設誤差服從何種分佈時的MLE？',
        options: {
          A: '伯努利分佈',
          B: '泊松分佈',
          C: '高斯(常態)分佈',
          D: '均勻分佈'
        },
        correctAnswer: 'C',
        explanation: '這為我們為什麼常用最小化均方誤差(MSE)來訓練線性迴歸提供了理論基礎。當假設殘差是常態分佈時，最大化其概似率的數學推導結果，恰好就是最小化MSE。'
    },
    {
        question: '隨機變數的「期望值(Expected Value)」代表什麼？',
        options: {
          A: '該變數最可能出現的值。',
          B: '該變數的長期平均值。',
          C: '該變數的最大值。',
          D: '該變數的變異程度。'
        },
        correctAnswer: 'B',
        explanation: '期望值是隨機變數所有可能取值與其對應機率的加權平均，代表了在大量重複試驗下，我們預期會觀測到的平均結果。'
    },
    {
        question: '下列何者是「變異數(Variance)」的定義？',
        options: {
          A: '數據的最大值與最小值之差。',
          B: '衡量數據點偏離其平均數的平均距離。',
          C: '衡量數據點偏離其期望值的平方的期望值。',
          D: '數據的中位數。'
        },
        correctAnswer: 'C',
        explanation: '變異數Var(X) = E[(X - E[X])²]，它量化了數據的整體波動性或分散程度。其平方根就是標準差。'
    },
    {
        question: '邏輯迴歸和神經網路中常用的「交叉熵損失函數」，其最小化過程等價於在哪種分佈假設下的MLE？',
        options: {
          A: '高斯分佈',
          B: '多項分佈/伯努利分佈',
          C: '泊松分佈',
          D: '指數分佈'
        },
        correctAnswer: 'B',
        explanation: '對於分類問題，我們通常假設數據的標籤服從伯努利分佈（二元分類）或多項分佈（多元分類）。在這一假設下，最大化概似率等價於最小化交叉熵損失。'
    },
    {
        question: '線性判別分析(Linear Discriminant Analysis, LDA)演算法，對數據的潛在分佈做出了什麼假設？',
        options: {
          A: '每個類別的數據都服從均勻分佈。',
          B: '每個類別的數據都服從高斯(常態)分佈。',
          C: '數據不服從任何特定分佈。',
          D: '數據是線性可分的。'
        },
        correctAnswer: 'B',
        explanation: 'LDA是一個生成式分類模型，它假設每個類別的數據都是從一個具有相同協方差矩陣的高斯分佈中抽樣出來的，並利用貝氏定理來找到決策邊界。'
    },
    {
        question: '為何說機率與統計是機器學習的基石？',
        options: {
          A: '因為所有機器學習演算法都是由統計學家發明的。',
          B: '因為它為在不確定性中進行推理、決策和從數據中學習提供了數學框架。',
          C: '因為機器學習的計算速度依賴於機率論。',
          D: '因為只有統計學背景的人才能學習機器學習。'
        },
        correctAnswer: 'B',
        explanation: '機器學習本質上就是一個從數據中進行推斷的過程，而機率論和統計學正是處理不確定性、從樣本推斷整體的科學，因此構成了機器學習的理論核心。'
    },
    {
        question: '樸素貝氏分類器的「樸素(Naive)」之處在於它做出了什麼簡化假設？',
        options: {
          A: '假設所有數據都服從常態分佈。',
          B: '假設特徵之間是條件獨立的。',
          C: '假設數據沒有任何噪聲。',
          D: '假設模型是線性的。'
        },
        correctAnswer: 'B',
        explanation: '「條件獨立假設」是指，在給定類別的情況下，模型假設所有特徵都是相互獨立的。這在現實中通常不成立，但這個簡化大大降低了模型的計算複雜度，且在實踐中效果依然很好。'
    },
    {
        question: '在貝氏定理中，P(E|H)代表什麼？',
        options: {
            A: '後驗機率',
            B: '概似率',
            C: '先驗機率',
            D: '邊際機率'
        },
        correctAnswer: 'B',
        explanation: 'P(E|H)是概似率(Likelihood)，它衡量的是在假設H為真的情況下，觀測到證據E的可能性。'
    },
    {
        question: '下列何者是變異數的主要缺點？',
        options: {
            A: '計算過於複雜。',
            B: '其單位是原始數據單位的平方，不易解釋。',
            C: '對離群值不敏感。',
            D: '只能用於類別型數據。'
        },
        correctAnswer: 'B',
        explanation: '變異數的單位問題使其在實際解釋上較為困難，這也是為何我們通常使用其平方根——標準差——來報告數據的離散程度。'
    },
    {
        question: '在A/B測試中，我們通常使用假設檢定來判斷結果是否顯著。這背後的理論基礎是什麼？',
        options: {
            A: '線性代數',
            B: '微積分',
            C: '抽樣分佈的機率論',
            D: '數值優化'
        },
        correctAnswer: 'C',
        explanation: '假設檢定是統計推斷的核心，它完全建立在機率論和抽樣分佈的基礎之上，用來量化由隨機抽樣帶來的不確定性。'
    },
    {
        question: '下列哪個機器學習任務與貝氏定理的「更新信念」思想最為吻合？',
        options: {
            A: 'K-均值聚類',
            B: '主成分分析',
            C: '線上學習 (Online Learning)',
            D: '決策樹'
        },
        correctAnswer: 'C',
        explanation: '線上學習是指模型隨著新數據的到來而持續更新其參數。這與貝氏定理「在見到新證據後，更新我們對假設的信念」的思想高度一致。'
    },
    {
        question: '「偏差-方差權衡」是機器學習的核心概念，下列哪個數學概念是理解它的基礎？',
        options: {
            A: '條件機率',
            B: '貝氏定理',
            C: '最大概似估計',
            D: '期望值與變異數'
        },
        correctAnswer: 'D',
        explanation: '模型的總誤差可以被數學上分解為偏差(bias)的平方、方差(variance)和不可避免的誤差。理解期望值和變異數是理解這個分解的基礎。'
    },
    {
        question: '下列何者不是機率論在機器學習中的應用？',
        options: {
            A: '建立生成式模型，學習數據分佈。',
            B: '為模型的預測提供不確定性估計。',
            C: '作為正規化(Regularization)的基礎。',
            D: '設計高效的矩陣乘法演算法。'
        },
        correctAnswer: 'D',
        explanation: '設計高效的矩陣乘法演算法屬於數值線性代數和電腦科學的範疇。A、B、C都與機率統計密切相關。'
    },
    {
        question: '在統計學中，我們用什麼來估計一個未知的母體參數？',
        options: {
            A: '另一個母體參數',
            B: '一個樣本統計量',
            C: '一個固定的常數',
            D: '一個假設'
        },
        correctAnswer: 'B',
        explanation: '統計推斷的核心就是使用從母體中抽取的樣本所計算出的統計量（如樣本平均數），來估計或推斷未知的母體參數（如母體平均數）。'
    },
    {
        question: '一個事件發生的機率是0.7，則它不發生的機率是多少？',
        options: {
            A: '0.7',
            B: '0.3',
            C: '1.0',
            D: '0.0'
        },
        correctAnswer: 'B',
        explanation: '根據機率的互補法則，P(A\') = 1 - P(A)。因此，不發生的機率是 1 - 0.7 = 0.3。'
    },
    {
        question: '在機器學習中，我們為什麼關心數據的分佈？',
        options: {
            A: '因為數據分佈決定了我們應該使用哪種硬體。',
            B: '因為許多演算法都對數據的潛在分佈做出了假設，了解分佈有助於我們選擇合適的模型。',
            C: '因為數據分佈越複雜，模型就越準確。',
            D: '這只是一個學術概念，在實務中不重要。'
        },
        correctAnswer: 'B',
        explanation: '了解數據的分佈是探索性數據分析(EDA)的關鍵一步。它可以幫助我們識別數據的特性（如偏態）、發現異常值，並為模型選擇提供依據。'
    },
    {
        question: '最大後驗機率估計(MAP)與最大概似估計(MLE)的主要區別是什麼？',
        options: {
            A: 'MAP考慮了參數的先驗機率，而MLE沒有。',
            B: 'MLE考慮了參數的先驗機率，而MAP沒有。',
            C: '兩者沒有任何區別。',
            D: 'MAP用於迴歸，MLE用於分類。'
        },
        correctAnswer: 'A',
        explanation: 'MAP (Maximum a Posteriori) 估計在MLE的基礎上，引入了對參數本身的先驗信念(Prior)，它最大化的是後驗機率 P(θ|D)，而非概似率 P(D|θ)。'
    },
    {
        question: '一個分類模型的輸出是一個機率值，我們通常如何將其轉換為最終的類別預測？',
        options: {
            A: '將機率值乘以一個常數。',
            B: '設定一個閾值（通常是0.5），高於閾值的判為正類，低於的判為負類。',
            C: '對機率值取對數。',
            D: '直接將機率值作為類別。'
        },
        correctAnswer: 'B',
        explanation: '將連續的機率輸出轉換為離散的類別預測，需要一個決策閾值。這個閾值的選擇會影響模型的精確率和召回率。'
    }
  ],
  L23102: [
    {
      question: '在神經網路中，從一層到下一層的計算，主要依賴下列哪項線性代數運算？',
      options: {
        A: '矩陣求逆 (Matrix Inversion)',
        B: '特徵值分解 (Eigen-decomposition)',
        C: '矩陣乘法 (Matrix Multiplication)',
        D: '行列式計算 (Determinant Calculation)'
      },
      correctAnswer: 'C',
      explanation: '神經網路的前向傳播可以簡潔地表示為對輸入向量進行一系列的矩陣乘法（乘以權重矩陣）和向量加法（加上偏置向量），然後通過激活函數。'
    },
    {
        question: '主成分分析 (PCA) 是一種常用的降維技術，其數學原理是找到數據的？',
        options: {
            A: '協方差矩陣的特徵向量。',
            B: '均值和中位數。',
            C: '貝氏後驗機率。',
            D: '梯度向量。'
        },
        correctAnswer: 'A',
        explanation: 'PCA通過計算數據協方差矩陣的特徵分解，來找到數據中方差最大的方向（主成分）。將數據投影到最重要的幾個主成分上，即可達到降維的目的。'
    },
    {
        question: '在機器學習中，一個數據樣本的所有特徵，通常被表示為什麼？',
        options: {
          A: '一個純量 (Scalar)',
          B: '一個特徵向量 (Feature Vector)',
          C: '一個矩陣 (Matrix)',
          D: '一個張量 (Tensor)'
        },
        correctAnswer: 'B',
        explanation: '將一個樣本的所有特徵（如[坪數, 屋齡, 房間數]）組織成一個有序的數字列表，即向量，是機器學習中表示數據點的標準方式。'
    },
    {
        question: '兩個向量的點積(內積)在機器學習中有何用途？',
        options: {
          A: '主要用於計算兩個向量的距離。',
          B: '可用於衡量兩個向量的相似度（如餘弦相似度）或計算一個向量在另一個向量上的投影。',
          C: '主要用於將向量降維。',
          D: '點積沒有實際用途。'
        },
        correctAnswer: 'B',
        explanation: '點積是一個非常基礎且重要的運算。例如，在詞向量中，兩個詞向量的點積（或由此計算的餘弦相似度）越大，代表它們的語義越相近。'
    },
    {
        question: '為何GPU（圖形處理器）在深度學習中扮演了關鍵角色？',
        options: {
          A: '因為GPU的記憶體比CPU大。',
          B: '因為GPU能更好地顯示圖像。',
          C: '因為GPU的架構使其能大規模並行地執行矩陣運算，極大地加速了模型訓練。',
          D: '因為GPU的程式設計比CPU簡單。'
        },
        correctAnswer: 'C',
        explanation: '深度學習的核心計算是大量的矩陣乘法。GPU擁有數千個小型核心，專為並行處理這類計算而設計，因此其訓練速度遠超只有少量核心的CPU。'
    },
    {
        question: '奇異值分解 (SVD) 在哪一類機器學習應用中有著經典的應用？',
        options: {
          A: '決策樹',
          B: '推薦系統 (基於矩陣分解的協同過濾)',
          C: 'K-均值聚類',
          D: '線性迴歸'
        },
        correctAnswer: 'B',
        explanation: 'SVD可以將一個巨大且稀疏的「用戶-商品」評分矩陣，分解為低維的用戶和商品隱藏因子矩陣。透過這兩個矩陣的乘積，可以預測用戶對未評分商品的可能評分，是矩陣分解類推薦演算法的核心。'
    },
    {
        question: '在主成分分析(PCA)中，我們通常選擇協方差矩陣的哪些特徵向量作為新的座標軸？',
        options: {
          A: '對應最小特徵值的特徵向量。',
          B: '對應最大特徵值的特徵向量。',
          C: '隨機選擇的特徵向量。',
          D: '所有特徵向量。'
        },
        correctAnswer: 'B',
        explanation: '特徵值的大小代表了數據在對應特徵向量方向上的方差大小。PCA選擇對應最大特徵值的特徵向量（主成分），是因為這些方向保留了數據中最多的資訊。'
    },
    {
        question: '一個神經網路的權重參數，通常被組織成什麼樣的線性代數結構？',
        options: {
          A: '向量',
          B: '矩陣',
          C: '純量',
          D: '集合'
        },
        correctAnswer: 'B',
        explanation: '一個神經層的所有連接權重，可以非常自然地表示為一個權重矩陣，其中行數是輸出神經元的數量，列數是輸入神經元的數量。'
    },
    {
        question: '為何說線性代數是機器學習的「語言」？',
        options: {
          A: '因為所有機器學習的程式碼都必須用線性代數符號寫。',
          B: '因為它提供了一種極其簡潔和高效的方式來表示和操作高維數據和模型。',
          C: '因為學習機器學習前必須先成為線性代數專家。',
          D: '因為線性代數是唯一的數學工具。'
        },
        correctAnswer: 'B',
        explanation: '線性代數將複雜的數據關係和模型運算，抽象為優雅的向量和矩陣操作，不僅讓演算法的表達變得簡潔，也使得利用現代硬體進行高效計算成為可能。'
    },
    {
        question: '下列關於線性代數的敘述何者「錯誤」？',
        options: {
          A: '整個數據集可以表示為一個矩陣。',
          B: '矩陣求逆的計算成本很低。',
          C: '一張灰階圖片可以看作一個矩陣。',
          D: 'SVD可以應用於任何m x n的矩陣。'
        },
        correctAnswer: 'B',
        explanation: '矩陣求逆的計算複雜度約為O(n³)，是一個計算成本非常高的操作，在處理大矩陣時需要盡量避免。'
    },
    {
        question: '在自然語言處理中，詞向量(Word Embedding)是什麼？',
        options: {
            A: '一個表示詞語出現次數的純量。',
            B: '一個表示詞語語義的高維向量。',
            C: '一個包含詞語所有字母的矩陣。',
            D: '一個表示詞語長度的整數。'
        },
        correctAnswer: 'B',
        explanation: '詞向量技術將每個詞語映射到一個高維的連續向量空間中，使得語義相近的詞在空間中的位置也相近，這是現代NLP的基礎。'
    },
    {
        question: '下列何者是PCA的主要應用之一？',
        options: {
            A: '訓練深度神經網路。',
            B: '進行A/B測試。',
            C: '高維數據的可視化。',
            D: '計算P值。'
        },
        correctAnswer: 'C',
        explanation: 'PCA可以將高維數據（如超過三維）降維到二維或三維，同時盡可能地保留原始數據的變異性，從而讓我們可以在平面或三維空間中對數據的結構進行可視化探索。'
    },
    {
        question: '一個線性變換，可以被什麼來表示？',
        options: {
            A: '一個向量',
            B: '一個純量',
            C: '一個矩陣',
            D: '一個點'
        },
        correctAnswer: 'C',
        explanation: '矩陣乘法在幾何上對應著一個線性變換（如旋轉、縮放、剪切）。一個向量左乘一個矩陣，就相當於對這個向量進行了該矩陣所代表的線性變換。'
    },
    {
        question: '一個 n x 1 的矩陣，也可以被稱為什麼？',
        options: {
            A: '一個 n 維的列向量',
            B: '一個 n 維的行向量',
            C: '一個 n x n 的方陣',
            D: '一個單位矩陣'
        },
        correctAnswer: 'A',
        explanation: '在線性代數中，向量通常被視為只有一列（列向量）或只有一行（行向量）的特殊矩陣。'
    },
    {
        question: '下列哪個問題「不」能透過線性代數直接解決？',
        options: {
            A: '求解線性方程組。',
            B: '找到數據的主成分。',
            C: '計算兩個詞的語義相似度。',
            D: '最小化一個非凸函數。'
        },
        correctAnswer: 'D',
        explanation: '最小化一個非凸函數屬於數值優化的範疇，通常需要使用梯度下降等迭代演算法。A、B、C都可以轉化為線性代數問題來求解。'
    },
    {
        question: '在機器學習中，張量(Tensor)是什麼？',
        options: {
            A: '向量的別稱。',
            B: '矩陣的別稱。',
            C: '向量和矩陣的推廣，可以視為多維數組。',
            D: '一種特殊的純量。'
        },
        correctAnswer: 'C',
        explanation: '純量是0階張量，向量是1階張量，矩陣是2階張量。一個三維的彩色圖片（高x寬x顏色通道）就是一個3階張量。深度學習框架（如TensorFlow）中，張量是基本數據單位。'
    },
    {
        question: '一個方陣的特徵值(Eigenvalue)在幾何上代表什麼？',
        options: {
            A: '變換後的旋轉角度。',
            B: '在對應特徵向量方向上變換的縮放比例。',
            C: '矩陣的行數。',
            D: '矩陣的行列式。'
        },
        correctAnswer: 'B',
        explanation: '特徵向量是變換中「不動」的方向，而特徵值則描述了在這些不動方向上的拉伸或壓縮程度，它揭示了線性變換的核心特性。'
    },
    {
        question: '如果一個方陣的行列式(Determinant)為0，代表什麼？',
        options: {
            A: '該矩陣代表的線性變換是可逆的。',
            B: '該矩陣代表的線性變換將空間壓縮到了更低的維度。',
            C: '該矩陣是一個單位矩陣。',
            D: '該矩陣的所有元素都是0。'
        },
        correctAnswer: 'B',
        explanation: '行列式為0的矩陣稱為奇異矩陣，它沒有逆矩陣。在幾何上，這意味著它所代表的線性變換將整個空間「壓扁」了，例如將一個平面壓縮成一條線。'
    },
    {
        question: '向量的L2範數(L2 Norm)在幾何上對應什麼？',
        options: {
            A: '向量的維度。',
            B: '向量所有元素的總和。',
            C: '向量在空間中的長度（歐幾里得距離）。',
            D: '向量的最大元素值。'
        },
        correctAnswer: 'C',
        explanation: 'L2範數的計算方式是將向量各元素的平方和開根號，這與歐幾里得空間中計算點到原點的距離公式完全相同。'
    },
    {
        question: '下列哪個操作是線性代數沒有定義的？',
        options: {
            A: '兩個向量相加。',
            B: '兩個向量相除。',
            C: '一個矩陣乘以一個向量。',
            D: '一個純量乘以一個向量。'
        },
        correctAnswer: 'B',
        explanation: '線性代數中定義了向量的加、減、純量乘法和點積等運算，但沒有定義向量與向量之間的除法。'
    },
    {
        question: '一個矩陣的轉置(Transpose)操作是什麼？',
        options: {
            A: '計算矩陣的逆。',
            B: '將矩陣的行和列互換。',
            C: '計算矩陣的行列式。',
            D: '將矩陣的所有元素取倒數。'
        },
        correctAnswer: 'B',
        explanation: '轉置是一個基本操作，它將矩陣的主對角線作為對稱軸進行翻轉，第 i 行第 j 列的元素變為第 j 行第 i 列的元素。'
    }
  ],
  L23103: [
    {
      question: '在訓練機器學習模型時，梯度下降法(Gradient Descent)中的「學習率(Learning Rate)」扮演什麼角色？',
      options: {
        A: '決定模型的最終準確率。',
        B: '控制每次參數更新的步長。',
        C: '衡量損失函數的複雜度。',
        D: '模型訓練需要花費的總時間。'
      },
      correctAnswer: 'B',
      explanation: '學習率是一個關鍵的超參數，它決定了在優化過程中沿著梯度反方向前進的每一步的大小。學習率過大會導致不收斂，過小則收斂太慢。'
    },
    {
        question: '相較於批量梯度下降，隨機梯度下降 (SGD) 的主要優點是什麼？',
        options: {
            A: '梯度計算更精確。',
            B: '收斂路徑更平滑。',
            C: '在處理大規模數據集時，更新速度更快。',
            D: '保證能找到全局最優解。'
        },
        correctAnswer: 'C',
        explanation: 'SGD每次只用一個樣本來更新參數，而批量梯度下降需要計算全部數據。因此在大數據集上，SGD的迭代速度遠遠快於批量梯度下降，儘管其收斂路徑會比較抖動。'
    },
    {
        question: '在機器學習中，幾乎所有問題最終都可以被看作是解決一個什麼問題？',
        options: {
          A: '分類問題',
          B: '迴歸問題',
          C: '優化問題',
          D: '統計問題'
        },
        correctAnswer: 'C',
        explanation: '機器學習的「學習」過程，在數學上就是一個尋找一組最佳模型參數，以最小化一個預定義的目標函數（損失函數）的優化過程。'
    },
    {
        question: '現代深度學習中最常用的梯度下降變體是什麼？',
        options: {
          A: '批量梯度下降 (Batch Gradient Descent)',
          B: '隨機梯度下降 (Stochastic Gradient Descent)',
          C: '小批量梯度下降 (Mini-batch Gradient Descent)',
          D: '沒有固定的常用方法。'
        },
        correctAnswer: 'C',
        explanation: '小批量梯度下降完美地平衡了批量梯度下降（梯度準確但慢）和隨機梯度下降（梯度噪聲大但快）的優缺點，是當前最主流、最高效的訓練方法。'
    },
    {
        question: 'Adam優化器為何會成為目前深度學習中的首選？',
        options: {
          A: '因為它的計算最簡單。',
          B: '因為它結合了動量(Momentum)和自適應學習率(如RMSprop)的優點，通常表現穩健且收斂快。',
          C: '因為它不需要設定任何超參數。',
          D: '因為它只適用於CPU。'
        },
        correctAnswer: 'B',
        explanation: 'Adam是一個非常強大且通用的優化器，它既能像動量一樣幫助加速收斂和越過鞍點，又能為每個參數自動調整學習率，使其在各種不同的任務和模型上都有很好的表現。'
    },
    {
        question: '在梯度下降法中，「梯度(Gradient)」指的是什麼？',
        options: {
          A: '損失函數的最小值。',
          B: '一個指向損失函數值上升最快方向的向量。',
          C: '模型參數的數量。',
          D: '學習率的大小。'
        },
        correctAnswer: 'B',
        explanation: '梯度由損失函數對各個參數的偏導數構成，它在幾何上指向了函數在某一點上變化率最大、上升最快的方向。因此，梯度下降法沿其相反方向更新參數。'
    },
    {
        question: '如果梯度下降的學習率設定得過大，最可能發生什麼情況？',
        options: {
          A: '收斂速度會變得非常慢。',
          B: '模型會很快地收斂到全局最優解。',
          C: '參數更新的步子太大，可能在最優解附近來回震盪，甚至發散，無法收斂。',
          D: '模型會發生欠擬合。'
        },
        correctAnswer: 'C',
        explanation: '學習率過大會導致「矯枉過正」，每一步都直接跨過了谷底，導致損失值不降反升或劇烈震盪。'
    },
    {
        question: '在深度神經網路的損失函數地形中，相比於局部最小值，「鞍點(Saddle Points)」是更常見的挑戰，其特點是什麼？',
        options: {
          A: '在所有維度上都是最小值。',
          B: '在所有維度上都是最大值。',
          C: '在某些維度是最小值，但在其他維度是最大值，此處梯度為零。',
          D: '梯度非常大的點。'
        },
        correctAnswer: 'C',
        explanation: '鞍點是高維優化中的一個難題。標準的梯度下降法在此處會因梯度為零而停滯，但動量和Adam等優化器有助於「衝」過這些平坦的鞍點區域。'
    },
    {
        question: '在目標函數中加入一個懲罰模型複雜度的「正規化項」，其主要目的是什麼？',
        options: {
          A: '加快模型的收斂速度。',
          B: '防止模型過擬合。',
          C: '增加模型的準確率。',
          D: '讓損失函數變為凸函數。'
        },
        correctAnswer: 'B',
        explanation: '正規化是一種對抗過擬合的核心技術。它透過懲罰過大的參數權重，來限制模型的複雜度，使其泛化能力更好。'
    },
    {
        question: '機器學習的「訓練」過程，在數學上可以被描述為什麼？',
        options: {
          A: '一個求解線性方程組的過程。',
          B: '一個最小化目標函數的數值優化過程。',
          C: '一個計算機率分佈的過程。',
          D: '一個矩陣分解的過程。'
        },
        correctAnswer: 'B',
        explanation: '整個訓練過程，無論多麼複雜的模型，其本質都是在尋找一組能讓損失函數最小化的參數。數值優化演算法就是實現這個目標的具體方法。'
    },
    {
        question: '下列哪個是迴歸問題常用的損失函數？',
        options: {
            A: '交叉熵 (Cross-Entropy)',
            B: '均方誤差 (Mean Squared Error, MSE)',
            C: 'Hinge Loss',
            D: '對數損失 (Log Loss)'
        },
        correctAnswer: 'B',
        explanation: 'MSE計算的是預測值與真實值之差的平方的平均值，是評估和優化迴歸模型最常用的損失函數。'
    },
    {
        question: '在深度學習中，梯度消失/爆炸問題會對優化過程造成什麼影響？',
        options: {
            A: '讓優化過程變得更快。',
            B: '讓模型變得更容易解釋。',
            C: '梯度過小或過大，導致模型參數更新緩慢或不穩定，使訓練難以進行。',
            D: '它只會影響模型的推論，不影響訓練。'
        },
        correctAnswer: 'C',
        explanation: '梯度是參數更新的依據。梯度消失會讓參數幾乎不更新，學習停滯；梯度爆炸則會讓參數更新過大，導致訓練過程發散。'
    },
    {
        question: '動量(Momentum)優化器引入了什麼概念來改善SGD？',
        options: {
            A: '自適應學習率',
            B: '歷史梯度的指數加權移動平均',
            C: '二階導數(Hessian矩陣)',
            D: '隨機噪聲'
        },
        correctAnswer: 'B',
        explanation: '動量法會累積一個「速度」向量，這個向量是過去梯度的加權平均。這使得更新方向不僅取決於當前梯度，還受歷史趨勢的影響，有助於加速並穩定收斂。'
    },
    {
        question: '一個損失函數如果是一個「凸函數」，它有什麼優良的性質？',
        options: {
            A: '它有很多個局部最小值。',
            B: '它只有一個全局最小值，沒有局部最小值。',
            C: '它的計算速度非常快。',
            D: '它只能用於分類問題。'
        },
        correctAnswer: 'B',
        explanation: '凸優化問題是優化領域中最理想的情況。因為它保證了任何局部最優解都是全局最優解，所以梯度下降法可以保證收斂到最佳解。邏輯迴歸的損失函數就是一個例子。'
    },
    {
        question: '下列何者不是數值優化演算法的超參數？',
        options: {
            A: '學習率',
            B: '批次大小',
            C: '模型權重',
            D: '優化器類型 (如Adam, SGD)'
        },
        correctAnswer: 'C',
        explanation: '模型權重是模型在訓練過程中需要「學習」的參數。而學習率、批次大小、優化器類型都是在訓練開始前需要「設定」的超參數。'
    },
    {
        question: '學習率調度(Learning Rate Scheduling)的目的是什麼？',
        options: {
            A: '讓學習率在訓練過程中保持不變。',
            B: '在訓練過程中動態地調整學習率，以獲得更好的收斂效果。',
            C: '隨機地選擇學習率。',
            D: '讓學習率變得越來越大。'
        },
        correctAnswer: 'B',
        explanation: '一個常見的策略是「學習率衰減」，即在訓練初期使用較大的學習率快速下降，後期逐漸減小學習率進行精細調整，有助於模型收斂到更好的最優點。'
    },
    {
        question: '為何小批量梯度下降成為深度學習的標配？',
        options: {
            A: '因為它能最好地利用GPU的並行計算能力。',
            B: '因為它比SGD和批量梯度下降都更穩定。',
            C: '因為它的梯度估計最準確。',
            D: '因為它能提供穩定的梯度估計，同時計算效率又很高。'
        },
        correctAnswer: 'D',
        explanation: '小批量梯度下降在梯度準確性（相比SGD）和計算效率（相比批量梯度下降）之間取得了最佳的平衡，並且其矩陣運算的形式非常適合GPU的並行計算架構。'
    },
    {
        question: '二階優化方法（如牛頓法）相比於一階方法（梯度下降）的主要區別是什麼？',
        options: {
            A: '二階方法不使用梯度。',
            B: '二階方法同時利用了一階導數（梯度）和二階導數（Hessian矩陣）的資訊。',
            C: '二階方法速度總是比較慢。',
            D: '二階方法只能用於凸優化。'
        },
        correctAnswer: 'B',
        explanation: 'Hessian矩陣描述了損失曲面的曲率。利用曲率資訊，二階方法通常能以更少的迭代次數收斂，但計算Hessian矩陣的成本極高，因此在深度學習中不常用。'
    },
    {
        question: '下列哪種情況下，SGD的「抖動」收斂路徑可能是有益的？',
        options: {
            A: '當損失函數是凸函數時。',
            B: '當損失函數存在許多局部最小值時。',
            C: '當我們希望快速收斂時。',
            D: '在任何情況下都是有害的。'
        },
        correctAnswer: 'B',
        explanation: 'SGD梯度的隨機性（噪聲）有時能幫助優化過程「跳出」尖銳的局部最小值或鞍點，從而有機會找到更好的解。'
    },
    {
        question: '一個分類問題的目標函數是什麼？',
        options: {
            A: '最小化預測類別與真實類別之間的差異。',
            B: '最大化模型的複雜度。',
            C: '最小化訓練時間。',
            D: '最大化學習率。'
        },
        correctAnswer: 'A',
        explanation: '無論是交叉熵還是Hinge Loss，分類問題的損失函數都是在衡量模型預測的類別（或機率分佈）與真實的類別標籤之間的「距離」或「不一致性」。'
    },
    {
        question: '下列哪個優化器是專門為稀疏特徵設計的？',
        options: {
            A: 'Momentum',
            B: 'AdaGrad',
            C: 'Adam',
            D: 'SGD'
        },
        correctAnswer: 'B',
        explanation: 'AdaGrad會對不經常更新的參數（對應稀疏特徵）給予較大的學習率，對經常更新的參數給予較小的學習率，這種自適應性使其在處理稀疏數據時很有效。'
    }
  ],
  L23201: [
    {
      question: '下列哪項任務屬於「非監督式學習 (Unsupervised Learning)」的範疇？',
      options: {
        A: '根據房屋特徵預測其售價。',
        B: '判斷一封郵件是否為垃圾郵件。',
        C: '根據用戶的購買歷史，將用戶自動分為不同群組。',
        D: '識別圖片中的動物是貓還是狗。'
      },
      correctAnswer: 'C',
      explanation: '用戶分群（聚類）是一個典型的非監督式學習任務，因為數據中沒有預先定義好的「群組」標籤，演算法需要自動從數據中發現其內在結構。A、B、D都是有明確標籤的監督式學習任務。'
    },
    {
        question: '一個模型在訓練集上表現極好，但在新的測試集上表現很差。這個現象被稱為什麼？',
        options: {
            A: '欠擬合 (Underfitting)',
            B: '過擬合 (Overfitting)',
            C: '偏差 (Bias)',
            D: '數據漂移 (Data Drift)'
        },
        correctAnswer: 'B',
        explanation: '過擬合指的是模型過度學習了訓練數據中的噪聲和細節，導致其失去了泛化到新數據的能力。高方差(Variance)是過擬合的數學體現。'
    },
    {
        question: '訓練一個機器手臂玩疊積木，透過獎勵（成功疊上一塊）和懲罰（積木倒塌）來學習策略，這屬於哪一類機器學習？',
        options: {
          A: '監督式學習',
          B: '非監督式學習',
          C: '強化學習',
          D: '半監督式學習'
        },
        correctAnswer: 'C',
        explanation: '強化學習的核心是智能體透過與環境的互動和獎勵回饋，來學習一個能最大化長期獎勵的決策策略，這與機器人控制和遊戲AI的場景非常吻合。'
    },
    {
        question: '在偏差-方差權衡中，「偏差(Bias)」指的是什麼？',
        options: {
          A: '模型對訓練數據中微小波動的敏感度。',
          B: '源於模型的簡化假設，導致模型無法捕捉到數據中真實的複雜關係。',
          C: '數據本身固有的噪聲。',
          D: '模型在訓練集上的錯誤率。'
        },
        correctAnswer: 'B',
        explanation: '高偏差源於模型過於簡單，無法擬合數據的真實模式，導致欠擬合。它衡量的是模型預測的平均值與真實值之間的差距。'
    },
    {
        question: '下列哪個問題是監督式學習中的「分類(Classification)」問題？',
        options: {
          A: '預測明天的股票價格。',
          B: '根據用戶評論判斷其情感是「正面」、「負面」還是「中性」。',
          C: '將新聞文章自動分為不同的主題。',
          D: '預測下一季度的公司總營收。'
        },
        correctAnswer: 'B',
        explanation: '情感分析的目標是預測一個離散的類別標籤（正面/負面/中性），因此是一個分類問題。A和D是迴歸問題，C是非監督式聚類問題。'
    },
    {
        question: '一個過於簡單的模型，在訓練集和測試集上表現都很差，這通常是什麼問題？',
        options: {
          A: '過擬合 (Overfitting)',
          B: '高方差 (High Variance)',
          C: '欠擬合 (Underfitting)',
          D: '數據洩漏 (Data Leakage)'
        },
        correctAnswer: 'C',
        explanation: '欠擬合的特徵就是模型過於簡單（高偏差），無法捕捉數據的基本模式，因此無論是在它學習過的訓練集上，還是在新的測試集上，表現都會很糟糕。'
    },
    {
        question: '機器學習的最終目標是什麼？',
        options: {
          A: '在訓練集上達到100%的準確率。',
          B: '找到最複雜的模型。',
          C: '讓模型在未見過的新數據上表現良好，即具備良好的泛化能力。',
          D: '最小化模型的訓練時間。'
        },
        correctAnswer: 'C',
        explanation: '一個只會「背誦」訓練數據的模型是沒有用的。機器學習的真正價值在於模型能從學習中「泛化」出規律，並將其應用到新的、從未見過的場景中。'
    },
    {
        question: '主成分分析(PCA)屬於哪一類機器學習？',
        options: {
          A: '監督式學習',
          B: '非監督式學習',
          C: '強化學習',
          D: '這不是機器學習'
        },
        correctAnswer: 'B',
        explanation: 'PCA是一種降維技術，它在沒有標籤的數據上運作，旨在發現數據中方差最大的方向（內部結構），因此屬於非監督式學習。'
    },
    {
        question: '增加模型複雜度（例如，增加決策樹的深度）通常會對偏差和方差產生什麼影響？',
        options: {
          A: '偏差和方差都增加。',
          B: '偏差和方差都降低。',
          C: '偏差降低，方差增加。',
          D: '偏差增加，方差降低。'
        },
        correctAnswer: 'C',
        explanation: '這正是偏差-方差權衡的核心。更複雜的模型能更好地擬合訓練數據，從而降低偏差；但它也更容易學習到數據中的噪聲，從而增加了方差。'
    },
    {
        question: '監督式學習、非監督式學習和強化學習，其最根本的區別在於什麼？',
        options: {
          A: '使用的程式語言不同。',
          B: '對硬體的要求不同。',
          C: '解決問題的目標和學習方式（回饋信號的類型）不同。',
          D: '開發者的背景不同。'
        },
        correctAnswer: 'C',
        explanation: '三者的根本區別在於它們的學習範式：監督式學習從「標籤」中學習，非監督式學習從「數據結構」中學習，而強化學習則從「獎勵信號」中學習。'
    },
    {
        question: '下列哪個是「不可避免的誤差 (Irreducible Error)」的來源？',
        options: {
            A: '模型選擇不當',
            B: '數據本身固有的噪聲或隨機性',
            C: '訓練數據量不足',
            D: '學習率設定不佳'
        },
        correctAnswer: 'B',
        explanation: '不可避免的誤差代表了數據中我們無法用模型捕捉的隨機部分，它是任何模型性能的理論上限。'
    },
    {
        question: '下列哪個任務屬於監督式學習中的「迴歸(Regression)」問題？',
        options: {
            A: '判斷一張圖片中是否有汽車。',
            B: '預測一個客戶下個月的消費金額。',
            C: '將客戶分為高、中、低三個價值等級。',
            D: '發現超市中經常一起被購買的商品。'
        },
        correctAnswer: 'B',
        explanation: '消費金額是一個連續的數值，預測這類數值的問題屬於迴歸問題。A是二元分類，C是多元分類，D是關聯規則學習。'
    },
    {
        question: '一個模型如果偏差(Bias)很高，我們應該如何調整？',
        options: {
            A: '增加訓練數據量。',
            B: '增加模型的複雜度（例如，使用更多特徵或更深的網路）。',
            C: '進行正規化(Regularization)。',
            D: '減少模型的複雜度。'
        },
        correctAnswer: 'B',
        explanation: '高偏差意味著模型欠擬合，太過簡單。因此，我們需要增加模型的「容量」或「學習能力」，讓它能夠捕捉到更複雜的數據模式。'
    },
    {
        question: '一個模型如果方差(Variance)很高，我們應該如何調整？',
        options: {
            A: '使用更複雜的模型。',
            B: '增加更多特徵。',
            C: '增加訓練數據量或進行正規化(Regularization)。',
            D: '減少訓練數據量。'
        },
        correctAnswer: 'C',
        explanation: '高方差意味著模型過擬合，太過複雜。增加數據量可以讓模型學到更具泛化性的規律；正規化則可以限制模型的複雜度。'
    },
    {
        question: '強化學習中的「智能體(Agent)」和「環境(Environment)」的關係是什麼？',
        options: {
            A: '智能體創造環境。',
            B: '環境控制智能體。',
            C: '智能體在環境中採取行動，環境給予回饋（新狀態和獎勵）。',
            D: '兩者沒有任何關係。'
        },
        correctAnswer: 'C',
        explanation: '這是強化學習最基本的互動迴圈：智能體觀察狀態 -> 採取行動 -> 環境改變狀態並給予獎勵 -> 智能體根據獎勵調整策略。'
    },
    {
        question: '機器學習的「學習」過程，指的是什麼？',
        options: {
            A: '將數據載入記憶體。',
            B: '從數據中自動地發現模式或規則。',
            C: '編寫程式碼。',
            D: '將數據可視化。'
        },
        correctAnswer: 'B',
        explanation: '與傳統編程不同，機器學習的核心是讓演算法自己從數據中「學習」出解決問題的方法，而非由人類直接編寫。'
    },
    {
        question: '下列何者不是監督式學習的例子？',
        options: {
            A: '人臉辨識',
            B: '語音辨識',
            C: '文本摘要',
            D: '異常偵測'
        },
        correctAnswer: 'D',
        explanation: '異常偵測通常是一種非監督式學習任務，因為異常樣本非常稀少，模型通常是透過學習「正常」數據的模式來發現「異常」。A, B, C通常都需要大量的標籤數據。'
    },
    {
        question: '強化學習中的「獎勵(Reward)」信號的主要作用是什麼？',
        options: {
            A: '告訴智能體正確的行動是什麼。',
            B: '為智能體的行動提供一個「好壞」的評分，以引導其學習。',
            C: '描述環境的當前狀態。',
            D: '直接更新智能體的參數。'
        },
        correctAnswer: 'B',
        explanation: '獎勵信號是強化學習中唯一的監督信號。它不直接告訴智能體應該怎麼做，而是評估其行動的結果，智能體的目標就是最大化這個累積的獎勵信號。'
    },
    {
        question: '下列哪種情況下，非監督式學習特別有用？',
        options: {
            A: '當我們有大量帶有精確標籤的數據時。',
            B: '當我們希望預測一個具體的數值時。',
            C: '當我們擁有大量數據但缺乏標籤，希望從中探索未知的結構或模式時。',
            D: '當我們需要訓練一個遊戲 AI 時。'
        },
        correctAnswer: 'C',
        explanation: '在許多真實世界場景中，獲取無標籤的數據遠比獲取有標籤的數據容易。非監督式學習能夠在這種情況下發揮作用，幫助我們對數據進行初步的探索和理解。'
    },
    {
        question: '「半監督式學習 (Semi-supervised Learning)」指的是什麼？',
        options: {
            A: '監督式學習和非監督式學習的統稱。',
            B: '一種同時使用少量帶標籤的數據和大量不帶標籤的數據進行學習的方法。',
            C: '一種完全由人類半監督半自動完成的學習。',
            D: '強化學習的另一個名字。'
        },
        correctAnswer: 'B',
        explanation: '半監督式學習試圖結合監督式和非監督式學習的優點，在標籤數據稀少的情況下，利用大量無標籤數據中蘊含的結構資訊，來提升模型的性能。'
    },
    {
        question: '一個完美的模型，其在測試集上的誤差應該等於什麼？',
        options: {
            A: '零',
            B: '偏差 (Bias)',
            C: '方差 (Variance)',
            D: '不可避免的誤差 (Irreducible Error)'
        },
        correctAnswer: 'D',
        explanation: '不可避免的誤差代表了數據本身固有的隨機性，這是任何模型都無法消除的理論誤差下限。一個完美的模型，其偏差和方差都應為零，但總誤差仍受限於此。'
    }
  ],
  L23202: [
    {
        question: '下列哪個演算法是透過集成學習(Ensemble Learning)中Bagging的思想，構建大量的決策樹來提升性能？',
        options: {
            A: '邏輯迴歸 (Logistic Regression)',
            B: '支援向量機 (SVM)',
            C: '隨機森林 (Random Forest)',
            D: 'K-均值聚類 (K-Means)'
        },
        correctAnswer: 'C',
        explanation: '隨機森林的核心思想就是Bagging（Bootstrap Aggregating）和特徵隨機化。它並行地訓練多棵決策樹，並透過投票或平均來匯總結果，有效降低了單棵決策樹容易過擬合的問題。'
    },
    {
        question: '支援向量機(SVM)的核心思想是什麼？',
        options: {
          A: '找到一條能穿過最多數據點的線。',
          B: '建立一個模仿人類決策流程的樹狀結構。',
          C: '找到一個能將不同類別的數據點最大化間隔(Margin)地分開的決策邊界。',
          D: '將相似的數據點自動分組。'
        },
        correctAnswer: 'C',
        explanation: 'SVM是一個最大間隔分類器。其目標不僅是找到一個能分開數據的超平面，而是要找到那個能讓兩類數據點到該平面的距離都最遠、最「安全」的超平面。'
    },
    {
        question: 'K-均值聚類(K-Means)演算法中的「K」代表什麼？',
        options: {
          A: '演算法的最大迭代次數。',
          B: '數據集的特徵數量。',
          C: '使用者預先指定的簇的數量。',
          D: '演算法作者的名字。'
        },
        correctAnswer: 'C',
        explanation: 'K是K-Means演算法的一個關鍵超參數，必須在演算法運行前由使用者指定，它決定了最終要將數據分為幾群。'
    },
    {
        question: '下列哪個演算法最適合做為一個分類問題的「基準模型(Baseline Model)」？',
        options: {
          A: '深度神經網路',
          B: '隨機森林',
          C: '邏輯迴歸',
          D: '支援向量機 (帶高斯核)'
        },
        correctAnswer: 'C',
        explanation: '邏輯迴歸模型簡單、計算速度快、可解釋性強，非常適合在專案初期作為一個基準模型，來快速驗證流程並建立一個性能的底線。'
    },
    {
        question: 'SVM中的「核技巧(Kernel Trick)」主要解決了什麼問題？',
        options: {
          A: '加快模型的訓練速度。',
          B: '解決原始特徵空間中線性不可分的問題。',
          C: '減少模型的參數數量。',
          D: '讓模型更容易解釋。'
        },
        correctAnswer: 'B',
        explanation: '核技巧透過核函數，可以巧妙地在高維特徵空間中計算點積，而無需顯式地將數據映射到高維空間。這使得SVM能夠用一個線性的超平面，來解決原始空間中的非線性分類問題。'
    },
    {
        question: '隨機森林的「隨機」體現在哪兩個方面？',
        options: {
          A: '隨機選擇演算法 和 隨機設定K值。',
          B: '隨機抽樣訓練數據 (Bootstrap) 和 隨機選取部分特徵來分裂節點。',
          C: '隨機初始化權重 和 隨機設定學習率。',
          D: '隨機丟棄一半數據 和 隨機選擇一半特徵。'
        },
        correctAnswer: 'B',
        explanation: '這兩個「隨機」的過程，確保了森林中的每一棵樹都是不同的，從而增加了模型的多樣性，這是Bagging類集成方法成功的關鍵。'
    },
    {
        question: '下列哪個演算法「不」屬於監督式學習？',
        options: {
          A: '線性迴歸',
          B: '決策樹',
          C: '支援向量機',
          D: 'K-均值聚類'
        },
        correctAnswer: 'D',
        explanation: 'K-均值聚類是在沒有標籤的數據上尋找模式，屬於非監督式學習。其他三個都是典型的監督式學習演算法。'
    },
    {
        question: '單棵決策樹的一個主要缺點是什麼？',
        options: {
          A: '模型過於簡單，容易欠擬合。',
          B: '模型容易過擬合，且對數據的微小變動很敏感。',
          C: '模型無法處理類別型特徵。',
          D: '模型的可解釋性很差。'
        },
        correctAnswer: 'B',
        explanation: '如果沒有進行剪枝等限制，單棵決策樹會傾向於不斷分裂，直到完美地擬合訓練數據，這使其非常容易過擬合，且不穩定。隨機森林正是為了解決這個問題而生。'
    },
    {
        question: '線性迴歸和邏輯迴歸的主要區別是什麼？',
        options: {
          A: '線性迴歸是監督式學習，邏輯迴歸是非監督式學習。',
          B: '線性迴歸預測連續數值，邏輯迴歸用於分類。',
          C: '線性迴歸使用梯度下降，邏輯迴歸不使用。',
          D: '線性迴歸更準確。'
        },
        correctAnswer: 'B',
        explanation: '這是兩者最根本的區別。雖然名字相似，但它們解決的問題類型完全不同：一個用於迴歸，一個用於分類。'
    },
    {
        question: '在K-Means演算法的迭代過程中，當每個簇的中心不再發生變化時，代表什麼？',
        options: {
          A: '演算法出錯了，需要重啟。',
          B: '演算法已經收斂，聚類過程完成。',
          C: '需要增加K的值。',
          D: '需要減少K的值。'
        },
        correctAnswer: 'B',
        explanation: '當簇中心和點的分配都穩定下來，不再有任何數據點會被重新分配到另一個簇時，演算法就達到了收斂狀態，找到了（可能是局部的）最優解。'
    },
    {
        question: '下列哪個演算法是梯度提升機(Gradient Boosting Machine)的代表？',
        options: {
            A: '隨機森林',
            B: 'XGBoost',
            C: 'SVM',
            D: 'K-Means'
        },
        correctAnswer: 'B',
        explanation: 'XGBoost和LightGBM是梯度提升機最流行、最高效的實現，它們在各種數據科學競賽和實際應用中，通常是處理表格數據的首選。'
    },
    {
        question: '集成學習(Ensemble Learning)的基本思想是什麼？',
        options: {
            A: '只使用一個最強大的模型。',
            B: '將多個模型的預測結果結合起來，以獲得更好的性能。',
            C: '將數據分為多個部分，分別訓練模型。',
            D: '使用多種不同的程式語言來開發模型。'
        },
        correctAnswer: 'B',
        explanation: '集成學習的核心是「群策群力」。它通常能獲得比任何單一模型都更穩定、更準確的預測結果。'
    },
    {
        question: '在決策樹中，我們用什麼指標來選擇最佳的特徵進行分裂？',
        options: {
            A: '特徵的平均值',
            B: '訊息增益(Information Gain)或基尼不純度(Gini Impurity)',
            C: '特徵的相關係數',
            D: 'P值'
        },
        correctAnswer: 'B',
        explanation: '這些指標衡量的是一個特徵在劃分數據後，能帶來多大的「純度」提升。決策樹會選擇那個能讓數據變得最「純」的特徵作為分裂節點。'
    },
    {
        question: 'K-Means演算法對什麼樣的數據分佈效果最好？',
        options: {
            A: '任意形狀的簇',
            B: '密度不均勻的簇',
            C: '球狀、大小相似的簇',
            D: '線性分佈的數據'
        },
        correctAnswer: 'C',
        explanation: 'K-Means基於歐幾里得距離來分配數據點，這隱含地假設了簇是凸形且大小相似的（通常是球狀）。對於複雜形狀的簇，DBSCAN等基於密度的演算法效果更好。'
    },
    {
        question: '下列哪個演算法的可解釋性最強？',
        options: {
            A: '支援向量機 (帶高斯核)',
            B: '梯度提升機',
            C: '決策樹',
            D: '深度神經網路'
        },
        correctAnswer: 'C',
        explanation: '單棵決策樹的決策過程可以被直接視覺化為一個if-then規則的樹狀圖，非常直觀且易於人類理解，是典型的「白箱模型」。'
    },
    {
        question: '在SVM中，那些落在間隔(Margin)邊緣上的數據點被稱為什麼？',
        options: {
            A: '離群值 (Outliers)',
            B: '中心點 (Centroids)',
            C: '支援向量 (Support Vectors)',
            D: '錨點 (Anchor Points)'
        },
        correctAnswer: 'C',
        explanation: '這些支援向量是決定最終決策邊界位置的關鍵數據點，SVM演算法的名稱也由此而來。'
    },
    {
        question: '下列關於常用機器學習演算法的敘述，何者正確？',
        options: {
            A: '線性迴歸只能用於分類問題。',
            B: '隨機森林是一種非監督式學習演算法。',
            C: 'SVM在數據量非常大時，訓練時間可能會很長。',
            D: 'K-Means可以自動找到最佳的簇數量。'
        },
        correctAnswer: 'C',
        explanation: '標準SVM的訓練複雜度較高（約為樣本數的平方到三次方），因此在處理超大規模數據集時可能會遇到性能瓶頸。'
    },
    {
        question: '下列哪個演算法不屬於集成學習？',
        options: {
            A: '隨機森林',
            B: '梯度提升機',
            C: 'AdaBoost',
            D: '樸素貝氏 (Naive Bayes)'
        },
        correctAnswer: 'D',
        explanation: '樸素貝氏是一個單一的、基於貝氏定理的分類演算法。A, B, C 都是集成學習的代表性方法。'
    },
    {
        question: '梯度提升機 (Gradient Boosting) 是如何運作的？',
        options: {
            A: '並行地訓練多個獨立的樹。',
            B: '串行地訓練多個樹，每個樹都試圖修正前一個樹的錯誤。',
            C: '只訓練一棵非常深的樹。',
            D: '對多個不同模型的預測結果進行投票。'
        },
        correctAnswer: 'B',
        explanation: '梯度提升機屬於 Boosting 類型的集成方法，其核心思想是迭代地、串行地構建模型，後一個模型會更關注前一個模型預測錯誤的樣本。'
    },
    {
        question: '在K-Means的分配步驟中，數據點被分配到哪個簇中心？',
        options: {
            A: '離它最遠的簇中心。',
            B: '離它最近的簇中心。',
            C: '隨機選擇一個簇中心。',
            D: '分配到樣本數最少的簇。'
        },
        correctAnswer: 'B',
        explanation: '分配步驟的依據是距離度量（通常是歐幾里得距離），每個點都會被歸入離它最近的那個簇中心的「勢力範圍」。'
    },
    {
        question: '下列哪個演算法非常適合處理表格數據(Tabular Data)？',
        options: {
            A: '卷積神經網路 (CNN)',
            B: '循環神經網路 (RNN)',
            C: '隨機森林或梯度提升機',
            D: 'Transformer'
        },
        correctAnswer: 'C',
        explanation: '對於結構化的表格數據，基於決策樹的集成學習模型（如隨機森林、XGBoost、LightGBM）通常能達到比深度學習模型更好或相當的性能，且訓練成本更低。'
    }
  ],
  L23203: [
    {
        question: '深度學習的「深(Deep)」指的是什麼？',
        options: {
            A: '模型能夠理解深刻的哲學問題。',
            B: '神經網路的層數很多。',
            C: '模型使用的數學理論非常深奧。',
            D: '模型訓練所需的時間非常長。'
        },
        correctAnswer: 'B',
        explanation: '「深」直接對應於深度神經網路中隱藏層的數量。透過堆疊多個處理層，模型能夠學習到數據中從低階到高階的層次化特徵。'
    },
    {
        question: '卷積神經網路(CNN)在哪一類任務中取得了最大的成功？',
        options: {
            A: '自然語言處理',
            B: '時間序列分析',
            C: '電腦視覺 (圖像處理)',
            D: '強化學習'
        },
        correctAnswer: 'C',
        explanation: 'CNN透過卷積核和權重共享的設計，特別擅長捕捉圖像等網格狀數據的局部空間特徵，是現代電腦視覺領域的基石。'
    },
    {
        question: '在神經網路中，如果沒有非線性的「激活函數」，一個再深的神經網路其實質等價於什麼？',
        options: {
            A: '一個決策樹',
            B: '一個單一的線性模型',
            C: '一個K-均值聚類模型',
            D: '一個隨機森林'
        },
        correctAnswer: 'B',
        explanation: '多個線性變換的組合，其結果仍然是一個線性變換。激活函數的引入，才使得神經網路能夠學習和逼近複雜的非線性關係。'
    },
    {
        question: 'Transformer架構的核心是什麼？',
        options: {
            A: '卷積核',
            B: '循環單元',
            C: '自注意力機制 (Self-Attention)',
            D: '最大池化'
        },
        correctAnswer: 'C',
        explanation: '自注意力機制是Transformer的革命性創新，它使得模型能夠在處理序列時，一步到位地計算序列中所有元素之間的相互影響，從而高效地捕捉長距離依賴關係。'
    },
    {
        question: '下列哪個是深度學習相比傳統機器學習最核心的優勢？',
        options: {
            A: '模型訓練速度更快。',
            B: '能夠自動從原始數據中學習有效的特徵表示（表示學習）。',
            C: '模型的可解釋性更強。',
            D: '對數據量的需求更少。'
        },
        correctAnswer: 'B',
        explanation: '傳統機器學習高度依賴手動的特徵工程，而深度學習的端到端學習能力，能夠自動從數據中提取層次化的特徵，大大減輕了特徵工程的負擔，尤其在非結構化數據上。'
    },
    {
        question: '訓練深度學習模型時，用來高效計算梯度的方法是什麼？',
        options: {
            A: '前向傳播演算法',
            B: '反向傳播演算法',
            C: '遺傳演算法',
            D: '蒙地卡羅方法'
        },
        correctAnswer: 'B',
        explanation: '反向傳播演算法（Backpropagation）利用微積分中的鏈式法則，能夠從後往前、高效地計算出損失函數對網路中每一個參數的偏導數（梯度），是訓練神經網路的基礎。'
    },
    {
        question: '循環神經網路(RNN)特別適合處理什麼類型的數據？',
        options: {
            A: '圖像數據',
            B: '表格數據',
            C: '序列數據（如文本、時間序列）',
            D: '地理空間數據'
        },
        correctAnswer: 'C',
        explanation: 'RNN的設計中包含了「循環」結構，使其能夠處理變長的序列輸入，並將前一個時間步的資訊傳遞給下一個時間步，從而捕捉序列中的時間依賴性。'
    },
    {
        question: '目前最常用的激活函數是什麼？',
        options: {
            A: 'Sigmoid',
            B: 'Tanh',
            C: 'ReLU (Rectified Linear Unit)',
            D: '線性函數'
        },
        correctAnswer: 'C',
        explanation: 'ReLU函數（f(x) = max(0, x)）計算簡單，且能有效緩解梯度消失問題，是當前絕大多數深度學習模型的標準激活函數。'
    },
    {
        question: 'GPT、BERT等大型語言模型的基礎架構是什麼？',
        options: {
            A: 'CNN',
            B: 'RNN',

            C: 'Transformer',
            D: '多層感知機 (MLP)'
        },
        correctAnswer: 'C',
        explanation: 'Transformer架構因其捕捉長距離依賴的能力和並行計算的效率，已完全取代RNN，成為現代自然語言處理領域的標準和主導架構。'
    },
    {
        question: '下列何者不是深度學習的應用？',
        options: {
            A: '人臉辨識',
            B: '語音助理',
            C: '求解一元二次方程',
            D: '自動駕駛中的物體偵測'
        },
        correctAnswer: 'C',
        explanation: '求解一元二次方程有明確的數學公式，可以直接計算求解，屬於傳統的確定性問題，不需要使用深度學習這種從數據中學習的方法。'
    }
  ],
  L23301: [
    {
        question: '在機器學習專案中，為何「數據準備與特徵工程」階段通常最耗時？',
        options: {
            A: '因為這個階段的演算法最複雜。',
            B: '因為原始數據通常是混亂、不完整且充滿錯誤的，需要大量工作來清理和轉換。',
            C: '因為需要等待硬體設備的採購。',
            D: '因為這個階段需要最多的人員參與。'
        },
        correctAnswer: 'B',
        explanation: '真實世界的數據遠非理想，數據準備階段需要處理缺失值、離群值、不一致等各種問題，並從中提取有用的特徵，這個過程通常佔據整個專案60%-80%的時間。'
    },
    {
        question: '將一個包含「城市」名稱的類別特徵，轉換為多個二元的「是否為某城市」的特徵，這種方法稱為什麼？',
        options: {
            A: '標籤編碼 (Label Encoding)',
            B: '獨熱編碼 (One-Hot Encoding)',
            C: '數據標準化',
            D: '特徵選擇'
        },
        correctAnswer: 'B',
        explanation: '獨熱編碼是處理無序類別變數的標準方法，它避免了為類別引入不應有的大小關係，但對於類別過多的特徵可能導致維度災難。'
    },
    {
        question: '為何在將數據輸入到基於梯度下降的演算法（如神經網路）之前，通常需要進行特徵縮放？',
        options: {
            A: '為了讓數據集變得更大。',
            B: '為了避免模型被數值尺度較大的特徵所主導，並加速收斂。',
            C: '為了讓數據更容易被人類讀懂。',
            D: '這只是一個傳統習慣，沒有實際作用。'
        },
        correctAnswer: 'B',
        explanation: '特徵縮放（如標準化或歸一化）可以確保所有特徵都在相似的尺度上，這有助於梯度下降法更平滑、更快速地找到最優解。'
    },
    {
        question: '從原始的「身高」和「體重」特徵，計算出一個新的「BMI」特徵，這個過程屬於什麼？',
        options: {
            A: '數據清洗',
            B: '數據標註',
            C: '特徵創造',
            D: '數據標準化'
        },
        correctAnswer: 'C',
        explanation: '特徵創造是特徵工程的一部分，它透過對現有特徵進行組合或變換，來創造出可能對模型更有預測能力的新特徵，通常需要領域知識。'
    },
    {
        question: '下列哪個模型對輸入特徵的尺度最不敏感，通常不需要進行特徵縮放？',
        options: {
            A: '線性迴歸',
            B: '支援向量機 (SVM)',
            C: 'K-均值聚類',
            D: '決策樹 / 隨機森林'
        },
        correctAnswer: 'D',
        explanation: '基於樹的模型在進行節點分裂時，只關心特徵值的順序和分裂點，而不關心其絕對大小。因此，它們對特徵的尺度不敏感。'
    },
    {
        question: '下列何者是「數據洩漏 (Data Leakage)」的典型例子？',
        options: {
            A: '在劃分訓練/測試集之後，才對訓練集進行標準化。',
            B: '在劃分訓練/測試集之前，就對整個數據集進行了標準化。',
            C: '使用交叉驗證來評估模型。',
            D: '訓練數據量太小。'
        },
        correctAnswer: 'B',
        explanation: '這是一個非常隱蔽但嚴重的錯誤。如果在劃分前就對整個數據集進行標準化，那麼測試集的資訊（如均值、標準差）就已經「洩漏」到了訓練過程中，會導致模型評估結果過於樂觀。'
    },
    {
        question: '主動學習(Active Learning)是一種怎樣的數據標註策略？',
        options: {
            A: '將所有數據都標註兩次以確保品質。',
            B: '讓模型挑出它最「困惑」、最需要被標註的困難樣本，以提高標註效率。',
            C: '隨機地選擇一半的數據進行標註。',
            D: '讓標註員主動選擇他們感興趣的數據。'
        },
        correctAnswer: 'B',
        explanation: '主動學習旨在用最少的標註成本，獲得最大的模型性能提升。其核心思想是，與其隨機標註，不如優先對那些最有價值的樣本進行標註。'
    },
    {
        question: '下列何者是「特徵選擇」的主要目的？',
        options: {
            A: '增加數據的總量。',
            B: '增加模型的特徵數量。',
            C: '移除無關或冗餘的特徵，以簡化模型、防止過擬合。',
            D: '讓所有特徵的尺度一致。'
        },
        correctAnswer: 'C',
        explanation: '特徵選擇的目標是「少即是多」，透過篩選出一個更小的、更有效的特徵子集，來提升模型的泛化能力和可解釋性，同時降低計算成本。'
    },
    {
        question: '對於一個監督式學習的圖像分類任務，數據標註的內容是什麼？',
        options: {
            A: '為每張圖片框出所有物體的位置。',
            B: '為每張圖片賦予一個正確的類別標籤（如「貓」）。',
            C: '為每張圖片寫一段詳細的文字描述。',
            D: '為每張圖片的每個像素進行分類。'
        },
        correctAnswer: 'B',
        explanation: '圖像分類的標註是最簡單的，只需為整張圖片提供一個類別標籤作為「正確答案」。'
    },
    {
        question: '下列何者不是數據清洗的常見任務？',
        options: {
            A: '處理缺失值',
            B: '處理離群值',
            C: '統一數據格式',
            D: '訓練機器學習模型'
        },
        correctAnswer: 'D',
        explanation: '訓練模型是在數據準備完成之後的下一個階段。數據清洗專注於提升數據本身的品質，為訓練提供乾淨的「燃料」。'
    }
  ],
  L23302: [
    {
        question: '在模型選擇中，奧卡姆剃刀原則（Occam\'s Razor）的啟示是什麼？',
        options: {
            A: '總是選擇最複雜的模型。',
            B: '在多個性能相近的模型中，應優先選擇那個最簡單的模型。',
            C: '模型的複雜度與其性能無關。',
            D: '應選擇訓練時間最長的模型。'
        },
        correctAnswer: 'B',
        explanation: '奧卡姆剃刀原則（「如無必要，勿增實體」）在模型選擇中意味著，更簡單的模型通常具有更好的泛化能力和可解釋性，因此在性能相當時應被優先考慮。'
    },
    {
        question: '為何在開發自己的模型時，應優先考慮使用「預訓練模型」？',
        options: {
            A: '因為預訓練模型是免費的。',
            B: '因為預訓練模型在大型數據集上已經學到了通用的、有價值的特徵，可以極大地加速收斂並提升性能。',
            C: '因為使用預訓練模型不需要任何程式設計能力。',
            D: '因為預訓練模型的準確率總是100%。'
        },
        correctAnswer: 'B',
        explanation: '這就是遷移學習的力量。與其從零開始，不如站在巨人的肩膀上。預訓練模型提供了一個非常好的初始化權重，讓我們的模型能更快、更好地適應新任務。'
    },
    {
        question: '在模型選擇的過程中，建立一個「基準模型(Baseline Model)」的主要目的是什麼？',
        options: {
            A: '基準模型就是最終要上線的模型。',
            B: '為了提供一個性能底線，任何更複雜的模型都必須顯著優於它才有價值。',
            C: '為了盡可能地延長專案時間。',
            D: '為了向管理層展示最簡單的技術。'
        },
        correctAnswer: 'B',
        explanation: '基準模型為模型性能提供了一個客觀的參考點。如果一個複雜的模型其性能僅略微優於（甚至不如）一個簡單的基準，那麼這個複雜模型就是沒有價值的。'
    },
    {
        question: '在深度學習架構設計中，增加網路的「深度」（層數）有什麼好處？',
        options: {
            A: '可以讓模型訓練得更快。',
            B: '可以讓模型學習到更抽象、更複雜的特徵。',
            C: '可以完全避免過擬合。',
            D: '可以減少模型的參數數量。'
        },
        correctAnswer: 'B',
        explanation: '深度學習的層次化結構使其能夠學習從低階到高階的特徵。更深的網路意味著能進行更高級別的特徵抽象，從而捕捉更複雜的數據模式。'
    },
    {
        question: '模型選擇不僅要考慮模型的預測準確率，還必須考慮什麼？',
        options: {
            A: '演算法的發明年份。',
            B: '部署環境的工程約束，如推論速度、記憶體佔用等。',
            C: '開發團隊的個人偏好。',
            D: '模型的程式碼行數。'
        },
        correctAnswer: 'B',
        explanation: '一個在雲端GPU上運行的大型模型，是無法被部署到資源受限的手機上的。模型選擇必須是準確率與現實工程限制之間的一個權衡。'
    },
    {
        question: '對於一個圖像分類任務，下列哪個是合適的骨幹網路選擇？',
        options: {
            A: 'LSTM',
            B: 'Transformer',
            C: 'ResNet',
            D: '線性迴歸'
        },
        correctAnswer: 'C',
        explanation: 'ResNet是一種經典且性能優異的卷積神經網路(CNN)架構，專為圖像處理而設計。LSTM和Transformer主要用於序列數據。'
    },
    {
        question: '一個模型的偏差(Bias)很高，這意味著什麼？',
        options: {
            A: '模型過於複雜。',
            B: '模型欠擬合，太過簡單。',
            C: '模型在測試集上表現很好。',
            D: '模型對數據中的噪聲很敏感。'
        },
        correctAnswer: 'B',
        explanation: '高偏差是欠擬合的信號，表示模型的假設太過簡化，無法捕捉數據中真實的、複雜的關係。'
    },
    {
        question: '在進行模型選擇時，我們應該主要依據模型在哪個數據集上的表現？',
        options: {
            A: '訓練集 (Training Set)',
            B: '驗證集 (Validation Set)',
            C: '測試集 (Test Set)',
            D: '整個數據集'
        },
        correctAnswer: 'B',
        explanation: '驗證集的作用就是在多個候選模型或超參數組合之間進行選擇。測試集應該被嚴格保護，只在最終選定模型後用來做一次性的最終評估。'
    },
    {
        question: '增加神經網路每層的「寬度」（神經元數量）有什麼作用？',
        options: {
            A: '可以讓模型變得更深。',
            B: '可以讓該層學習到更多樣化的特徵。',
            C: '可以降低模型的計算成本。',
            D: '可以讓模型的可解釋性更強。'
        },
        correctAnswer: 'B',
        explanation: '每一層的神經元都可以被看作是一個特徵提取器。更寬的層意味著有更多的特徵提取器，能夠從輸入中捕捉更多元的模式。'
    },
    {
        question: '「模型選擇的流程」記憶輔助中，「別忘了現實」指的是什麼？',
        options: {
            A: '不要選擇過於理想化的模型。',
            B: '考慮到部署環境的現實工程約束。',
            C: '承認模型永遠不可能達到100%準確。',
            D: '要考慮到專案的預算現實。'
        },
        correctAnswer: 'B',
        explanation: '這個記憶輔助提醒我們，模型選擇是一個綜合決策，除了理論上的準確率，還必須務實地考慮到最終部署時的各種現實限制。'
    }
  ],
  L23303: [
    {
        question: '在機器學習中，為何需要將數據集劃分為訓練集、驗證集和測試集？',
        options: {
            A: '為了增加數據的總量。',
            B: '為了能夠客觀地評估模型的泛化能力。',
            C: '這只是一個傳統，沒有實際作用。',
            D: '為了讓模型訓練得更快。'
        },
        correctAnswer: 'B',
        explanation: '如果在訓練數據上評估模型，結果會過於樂觀。使用一個獨立的、模型從未見過的測試集來進行最終評估，才能真實地反映模型在現實世界中的表現。'
    },
    {
        question: '在一個極度不平衡的分類問題中（例如，99%是負樣本，1%是正樣本），哪個評估指標最可能產生誤導？',
        options: {
            A: '精確率 (Precision)',
            B: '召回率 (Recall)',
            C: '準確率 (Accuracy)',
            D: 'F1分數'
        },
        correctAnswer: 'C',
        explanation: '在這種情況下，一個將所有樣本都預測為「負」的無用模型，其準確率也能達到99%。因此，準確率會給出一個虛高的、具有誤導性的評估。'
    },
    {
        question: '在癌症篩檢模型中，我們更關心不要漏掉任何真正的病患。這意味著我們希望最大化哪個指標？',
        options: {
            A: '精確率 (Precision)',
            B: '召回率 (Recall)',
            C: '準確率 (Accuracy)',
            D: '真陰性率 (True Negative Rate)'
        },
        correctAnswer: 'B',
        explanation: '召回率（Recall）衡量的是在所有真正為「正」（有病）的樣本中，有多少被成功地找了出來。在漏診代價極高的醫療場景，最大化召回率是首要目標。'
    },
    {
        question: 'K-摺交叉驗證 (K-Fold Cross-Validation) 的主要好處是什麼？',
        options: {
            A: '可以讓模型訓練得更快。',
            B: '可以提供一個比單次劃分驗證集更穩定、更可靠的模型性能估計。',
            C: '可以完全避免過擬合。',
            D: '可以自動選擇最佳的演算法。'
        },
        correctAnswer: 'B',
        explanation: '透過多次劃分和評估，並將結果平均，交叉驗證可以有效降低因數據劃分的偶然性而導致的評估偏差，尤其在數據量較小時非常有用。'
    },
    {
        question: '「測試集」在模型開發流程中應該何時使用？',
        options: {
            A: '在訓練過程中，用來調整超參數。',
            B: '在模型開發的最終階段，只使用一次，用來評估最終選定模型的泛化能力。',
            C: '與訓練集混合在一起，共同用於模型訓練。',
            D: '在專案一開始，用來探索數據。'
        },
        correctAnswer: 'B',
        explanation: '測試集是模擬未來未知數據的「最終考卷」，必須被嚴格保護。如果在開發過程中頻繁使用它，資訊就會洩漏，導致最終評估結果失效。'
    },
    {
        question: '混淆矩陣中的「假陽性 (False Positive)」指的是什麼？',
        options: {
            A: '真實是正，預測也是正。',
            B: '真實是正，預測是負。',
            C: '真實是負，預測是正。',
            D: '真實是負，預測也是負。'
        },
        correctAnswer: 'C',
        explanation: '假陽性（Type I Error）指的是「誤報」，即樣本真實是負類，但模型錯誤地將其預測為正類。'
    },
    {
        question: '下列哪個是評估迴歸模型性能的常用指標？',
        options: {
            A: 'F1分數',
            B: 'AUC-ROC',
            C: '精確率',
            D: '均方根誤差 (RMSE)'
        },
        correctAnswer: 'D',
        explanation: 'RMSE是衡量迴歸模型預測值與真實值之間誤差大小的核心指標，它對較大的誤差給予更重的懲罰。'
    },
    {
        question: '精確率(Precision)的定義是什麼？',
        options: {
            A: '在所有真實為「正」的樣本中，有多少被成功找出來。',
            B: '在所有被預測為「正」的樣本中，有多少是真的「正」。',
            C: '模型預測正確的樣本佔總樣本的比例。',
            D: '模型預測錯誤的樣本佔總樣本的比例。'
        },
        correctAnswer: 'B',
        explanation: '精確率衡量的是模型預測結果的「準確性」。高精確率意味著模型預測為「正」的結果，可信度很高。'
    },
    {
        question: '在數據集劃分的比喻中，「模擬考」對應的是哪個數據集？',
        options: {
            A: '訓練集',
            B: '驗證集',
            C: '測試集',
            D: '整個數據集'
        },
        correctAnswer: 'B',
        explanation: '驗證集就像模擬考，我們用它來評估不同的學習策略（超參數）的好壞，並進行調整，但它不應用來做最終的成績評定。'
    },
    {
        question: 'R² (決定係數) 這個指標是用來做什麼的？',
        options: {
            A: '衡量分類模型的準確率。',
            B: '衡量迴歸模型能解釋數據變異性的百分比。',
            C: '衡量模型的訓練時間。',
            D: '衡量特徵的重要性。'
        },
        correctAnswer: 'B',
        explanation: 'R²的值介於0和1之間，越接近1，代表模型的自變數能解釋越多依變數的變異，模型的擬合效果越好。'
    }
  ],
  L23304: [
    {
        question: '在模型調優中，學習率、批次大小、樹的深度等，這些由人類在訓練前設定的參數被稱為什麼？',
        options: {
            A: '模型參數',
            B: '模型權重',
            C: '超參數',
            D: '模型特徵'
        },
        correctAnswer: 'C',
        explanation: '超參數是控制學習過程的外部設定，而參數是模型在學習過程中內部自動調整的。超參數調優是找到最佳外部設定的過程。'
    },
    {
        question: '下列哪種超參數調優策略，會根據過去的評估結果，來有方向性地選擇下一組最有可能的超參數進行嘗試？',
        options: {
            A: '網格搜索 (Grid Search)',
            B: '隨機搜索 (Random Search)',
            C: '手動調優 (Manual Tuning)',
            D: '貝氏優化 (Bayesian Optimization)'
        },
        correctAnswer: 'D',
        explanation: '貝氏優化是一種更智能的搜索策略，它建立了一個代理模型來學習超參數與模型性能之間的關係，從而能用更少的嘗試次數找到更好的超參數組合。'
    },
    {
        question: '在深度學習中常用的Dropout技術，其主要目的是什麼？',
        options: {
            A: '加快模型的訓練速度。',
            B: '減少模型的參數數量。',
            C: '防止模型過擬合。',
            D: '增加模型的可解釋性。'
        },
        correctAnswer: 'C',
        explanation: 'Dropout透過在訓練時隨機「失活」一部分神經元，強迫網路學習更穩健、更具冗餘性的特徵，是一種非常有效的正規化技術，可以顯著降低過擬合。'
    },
    {
        question: '「早停 (Early Stopping)」策略是如何防止過擬合的？',
        options: {
            A: '在訓練一開始就停止。',
            B: '當訓練集上的損失不再下降時停止。',
            C: '持續監控模型在「驗證集」上的性能，一旦性能不再提升就立即停止訓練。',
            D: '設定一個固定的、非常短的訓練時間。'
        },
        correctAnswer: 'C',
        explanation: '早停是一種簡單而有效的正規化方法。它利用驗證集來監控模型的泛化能力，在模型剛要開始過擬合（即驗證集性能變差）的那個點及時剎車。'
    },
    {
        question: '對訓練圖像進行隨機的翻轉、旋轉、裁剪等操作，這種技術稱為什麼？',
        options: {
            A: '數據清洗',
            B: '數據增強',
            C: '特徵選擇',
            D: '數據標準化'
        },
        correctAnswer: 'B',
        explanation: '數據增強是一種在不改變標籤的前提下，人工擴大數據集規模的技術。它是防止過擬合、提升模型穩健性最有效的方法之一。'
    },
    {
        question: 'L1正規化(Lasso)和L2正規化(Ridge)的主要區別是什麼？',
        options: {
            A: 'L1只用於迴歸，L2只用於分類。',
            B: 'L1會使不重要的特徵權重變為0，而L2只會使其趨近於0。',
            C: 'L2會使不重要的特徵權重變為0，而L1只會使其趨近於0。',
            D: '兩者沒有任何區別。'
        },
        correctAnswer: 'B',
        explanation: 'L1正規化因其懲罰項的性質，具有「稀疏性」，能夠將某些特徵的權重完全壓縮到零，因此可以兼具正規化和特徵選擇的效果。'
    },
    {
        question: '下列何者是「對抗過擬合的三板斧」記憶輔助中提到的方法？',
        options: {
            A: '更多數據、簡化模型、集成大法',
            B: '更快速度、更低成本、更少人力',
            C: '網格搜索、隨機搜索、貝氏優化',
            D: '訓練集、驗證集、測試集'
        },
        correctAnswer: 'A',
        explanation: '這三種方法是處理過擬合最核心、最有效的策略：增加數據（包括數據增強）、降低模型複雜度（包括正規化）、以及使用集成學習。'
    },
    {
        question: '網格搜索(Grid Search)調優策略的主要缺點是什麼？',
        options: {
            A: '搜索結果不夠精確。',
            B: '計算成本隨著超參數的數量和取值呈指數級增長。',
            C: '無法處理連續的超參數。',
            D: '每次運行的結果都不同。'
        },
        correctAnswer: 'B',
        explanation: '網格搜索會窮舉所有可能的組合，當超參數維度很高時，其計算量會變得非常巨大，導致效率低下。'
    },
    {
        question: '集成學習(Ensemble Learning)為何通常能提升模型性能？',
        options: {
            A: '因為它總是選擇最簡單的模型。',
            B: '因為它結合了多個不同模型的「智慧」，可以降低單一模型的偏差和方差。',
            C: '因為它的計算速度最快。',
            D: '因為它只需要很少的數據。'
        },
        correctAnswer: 'B',
        explanation: '集成學習利用了「群體智慧」的原理。透過將多個（通常是多樣化的）模型的預測結合起來，可以有效地平滑掉單一模型的極端錯誤，從而獲得更穩定、更準確的結果。'
    },
    {
        question: '下列哪個選項不是超參數？',
        options: {
            A: '學習率',
            B: '神經網路的權重',
            C: '隨機森林中樹的數量',
            D: '正規化強度(lambda)'
        },
        correctAnswer: 'B',
        explanation: '神經網路的權重是模型在訓練過程中，透過梯度下降等優化演算法自動學習到的「參數」，而非由人類預先設定的超參數。'
    }
  ],
  L23401: [
    {
        question: '在機器學習治理中，確保模型決策原因可被理解，以滿足法規要求（如GDPR的「解釋權」），這指的是什麼？',
        options: {
            A: '模型安全性',
            B: '模型隱私性',
            C: '模型可解釋性 (Explainability)',
            D: '模型穩健性'
        },
        correctAnswer: 'C',
        explanation: '可解釋性（XAI）是負責任AI的核心，尤其在金融、醫療等高風險領域，模型不僅要做出準確的預測，還必須能夠解釋其預測的依據，以滿足合規和信任的需求。'
    },
    {
        question: '「數據保留在本地，只將加密的模型更新傳回中央伺服器進行聚合」，這描述了哪種隱私保護技術？',
        options: {
            A: '差分隱私',
            B: '聯邦學習',
            C: '數據匿名化',
            D: '對抗性訓練'
        },
        correctAnswer: 'B',
        explanation: '聯邦學習是一種分散式的機器學習方法，它的核心優勢在於，原始的、可能包含敏感資訊的數據永遠不需要離開用戶的設備或本地伺服器，從而極大地保護了數據隱私。'
    },
    {
        question: '在輸入圖像中加入人眼無法察覺的微小惡意擾動，就能導致模型分類錯誤，這種攻擊稱為什麼？',
        options: {
            A: '數據中毒',
            B: '模型竊取',
            C: '提示注入',
            D: '對抗性攻擊'
        },
        correctAnswer: 'D',
        explanation: '對抗性攻擊利用了深度學習模型在高維空間中的一些脆弱性，是一種在推論階段對模型進行欺騙的攻擊手段。'
    },
    {
        question: 'SHAP和LIME是機器學習治理中常用的工具，它們主要用來解決什麼問題？',
        options: {
            A: '提升模型的訓練速度。',
            B: '解釋黑箱模型的預測結果。',
            C: '保護數據隱私。',
            D: '自動調整超參數。'
        },
        correctAnswer: 'B',
        explanation: 'SHAP和LIME是兩種流行的模型無關（model-agnostic）的可解釋AI（XAI）技術，它們可以為任何複雜的黑箱模型（如XGBoost、神經網路）的單次預測，提供其特徵貢獻度的解釋。'
    },
    {
        question: '「機器學習治理三要素」記憶輔助中，「保護決策」對應的是哪兩項要求？',
        options: {
            A: '隱私與安全',
            B: '合規與可解釋性',
            C: '速度與準確率',
            D: '偏差與方差'
        },
        correctAnswer: 'B',
        explanation: '「保護決策」指的是確保模型的決策過程是合法的、可被理解和追溯的，這直接對應了合規（Compliance）和可解釋性（Explainability）這兩個核心要求。'
    },
    {
        question: '污染訓練數據以破壞模型或植入後門，這種攻擊手法被稱為什麼？',
        options: {
            A: '對抗性攻擊',
            B: '模型竊取',
            C: '數據中毒',
            D: '阻斷服務攻擊'
        },
        correctAnswer: 'C',
        explanation: '數據中毒是一種從源頭污染AI的攻擊，透過污染訓練數據來破壞最終模型的準確性或植入後門，防禦難度較高。'
    },
    {
        question: '對數據、程式碼和模型進行嚴格的版本控制，主要是為了實現什麼？',
        options: {
            A: '讓專案看起來更專業。',
            B: '增加儲存空間的使用量。',
            C: '實驗的可追溯性與可重現性。',
            D: '加快模型的推論速度。'
        },
        correctAnswer: 'C',
        explanation: '版本控制是科學實驗和工程實踐的基礎。它確保了當問題出現時，我們能夠準確地回溯到哪個版本的數據、程式碼和模型出了問題，並能重現當時的結果。'
    },
    {
        question: '差分隱私(Differential Privacy)技術是如何保護隱私的？',
        options: {
            A: '透過對所有數據進行加密。',
            B: '透過移除所有的個人可識別資訊。',
            C: '透過向查詢結果或模型梯度中加入經過計算的噪聲。',
            D: '透過將數據分散儲存在不同的地方。'
        },
        correctAnswer: 'C',
        explanation: '差分隱私的核心思想是，透過添加噪聲來模糊化單個數據點的貢獻，使得從最終的統計結果中，無法反推出任何個體的具體資訊。'
    },
    {
        question: '下列何者是「模型卡(Model Cards)」的主要內容？',
        options: {
            A: '模型的價格和購買方式。',
            B: '模型的開發團隊成員名單。',
            C: '記錄模型的訓練數據、性能指標、預期用途、限制和倫理考量等。',
            D: '模型的程式碼註解。'
        },
        correctAnswer: 'C',
        explanation: '模型卡是一種標準化的模型文檔，旨在提高模型的透明度，讓使用者和利害關係人能快速了解一個模型的各個重要面向。'
    },
    {
        question: '下列哪項是機器學習治理的主要目標？',
        options: {
            A: '最大化模型的準確率，不計任何代價。',
            B: '確保模型的開發、部署和運維是安全、可靠且合乎法規的。',
            C: '最小化模型的開發時間。',
            D: '讓所有模型都開源。'
        },
        correctAnswer: 'B',
        explanation: '機器學習治理是一個綜合性的框架，其目標是在追求模型性能的同時，兼顧隱私、安全、公平、合規等多方面的要求，實現負責任的AI。'
    }
  ],
  L23402: [
    {
        question: '下列何者是「歷史偏見」的例子？',
        options: {
            A: '模型的演算法設計本身存在缺陷。',
            B: '數據收集時，只採集了某一特定區域的樣本。',
            C: '用於訓練信貸模型的歷史數據，反映了過去社會對特定族群的歧視性做法。',
            D: '模型的預測結果不穩定。'
        },
        correctAnswer: 'C',
        explanation: '歷史偏見指的是數據本身是真實的，但它反映了社會過去存在的不公平現象。模型會忠實地學習這種偏見，並在未來重現它。'
    },
    {
        question: '在公平性的定義中，「機會均等 (Equal Opportunity)」指的是什麼？',
        options: {
            A: '所有群體被預測為正類的比例應相等。',
            B: '所有群體中，真實為正類的樣本，被預測為正類的比例（真陽性率）應相等。',
            C: '所有群體中，真實為負類的樣本，被預測為負類的比例（真陰性率）應相等。',
            D: '所有群體的準確率都應相等。'
        },
        correctAnswer: 'B',
        explanation: '機會均等關注的是，對於那些「有資格」的個體（真實為正類），模型是否給予了他們平等的被識別出來的機會。'
    },
    {
        question: '在模型生命週期的哪個階段，可以透過「重採樣(Resampling)」或「重加權(Reweighting)」來緩解偏見？',
        options: {
            A: '預處理 (Pre-processing)',
            B: '處理中 (In-processing)',
            C: '後處理 (Post-processing)',
            D: '部署後'
        },
        correctAnswer: 'A',
        explanation: '這些都是在模型訓練之前，直接對原始數據進行操作的方法，旨在從數據源頭上調整數據分佈，使其更為均衡。'
    },
    {
        question: '在機器學習中，演算法偏見的主要來源是什麼？',
        options: {
            A: '硬體設備的故障。',
            B: '程式語言的選擇。',
            C: '數據中存在的各種偏見（如歷史偏見、樣本偏見）。',
            D: '模型訓練的時間不夠長。'
        },
        correctAnswer: 'C',
        explanation: '數據是演算法偏見最主要、最根本的來源。模型本身沒有歧視的意圖，但它會像一面鏡子一樣，誠實地反映出訓練數據中的所有模式，包括那些不公平的模式。'
    },
    {
        question: '為不同群體設定不同的分類閾值，以達到公平性目標，這屬於哪一類偏見緩解策略？',
        options: {
            A: '預處理',
            B: '處理中',
            C: '後處理',
            D: '這不是一種有效的策略'
        },
        correctAnswer: 'C',
        explanation: '後處理策略是在不改變原始數據和已訓練模型的前提下，僅對模型的預測輸出進行調整，以滿足特定的公平性約束。'
    },
    {
        question: '「相似的個體應該被相似地對待」，這描述了哪一類公平性定義？',
        options: {
            A: '群體公平性',
            B: '個體公平性',
            C: '條件公平性',
            D: '反事實公平性'
        },
        correctAnswer: 'B',
        explanation: '個體公平性關注的是對個體的處理，要求模型對那些特徵相似的個體，給出相似的預測結果，而不受其所屬的群體影響。'
    },
    {
        question: '在「對抗偏見的時間點」記憶輔助中，「事中」對應的是哪種策略？',
        options: {
            A: '處理數據',
            B: '處理演算法',
            C: '處理結果',
            D: '處理硬體'
        },
        correctAnswer: 'B',
        explanation: '「事中」指的是在模型訓練的過程中，直接修改演算法或損失函數，將公平性作為一個約束條件加入到優化目標中。'
    },
    {
        question: '下列何者是「樣本偏見」的例子？',
        options: {
            A: '一個在1980年代數據上訓練的招聘模型，可能對女性有偏見。',
            B: '一個人臉辨識模型的訓練數據中，絕大多數是白人男性的照片。',
            C: '使用郵遞區號作為預測信貸風險的特徵。',
            D: '模型的優化目標是最大化利潤。'
        },
        correctAnswer: 'B',
        explanation: '樣本偏見指的是數據的收集方式導致某些群體的代表性嚴重不足，這會使得模型在這些代表性不足的群體上表現很差。'
    },
    {
        question: '為何說不同的公平性定義有時是相互衝突的？',
        options: {
            A: '這是一個錯誤的說法，所有公平性定義都完全兼容。',
            B: '因為在數學上，通常不可能同時滿足所有不同定義的公平性指標。',
            C: '因為不同的研究團隊對公平有不同的看法。',
            D: '因為公平性是一個主觀概念，無法量化。'
        },
        correctAnswer: 'B',
        explanation: '這是在實踐公平性時的一個核心挑戰。例如，滿足「人口統計均等」可能意味著會違反「機會均等」。因此，必須根據具體的應用場景和價值觀，來選擇和權衡最重要的公平性目標。'
    },
    {
        question: '演算法偏見與公平性是哪個機器學習治理領域的核心議題？',
        options: {
            A: '模型安全',
            B: '數據隱私',
            C: '負責任AI (Responsible AI)',
            D: 'MLOps'
        },
        correctAnswer: 'C',
        explanation: '負責任AI是一個更宏觀的框架，旨在確保AI的開發和應用是安全、可靠、透明、公平且對社會有益的。演算法偏見與公平性是其中最受關注的倫理議題之一。'
    }
  ]
};
