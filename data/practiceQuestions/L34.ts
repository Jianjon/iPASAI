import type { PracticeQuestion } from '../../types';

export const L34_PRACTICE: Record<string, PracticeQuestion[]> = {
  L34101: [
    {
      question: '歐盟《人工智慧法案》(EU AI Act) 的核心監管方法是什麼？',
      options: {
        A: '對所有AI應用採取統一的嚴格標準。',
        B: '以技術類型為基礎的方法，對不同演算法有不同規定。',
        C: '以風險為基礎的方法，對不同風險等級的AI施加不同程度的監管。',
        D: '僅監管由政府開發的AI系統。'
      },
      correctAnswer: 'C',
      explanation: '法案的核心是其創新的「以風險為基礎」的方法，將AI應用分為不可接受、高、有限、最小四個風險等級，並施加與風險程度相稱的監管義務。'
    },
    {
      question: '根據歐盟AI法案，下列哪一項AI應用屬於「不可接受風險」，將被完全禁止？',
      options: {
        A: '用於篩選履歷的AI系統。',
        B: '由政府進行的通用型社會信用評分系統。',
        C: '與使用者對話的聊天機器人。',
        D: '用於輔助醫療診斷的AI軟體。'
      },
      correctAnswer: 'B',
      explanation: '法案明確禁止了幾類對基本權利構成重大威脅的AI應用，其中就包括由政府主導的通用型社會信用評分系統。'
    },
    {
      question: '歐盟AI法案的「境外效力」指的是什麼？',
      options: {
        A: '該法案只適用於歐盟境外的公司。',
        B: '只要AI系統的輸出結果在歐盟境內被使用，不論開發者在何處，都可能受到管轄。',
        C: '歐盟將派稽查員到全球各地進行檢查。',
        D: '該法案只對在歐盟註冊的公司有效。'
      },
      correctAnswer: 'B',
      explanation: '這是法案影響廣泛的關鍵條款。它確立了「市場準入」原則，意味著任何想將AI產品或服務提供給歐盟市場的企業，都必須遵守此法案。'
    },
    {
        question: '根據法案第二章，在工作場所或教育機構使用AI系統來推斷個人情緒，屬於哪個風險等級？',
        options: {
          A: '高風險',
          B: '有限風險',
          C: '最小風險',
          D: '不可接受風險'
        },
        correctAnswer: 'D',
        explanation: '法案明確禁止在工作場所和教育機構中部署情緒識別系統，因為這被認為嚴重侵犯了個人的基本權利，屬於不可接受的風險。'
    },
    {
        question: '下列何者是執法單位在公共場所使用「遠程即時生物辨識」（如人臉辨識）的例外情況？',
        options: {
          A: '為了監控交通違規。',
          B: '為了預防真實且迫在眉睫的恐怖攻擊威脅。',
          C: '為了識別參加合法抗議的民眾。',
          D: '沒有任何例外情況，一律禁止。'
        },
        correctAnswer: 'B',
        explanation: '法案對此設下了極其嚴格的豁免條件，僅在預防重大威脅、尋找受害者或追捕重罪嫌犯等極端情況下，並經司法授權，才被允許使用。'
    },
    {
        question: '「AI法案的四條紅線」記憶輔助中，「不評分」對應的是哪項被禁止的實踐？',
        options: {
          A: '潛意識操縱技術',
          B: '利用弱勢群體',
          C: '通用型社會信用評分',
          D: '無差別抓取臉部影像'
        },
        correctAnswer: 'C',
        explanation: '記憶輔助中的「不評分」直接對應法案禁止由公共主管機關出於通用目的進行社會信用評分。'
    },
    {
        question: '歐盟AI法案對「AI系統」的定義，強調了AI的哪兩項能力？',
        options: {
          A: '情感與創造力',
          B: '計算速度與儲存容量',
          C: '自主性與影響環境的能力',
          D: '開源與免費'
        },
        correctAnswer: 'C',
        explanation: '法案採用的定義相當廣泛，其核心是AI能夠在一定程度上自主運行，並其輸出（如決策、推薦）能對物理或虛擬環境產生影響。'
    },
    {
        question: '一家臺灣公司開發的AI玩具，其主要市場在歐盟。該公司是否需要遵守歐盟AI法案？',
        options: {
          A: '否，因為公司不在歐盟。',
          B: '是，因為其產品的輸出結果在歐盟境內被使用，受到境外效力管轄。',
          C: '否，因為玩具不屬於AI系統。',
          D: '只有在該公司於歐盟設立分公司後才需要。'
        },
        correctAnswer: 'B',
        explanation: '法案的境外效力是基於「市場」而非「開發者所在地」。只要產品或服務在歐盟市場上提供，就必須遵守該法案。'
    },
    {
        question: '下列哪一項AI實踐，根據法案，原則上被禁止，但設有極其嚴格的例外情況？',
        options: {
          A: '利用潛意識技術操縱個人行為。',
          B: '執法單位在公共場所進行遠程即時生物辨識。',
          C: '政府進行的通用型社會信用評分。',
          D: '利用老年人的脆弱性誘導其購買不必要的產品。'
        },
        correctAnswer: 'B',
        explanation: '在四類被禁止的實踐中，只有執法單位使用遠程即時生物辨識設有極少數、經嚴格司法授權的豁免情況，其他三類是絕對禁止。'
    },
    {
        question: '歐盟AI法案的主要目標「不」包含下列何者？',
        options: {
          A: '確保AI系統的安全與合規。',
          B: '保護民眾的基本權利。',
          C: '促進AI技術的投資與創新。',
          D: '確保歐盟在AI演算法開發上領先全球。'
        },
        correctAnswer: 'D',
        explanation: '法案的目標是在「安全監管」與「促進創新」之間取得平衡，建立一個可信賴的AI生態系。它是一個監管框架，而非產業發展政策，其目標不是確保技術領先。'
    }
  ],
  L34102: [
    {
        question: '根據歐盟AI法案附件三，下列哪個領域的AI應用「不」被直接推定為高風險？',
        options: {
          A: '用於篩選履歷的就業管理系統。',
          B: '用於評估考試成績的教育系統。',
          C: '用於推薦電影的娛樂系統。',
          D: '用於決定社會福利資格的公共服務系統。'
        },
        correctAnswer: 'C',
        explanation: '附件三列舉的八大高風險領域，主要涉及對個人健康、安全、基本權利有重大影響的場景。電影推薦系統通常被視為最小風險。'
    },
    {
        question: '高風險AI系統的義務中，「高品質的資料治理」要求用於訓練的資料集必須具備哪些特性？',
        options: {
          A: '相關性、代表性、無錯誤且完整。',
          B: '檔案大小最小、格式最統一。',
          C: '全部來自公開資料、完全匿名。',
          D: '資料量最大、更新頻率最高。'
        },
        correctAnswer: 'A',
        explanation: '法案對高風險系統的訓練資料品質有明確要求，這四個特性（相關、代表、無誤、完整）是確保模型公平性與準確性的基礎。'
    },
    {
        question: '一個AI系統如果作為受歐盟玩具安全指令規範的玩具的安全組件，它會被歸類為哪個風險等級？',
        options: {
          A: '最小風險',
          B: '有限風險',
          C: '高風險',
          D: '不可接受風險'
        },
        correctAnswer: 'C',
        explanation: '法案規定，如果AI系統是受現有特定安全法規（如玩具安全指令）規範的產品的安全組件，它就自動被視為高風險AI系統。'
    },
    {
        question: '在高風險系統的義務中，要求系統必須能自動、可追溯地記錄事件（Logs），這主要是為了實現什麼？',
        options: {
          A: '提高系統的運行速度。',
          B: '減少數據儲存的需求。',
          C: '實現問責性與事後審計。',
          D: '方便使用者查看日誌。'
        },
        correctAnswer: 'C',
        explanation: '保留日誌紀錄是實現可追溯性的基礎。當模型做出錯誤決策或發生事故時，這些紀錄是分析原因、釐清責任的關鍵證據。'
    },
    {
        question: '下列何者是「備妥詳盡的技術文件」這項義務的主要目的？',
        options: {
          A: '為了讓競爭對手可以參考。',
          B: '為了讓主管機關能夠評估該系統是否符合所有規定。',
          C: '為了作為產品的行銷手冊。',
          D: '這只是一個形式要求，沒有實際用途。'
        },
        correctAnswer: 'B',
        explanation: '技術文件是提供者向監管機構證明其產品合規性的核心證據。監管機構將依據這份文件來審查該AI系統是否滿足法案的所有要求。'
    },
    {
        question: '一家銀行使用AI來進行信貸評分，以決定是否批准貸款。該AI系統最可能被歸類為？',
        options: {
          A: '最小風險，因為是金融應用。',
          B: '高風險，因為屬於附件三中「關鍵私人服務的取用」。',
          C: '不可接受風險，因為涉及金錢。',
          D: '有限風險，只需告知客戶即可。'
        },
        correctAnswer: 'B',
        explanation: '信貸評分直接決定了個人能否獲取關鍵的金融服務，對個人權益有重大影響，因此被明確列於附件三的高風險清單中。'
    },
    {
        question: '高風險八大領域速記「生、基、教、勞、公、法、移、司」中，「勞」指的是哪個領域？',
        options: {
          A: '勞動檢查',
          B: '就業、勞工管理與自僱機會',
          C: '退休金管理',
          D: '工會組織'
        },
        correctAnswer: 'B',
        explanation: '記憶輔助中的「勞」字，對應的是附件三中關於「就業、勞工管理與自僱機會」的類別，涵蓋了招聘、績效評估等應用。'
    },
    {
        question: '建立並維護一個持續的風險識別、評估和緩解流程，這屬於高風險系統的哪一項義務？',
        options: {
          A: '保留紀錄',
          B: '建立風險管理系統',
          C: '高品質的資料治理',
          D: '確保人類監督'
        },
        correctAnswer: 'B',
        explanation: '這是七大義務之首，要求提供者必須有一個動態的、貫穿整個生命週期的風險管理框架，而不僅僅是一次性的風險評估。'
    },
    {
        question: '為何法案對高風險AI系統的訓練資料有如此嚴格的要求？',
        options: {
          A: '為了增加提供者的開發成本。',
          B: '因為訓練資料的品質，是模型準確性、穩健性及公平性的根本來源。',
          C: '為了讓所有公司都使用相同的資料集。',
          D: '因為高品質的資料儲存起來比較容易。'
        },
        correctAnswer: 'B',
        explanation: '「Garbage in, garbage out」。法案深刻認識到，有偏見、不完整或錯誤的資料是導致AI產生有害結果的主要根源，因此從資料治理上設立了高標準。'
    },
    {
        question: '一個AI系統被用於管理城市的電網。此應用屬於附件三中的哪個高風險類別？',
        options: {
          A: '執法',
          B: '司法',
          C: '教育',
          D: '關鍵基礎設施的管理與營運'
        },
        correctAnswer: 'D',
        explanation: '電網屬於城市的關鍵基礎設施，其穩定運行至關重要。因此，用於管理這類設施的AI系統被歸類為高風險。'
    }
  ],
  L34103: [
    {
      question: '在高風險AI系統的義務中，「確保適當的人類監督」其核心目標是什麼？',
      options: {
        A: '讓AI系統的每個決策都必須由人類手動批准。',
        B: '確保AI系統始終處於人類的有效控制之下，並允許人類干預或停止。',
        C: '只是為了在系統出錯時，可以找到負責的人。',
        D: '讓更多的人可以參與AI系統的開發。'
      },
      correctAnswer: 'B',
      explanation: '人類監督是確保AI安全、可控的關鍵機制。它要求系統的設計必須包含一個可靠的「剎車」，讓人類始終保有最終的控制權。'
    },
    {
      question: '在AI供應鏈中，哪個角色對高風險系統的合規性負有最主要的、全面的責任？',
      options: {
        A: '使用者 (User)',
        B: '提供者 (Provider)',
        C: '經銷商 (Distributor)',
        D: '進口商 (Importer)'
      },
      correctAnswer: 'B',
      explanation: '提供者是將AI系統推向市場的第一方，因此法案將確保系統完全合規的絕大部分義務都放在提供者身上，他們是責任的核心。'
    },
    {
      question: '一家法國銀行（使用者）從一家德國公司（進口商）購買了一套由美國公司（提供者）開發的AI信評軟體。根據法案，法國銀行的主要義務是什麼？',
      options: {
        A: '重新對軟體進行完整的合格評定程序。',
        B: '按照提供者的使用說明來操作，並對系統進行人類監督。',
        C: '幫助美國公司修改軟體的原始碼。',
        D: '不需負擔任何義務，所有責任都在美國公司。'
      },
      correctAnswer: 'B',
      explanation: '作為使用者，法國銀行的責任在於「正確地使用」和「有效地監督」。他們必須遵循使用說明，並確保最終的信貸決策是在人類監督下做出的。'
    },
    {
      question: '「高度的準確性、穩健性與安全性」這項義務，對「穩健性」的要求是什麼？',
      options: {
        A: '系統的預測必須100%正確。',
        B: '系統應能抵抗因錯誤或不一致的輸入而產生的錯誤。',
        C: '系統的程式碼必須沒有任何漏洞。',
        D: '系統必須使用最新的硬體。'
      },
      correctAnswer: 'B',
      explanation: '穩健性（Robustness）指的是系統在面對異常、非預期或有問題的輸入時的容錯能力和恢復能力，確保其不會輕易崩潰或產生災難性後果。'
    },
    {
      question: '一家位於歐盟境外的AI公司，想將其高風險AI產品銷售到歐盟，必須先做什麼？',
      options: {
        A: '在歐盟設立一個總部。',
        B: '確保其產品完全符合AI法案的所有義務，並完成合格評定程序（如獲得CE標誌）。',
        C: '將其產品的價格降低一半。',
        D: '只需找到一個歐盟的經銷商即可。'
      },
      correctAnswer: 'B',
      explanation: 'CE標誌是產品進入歐盟市場的「護照」。對於高風險AI系統，提供者必須先完成所有合規工作和評定程序，證明其產品是安全合規的，才能合法地在歐盟銷售。'
    },
    {
      question: 'AI供應鏈的守門人記憶輔助中，「海關」比喻的是哪個角色？',
      options: {
        A: '提供者',
        B: '使用者',
        C: '進口商',
        D: '經銷商'
      },
      correctAnswer: 'C',
      explanation: '進口商是將境外產品首次引入歐盟市場的關鍵角色，如同海關一樣，他們有責任對產品的合規性進行第一道把關和檢查。'
    },
    {
      question: '下列何者不是高風險AI系統提供者對使用者必須履行的「透明度」義務？',
      options: {
        A: '提供清晰的使用說明書。',
        B: '告知系統的能力與限制。',
        C: '解釋系統的預期目的。',
        D: '提供模型的完整訓練資料集。'
      },
      correctAnswer: 'D',
      explanation: '對使用者的透明度義務，旨在確保使用者能「正確且安全地使用」系統，但不代表需要提供涉及營業秘密和大量隱私的完整訓練資料集。'
    },
    {
      question: '為何法案要對供應鏈中的進口商和經銷商也施加義務？',
      options: {
        A: '為了增加他們的營運成本。',
        B: '為了建立一個層層把關的監管鏈條，確保市場上的產品都經過多重驗證。',
        C: '因為他們比提供者更了解技術。',
        D: '這只是一個形式上的要求。'
      },
      correctAnswer: 'B',
      explanation: '透過讓供應鏈的每個環節都負起檢查和驗證的責任，法案建立了一個更具韌性的市場監督體系，降低了不合規產品流入市場的風險。'
    },
    {
      question: '一個高風險AI系統的使用者，在發現系統可能導致嚴重風險時，應採取的首要行動是什麼？',
      options: {
        A: '嘗試自己修復系統。',
        B: '立即停止使用，並通知提供者和相關主管機關。',
        C: '忽略該風險，繼續使用。',
        D: '在社群媒體上公開該問題。'
      },
      correctAnswer: 'B',
      explanation: '使用者處於監控系統實際運作的第一線。法案規定，當使用者發現重大風險時，有義務立即中止使用並通報，以防止危害擴大。'
    },
    {
      question: '「確保適當的人類監督」這項義務，意味著什麼？',
      options: {
        A: 'AI系統的旁邊必須隨時有一位員工站著監看。',
        B: '系統的設計應內建允許人類有效監督和干預的機制。',
        C: '所有AI的決策都必須由委員會投票決定。',
        D: 'AI系統的準確率可以降低。'
      },
      correctAnswer: 'B',
      explanation: '人類監督是一項「由設計而始」的要求。它指的是系統本身應具備支援人類監督的功能，而非僅僅是事後的人力安排。'
    }
  ],
  L34104: [
    {
      question: '根據歐盟AI法案，當您在網路上與一個聊天機器人互動時，該系統的提供者應履行什麼義務？',
      options: {
        A: '必須告訴您該聊天機器人的開發成本。',
        B: '必須讓您知曉您是在與一個AI系統互動。',
        C: '必須提供該AI的原始碼。',
        D: '不需履行任何義務，因為聊天機器人風險很低。'
      },
      correctAnswer: 'B',
      explanation: '聊天機器人屬於「有限風險」，其核心義務是「透明度」。為了避免使用者被誤導，法案規定必須讓使用者清楚地知道其互動對象是AI。'
    },
    {
      question: '法案對所有通用目的AI模型（GPAI）的提供者，都規定了下列哪一項義務？',
      options: {
        A: '必須將模型開源。',
        B: '必須公開一份關於用於訓練模型的內容的詳細摘要。',
        C: '必須為所有使用者提供免費的API。',
        D: '必須保證模型永不產生錯誤資訊。'
      },
      correctAnswer: 'B',
      explanation: '為了提高基礎模型的透明度，法案要求所有GPAI提供者都需公開其訓練資料的摘要，讓外界對其學習的內容有一個大致的了解。'
    },
    {
      question: '一個藝術家使用AI工具生成了一張看起來像真實照片的風景圖，並將其發布在社群媒體上。根據法案，他應該做什麼？',
      options: {
        A: '無需做任何事。',
        B: '申請高風險系統認證。',
        C: '刪除這張圖片。',
        D: '以清晰可見的方式標示該圖片為「人工生成」。'
      },
      correctAnswer: 'D',
      explanation: '這屬於對「深度偽造」（Deepfake）的透明度義務。為了防止公眾被誤導，看起來像真實事物的AI生成內容必須被明確標示。'
    },
    {
      question: '下列哪個GPAI模型，最可能被認定為具有「系統性風險」而需履行更嚴格的義務？',
      options: {
        A: '一個只用於學術研究的小型實驗性模型。',
        B: '一個能力強大、被廣泛使用、可能對社會產生重大影響的模型（如GPT-4）。',
        C: '一個只在單一公司內部使用的模型。',
        D: '一個開源的模型。'
      },
      correctAnswer: 'B',
      explanation: '「系統性風險」的認定標準，主要基於模型的技術能力（如運算量）及其影響範圍。像GPT-4這樣能力頂尖且影響深遠的模型，是法案中額外嚴格監管的對象。'
    },
    {
      question: '記憶輔助「透明度三原則：說、標、明」中，「明」指的是什麼？',
      options: {
        A: '必須明確告知互動對象是AI。',
        B: '必須明確標示AI生成的圖片。',
        C: 'AI生成的、關於公共利益的文本，必須**明**確標示為AI所寫。',
        D: '必須闡明模型的演算法。'
      },
      correctAnswer: 'C',
      explanation: '記憶輔助中的「明」對應的是針對AI生成文本的特殊透明度要求，特別是當文本涉及可能影響公眾輿論的事項時。'
    },
    {
      question: '法案要求GPAI提供者制定版權政策，主要是為了解決什麼問題？',
      options: {
        A: '模型本身的版權歸屬問題。',
        B: '模型訓練過程中，可能使用了大量受版權保護的網路資料的問題。',
        C: '使用者生成內容的版權問題。',
        D: '模型被非法複製的問題。'
      },
      correctAnswer: 'B',
      explanation: '這是目前關於基礎模型最大的爭議之一。法案要求模型提供者必須有明確的政策，來說明他們如何遵守歐盟的版權法，以應對此問題。'
    },
    {
      question: '下列何者是針對具「系統性風險」的GPAI模型的「額外」義務？',
      options: {
        A: '提供技術文件。',
        B: '制定版權政策。',
        C: '進行對抗性測試以評估和緩解風險。',
        D: '公開訓練資料的摘要。'
      },
      correctAnswer: 'C',
      explanation: 'A、B、D是所有GPAI模型都需履行的基礎義務。而進行模型評估（包括對抗性測試）、風險緩解、報告嚴重事件等，是只針對最強大的、具系統性風險的模型才有的額外嚴格要求。'
    },
    {
      question: '法案對GPAI模型的規範，體現了什麼樣的監管思路？',
      options: {
        A: '只監管最終的AI應用，不監管上游技術。',
        B: '從源頭上進行監管，確保作為AI生態系基礎的通用模型是透明且可信的。',
        C: '試圖禁止所有通用目的AI模型的發展。',
        D: '要求所有GPAI模型都必須由歐盟開發。'
      },
      correctAnswer: 'B',
      explanation: '法案意識到，許多AI應用的風險源於其底層的基礎模型。因此，透過對上游的GPAI模型施加義務，可以更有效地管理整個AI生態系的風險。'
    },
    {
      question: '一家公司基於一個GPAI開發了一個高風險的AI應用。GPAI提供者有義務向該公司提供什麼？',
      options: {
        A: '免費的API點數。',
        B: '市場行銷的建議。',
        C: '足夠的資訊和文件，以幫助該公司履行其在高風險系統下的合規義務。',
        D: '其公司的股票。'
      },
      correctAnswer: 'C',
      explanation: '這是確保AI供應鏈責任能夠順利傳遞的關鍵條款。上游的GPAI提供者必須向下游的應用開發者提供必要的技術資訊，讓他們能夠完成自己的合規工作。'
    },
    {
      question: '法案要求具系統性風險的GPAI模型需報告其能源消耗，這主要與AI治理的哪個宏觀目標有關？',
      options: {
        A: '公平性',
        B: '透明性',
        C: '安全性',
        D: '永續發展'
      },
      correctAnswer: 'D',
      explanation: '訓練和運行大型基礎模型需要消耗巨大的能源，這對環境造成了影響。要求報告能源消耗，是將AI的環境足跡納入監管考量，與永續發展（ESG）的目標一致。'
    }
  ],
  L34105: [
    {
      question: '歐盟AI法案中設立「AI監管沙盒」的主要目的是什麼？',
      options: {
        A: '對所有高風險AI系統進行永久性的隔離。',
        B: '為AI的開發和測試提供一個受控的實驗環境，以促進負責任的創新。',
        C: '一個專門用來懲罰違規企業的場所。',
        D: '一個供大眾體驗最新AI技術的展覽。'
      },
      correctAnswer: 'B',
      explanation: '監管沙盒是一個「安全實驗區」，旨在降低創新者（特別是中小企業）的合規門檻，讓他們可以在監管機構的指導下，安全地測試其產品，從而鼓勵創新。'
    },
    {
      question: '在歐盟AI法案的治理架構中，哪個機構是設立於歐盟執委會內部，負責監督法案在歐盟層級的執行核心？',
      options: {
        A: '歐洲人工智慧委員會 (AI Board)',
        B: '歐洲人工智慧辦公室 (AI Office)',
        C: '國家主管機關 (National Competent Authority)',
        D: '歐洲議會 (European Parliament)'
      },
      correctAnswer: 'B',
      explanation: 'AI辦公室是法案設立的一個新的、常設的歐盟層級執行機構，負責協調和監督法案的實施，特別是針對GPAI模型的執法。'
    },
    {
      question: '「歐洲人工智慧委員會 (AI Board)」的成員主要由誰組成？',
      options: {
        A: '大型科技公司的CEO。',
        B: '每個歐盟成員國的一名代表。',
        C: '頂尖大學的AI教授。',
        D: '消費者保護組織的代表。'
      },
      correctAnswer: 'B',
      explanation: 'AI委員會是一個由各成員國代表組成的機構，其主要職能是作為諮詢單位，促進各國監管實踐的一致性，確保法案在各國的解釋和執行不會出現太大分歧。'
    },
    {
      question: '根據法案，誰可以優先進入AI監管沙盒？',
      options: {
        A: '只有大型跨國企業。',
        B: '中小企業 (SMEs) 和新創公司。',
        C: '只有政府機構。',
        D: '任何有興趣的個人。'
      },
      correctAnswer: 'B',
      explanation: '法案特別強調要支持創新，並認識到中小企業在合規上面臨更大的挑戰。因此，法案要求成員國應為中小企業和新創公司提供優先進入沙盒的機會。'
    },
    {
      question: '「一大腦、一議會、眾手腳」的記憶輔助中，「眾手腳」指的是哪個機構？',
      options: {
        A: 'AI辦公室',
        B: 'AI委員會',
        C: '國家主管機關',
        D: '監管沙盒'
      },
      correctAnswer: 'C',
      explanation: '「眾手腳」比喻的是在每個成員國負責具體執法和市場監督的國家級主管機關，他們是法案在地方落地的執行者。'
    },
    {
      question: '下列何者是AI監管沙盒提供的價值？',
      options: {
        A: '為參與者提供直接的資金補助。',
        B: '讓參與者可以豁免所有AI法案的規定。',
        C: '讓參與者在上市前，能從監管機構獲得指導，降低合規不確定性。',
        D: '保證參與者的產品一定能在市場上取得成功。'
      },
      correctAnswer: 'C',
      explanation: '沙盒最大的價值在於提供了一個與監管者直接溝通和學習的管道，讓創新者可以在開發早期就釐清合規路徑，避免在錯誤的方向上投入過多資源。'
    },
    {
      question: '歐盟AI法案的治理架構是單層還是雙層的？',
      options: {
        A: '單層的，只有歐盟層級的機構。',
        B: '單層的，只有國家層級的機構。',
        C: '雙層的，結合了歐盟層級的機構（AI辦公室、委員會）和國家層級的機構。',
        D: '三層的，還包含了市級的機構。'
      },
      correctAnswer: 'C',
      explanation: '法案的治理是一個歐盟與成員國協同的雙層架構，旨在確保法規的統一性（由歐盟機構協調）和執行的落地性（由國家機構負責）。'
    },
    {
      question: '歐盟AI法案設立支持創新措施的主要考量是什麼？',
      options: {
        A: '法案的主要目的是支持創新，監管只是次要的。',
        B: '為了在嚴格監管的同時，避免扼殺創新，特別是保護中小企業的發展。',
        C: '因為監管沙盒可以為政府帶來收入。',
        D: '為了與美國的創新政策競爭。'
      },
      correctAnswer: 'B',
      explanation: '這體現了法案試圖在「監管」與「創新」之間取得平衡的立法哲學。它認識到過於嚴苛的監管可能會不成比例地影響資源較少的中小企業，因此設計了沙盒等支持機制。'
    },
    {
      question: '下列哪個機構主要負責監督具「系統性風險」的通用目的AI模型？',
      options: {
        A: '歐洲人工智慧委員會 (AI Board)',
        B: '每個國家的市場監督機關。',
        C: '歐洲人工智慧辦公室 (AI Office)',
        D: 'AI監管沙盒。'
      },
      correctAnswer: 'C',
      explanation: '對於影響力最大、風險最高的GPAI模型，法案將其監督和執法的權力集中在歐盟層級的AI辦公室，以確保監管的統一性和專業性。'
    },
    {
      question: '參與AI監管沙盒是否為強制性的？',
      options: {
        A: '是，所有高風險AI系統都必須先進入沙盒。',
        B: '否，參與應基於自願原則。',
        C: '是，所有中小企業都必須參加。',
        D: '否，但如果不參加會面臨罰款。'
      },
      correctAnswer: 'B',
      explanation: '法案明確規定，監管沙盒是一個支持性的、自願參與的機制，旨在幫助而非強制創新者。'
    }
  ],
  L34106: [
    {
      question: '根據歐盟AI法案，違反「禁止的AI實踐」的公司，最高可能面臨多少罰款？',
      options: {
        A: '1500萬歐元或全球年度總營業額的3%。',
        B: '750萬歐元或全球年度總營業額的1.5%。',
        C: '3500萬歐元或全球年度總營業額的7%。',
        D: '5000萬歐元或全球年度總營業額的10%。'
      },
      correctAnswer: 'C',
      explanation: '這是法案中最高級別的罰則，針對的是違反最根本倫理紅線的行為，其罰款金額極具威懾力。'
    },
    {
      question: '高風險AI系統的提供者，在產品上市後仍需履行的持續性義務是什麼？',
      options: {
        A: '每個月都發布一個新版本。',
        B: '建立並維護一個上市後監督(PMM)系統。',
        C: '將所有使用者資料都刪除。',
        D: '上市後就不再有任何義務。'
      },
      correctAnswer: 'B',
      explanation: '上市後監督（Post-Market Monitoring）是確保AI系統在整個生命週期中持續合規和安全的關鍵機制，是提供者的一項長期責任。'
    },
    {
      question: '一家公司在接受調查時，向主管機關提供了不實的技術文件。該公司可能面臨哪一級別的罰款？',
      options: {
        A: '最高級別（7%）',
        B: '次高級別（3%）',
        C: '最低級別（1.5%）',
        D: '不會面臨罰款，只會收到警告。'
      },
      correctAnswer: 'C',
      explanation: '法案將「提供不正確、不完整或誤導性的資訊」列為一個獨立的處罰類別，最高可罰750萬歐元或全球營業額的1.5%。'
    },
    {
      question: '在上市後監督中，當提供者發現其AI系統導致了「嚴重事件」時，應採取的首要行動是什麼？',
      options: {
        A: '立即將該系統下架並銷毀。',
        B: '嘗試在內部秘密修復，不告知任何人。',
        C: '立即向相關國家的市場監督機關報告。',
        D: '等待使用者提出客訴。'
      },
      correctAnswer: 'C',
      explanation: '法案規定了強制性的嚴重事件報告義務。提供者有責任在發現問題後，主動、及時地向監管機構通報，以便共同控制風險。'
    },
    {
      question: '「罰款三級跳：7%, 3%, 1.5%」記憶輔助中，「沒做功課」指的是什麼？',
      options: {
        A: '違反了「禁止的AI實踐」。',
        B: '提供了不實的資訊。',
        C: '違反了法案中除禁止條款外的其他主要義務（如高風險系統的合規要求）。',
        D: '沒有參加AI相關的培訓課程。'
      },
      correctAnswer: 'C',
      explanation: '記憶輔助中的「沒做功課」比喻的是未能履行法案中規定的各種合規義務，對應的是次高級別的罰款（最高1500萬歐元或3%）。'
    },
    {
      question: '國家市場監督機關的權力「不」包含下列何者？',
      options: {
        A: '要求提供者提供技術文件進行檢查。',
        B: '對不合規的AI系統下令召回。',
        C: '直接接管違規公司的營運。',
        D: '對市場上的AI系統進行抽查。'
      },
      correctAnswer: 'C',
      explanation: '市場監督機關的權力主要集中在產品的監督和執法上，如檢查、要求改正、限制上市或召回，但不能直接干預公司的內部營運。'
    },
    {
      question: '歐盟AI法案的罰則，其計算基礎是什麼，使其極具威懾力？',
      options: {
        A: '公司的註冊資本額。',
        B: '公司的年度利潤。',
        C: '公司的全球年度總營業額。',
        D: 'AI專案的開發預算。'
      },
      correctAnswer: 'C',
      explanation: '與歐盟的GDPR類似，AI法案的罰款是與公司的全球營業額掛鉤的。這意味著對於大型跨國公司而言，罰款金額可能是天文數字，從而確保它們會嚴肅對待合規義務。'
    },
    {
      question: '高風險AI系統的提供者，若發現系統不合規，在採取糾正措施後，還需要通知誰？',
      options: {
        A: '只需通知公司內部的法務部門。',
        B: '需要通知供應鏈中的經銷商、進口商和使用者。',
        C: '只需在公司網站上發布公告。',
        D: '不需要通知任何人。'
      },
      correctAnswer: 'B',
      explanation: '提供者有責任確保整個供應鏈的資訊透明。當產品出現問題時，必須通知下游的合作夥伴和最終使用者，以便他們能採取相應的行動。'
    },
    {
      question: '建立一個公開的、用於註冊高風險AI系統的歐盟資料庫，其主要目的是什麼？',
      options: {
        A: '增加市場透明度，便於公眾和監管機構監督。',
        B: '對註冊的公司收取費用。',
        C: '讓公司可以互相比較其AI系統的數量。',
        D: '取代公司的官方網站。'
      },
      correctAnswer: 'A',
      explanation: '這個公開資料庫是提高透明度的重要措施，它讓市場監督變得更容易，也讓公眾對哪些高風險AI系統正在市場上運行有一個清晰的了解。'
    },
    {
      question: '為何說AI的合規性是一個「持續的過程」？',
      options: {
        A: '因為法規會一直改變。',
        B: '因為上市後監督(PMM)要求提供者在產品的整個生命週期中，都必須主動監控其性能與風險。',
        C: '因為每年都需要重新申請一次認證。',
        D: '因為開發人員喜歡不斷修改程式碼。'
      },
      correctAnswer: 'B',
      explanation: '法案確立了AI的責任是貫穿其整個生命週期的。上市審查只是第一步，持續的上市後監督才是確保AI長期安全合規的關鍵。'
    }
  ],
  L34107: [
    {
      question: '根據歐盟AI法案，「行為準則 (Codes of Conduct)」的性質是什麼？',
      options: {
        A: '是所有AI系統都必須遵守的強制性法律。',
        B: '是由AI系統的提供者或產業協會等，自願制定的一套實踐準則。',
        C: '是由歐盟執委會為每個行業制定的詳細技術規範。',
        D: '是取代AI法案的另一套法規。'
      },
      correctAnswer: 'B',
      explanation: '行為準則是法案鼓勵的一種「軟法」或「自我調節」機制，旨在為風險較低的AI應用提供最佳實踐指導，是對強制性法律的補充。'
    },
    {
      question: '歐盟AI法案的實施時間表是怎樣的？',
      options: {
        A: '法案生效後，所有條款立即全面適用。',
        B: '是分階段的，給予市場足夠的適應時間。',
        C: '由每個成員國自行決定何時開始適用。',
        D: '在法案公布後五年才開始適用。'
      },
      correctAnswer: 'B',
      explanation: '法案採用了分階段實施（staggered application）的方式，從禁止條款（6個月）、GPAI義務（12個月）到大部分條款（24個月），為企業提供了逐步適應的緩衝期。'
    },
    {
      question: '法案中「禁止的AI實踐」相關條款，將在法案生效後多久開始適用？',
      options: {
        A: '立即適用',
        B: '6個月後',
        C: '12個月後',
        D: '24個月後'
      },
      correctAnswer: 'B',
      explanation: '由於禁止條款涉及對基本權利的重大威脅，法案為其設定了最早的適用期限，即生效後6個月，以便盡快清除市場上最有害的AI應用。'
    },
    {
      question: '「行為準則」主要是為哪一類AI系統提供指導？',
      options: {
        A: '高風險AI系統',
        B: '非高風險AI系統',
        C: '被禁止的AI系統',
        D: '通用目的AI模型'
      },
      correctAnswer: 'B',
      explanation: '法案鼓勵為非高風險的AI系統制定行為準則，以自願的方式來實踐法案的某些原則（如永續發展），促進整個生態系的健康發展。'
    },
    {
      question: '「AI法案上路時間表」記憶輔助中，「+24個月」對應的是什麼事件？',
      options: {
        A: '禁止條款生效。',
        B: 'GPAI義務生效。',
        C: '法案的絕大部分條款開始全面適用。',
        D: '法案完全失效。'
      },
      correctAnswer: 'C',
      explanation: '生效後24個月是最大的一個時間節點，屆時包括對高風險AI系統的嚴格義務在內的大部分法規都將正式實施，是企業合規的最終大限。'
    },
    {
      question: '對於在法規全面適用之日前就已經投放市場的AI系統，法案提供了什麼？',
      options: {
        A: '可以永久豁免所有規定。',
        B: '必須立即下架。',
        C: '提供了一定的過渡期，讓其有時間進行調整以符合法案要求。',
        D: '會被處以雙倍的罰款。'
      },
      correctAnswer: 'C',
      explanation: '為了避免對現有市場造成過度衝擊，法案為「存量」的AI系統提供了一定的緩衝和過渡期，體現了其立法上的務實考量。'
    },
    {
      question: '法案的最終條款，主要涉及什麼內容？',
      options: {
        A: '對高風險AI系統的技術要求。',
        B: '對AI倫理的哲學思辨。',
        C: '法案的立法技術細節、生效日期與實施時間表。',
        D: '對AI產業的未來預測。'
      },
      correctAnswer: 'C',
      explanation: '最終條款（Final Provisions）通常是法律文本的最後部分，用於處理程序性、時間性的問題，確保法律能夠順利地、有序地生效和實施。'
    },
    {
      question: '歐洲的遊戲開發者協會，共同制定了一份關於在遊戲中負責任地使用AI的指引。這屬於AI法案中的哪一項？',
      options: {
        A: '強制性的高風險系統義務。',
        B: '自願性的行為準則。',
        C: '被禁止的AI實踐。',
        D: '監管沙盒。'
      },
      correctAnswer: 'B',
      explanation: '由於AI遊戲通常屬於最小風險，因此產業協會自願制定指引，以展現其自律和社會責任，是法案第九章所鼓勵的「行為準則」的典型例子。'
    },
    {
      question: '法案設定分階段實施時間表的主要原因是什麼？',
      options: {
        A: '因為立法者還沒完全想清楚。',
        B: '為了給予企業、監管機構和標準制定單位足夠的時間來準備和適應。',
        C: '為了讓法案看起來更複雜。',
        D: '為了配合歐盟的選舉週期。'
      },
      correctAnswer: 'B',
      explanation: 'AI法案是一部非常複雜的法規，其成功實施需要整個生態系的共同努力。分階段的時間表為各方進行技術調整、流程改造和能力建設，提供了必要的準備時間。'
    },
    {
      question: '關於「通用目的AI模型(GPAI)」的義務，將在法案生效後多久開始適用？',
      options: {
        A: '6個月後',
        B: '12個月後',
        C: '24個月後',
        D: '36個月後'
      },
      correctAnswer: 'B',
      explanation: '法案為GPAI的義務設定了12個月的適用期限，早於大部分高風險系統的24個月，體現了監管機構從源頭上治理AI生態系的思路。'
    }
  ]
};
