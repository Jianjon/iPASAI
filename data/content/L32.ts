import type { LearningContent } from '../../types';

export const L32_CONTENT: Record<string, LearningContent> = {
  // L321 總則與核心原則
  L32101: {
    introduction: '金融業導入AI技術已是不可逆的趨勢，然而創新與風險如影隨形。本指引旨在為金融業導入及運用AI提供一個共通性的原則框架，確保在追求效率與創新的同時，能有效控管風險、保障消費者權益並維持金融市場穩定。本單元將從AI的基礎定義、系統生命週期、風險評估基礎，到第三方業者管理，建立一個全面的認知基礎。',
    keyConcepts: [
      {
        title: 'AI相關定義',
        explanation: `• **AI系統**: 指透過機器學習演算法、大量資料學習，能進行感知、預測、推薦、決策等模仿人類思考反應模式的系統。其核心特徵是「從資料中學習」，而非僅執行固定規則。\n• **生成式AI (Generative AI)**: 是AI的一個分支，專指能生成模擬人類智慧創造之內容（如文章、圖像、程式碼、音樂）的AI系統，是近年發展的重點。`
      },
      {
        title: 'AI系統生命週期 (4階段)',
        explanation: `一個負責任的AI系統，其生命週期應涵蓋從無到有、再到持續維運的完整過程：
1. **系統規劃及設計**: 此為起始階段，需明確定義系統要解決的業務問題、預期目標、功能需求、適用範圍，以及初步的風險與倫理考量。
2. **資料蒐集及輸入**: 資料是AI的燃料。此階段涉及蒐集、清理、標註、整合來自不同來源的資料，並確保其品質與合規性。
3. **模型建立及驗證**: 這是技術核心階段，包含選擇合適的演算法、訓練模型、評估模型效能（準確率、穩健性、公平性），並進行反覆的參數調校與優化。
4. **系統部署及監控**: 將驗證通過的模型部署到實際營運環境，並建立持續的監控機制，追蹤模型表現、偵測數據漂移，確保系統長期穩定運行。`
      },
      {
        title: '風險評估考量因素 (風險為本原則)',
        explanation: `金融機構應以「風險為本(Risk-based Approach)」，根據AI應用的風險高低，採取不同程度的控管措施。評估因素包括：
• **對客戶/營運的影響**: AI決策是否直接影響客戶權益（如核貸、拒保）或對營運有重大影響？影響越大，風險越高。
• **個資使用程度**: 使用原始個人資料或機敏個資（如健康、財務狀況）的程度越高，隱私風險越高。
• **AI自主決策程度**: AI取代人類判斷、或能自主學習並調整決策邏輯的程度越高，失控風險越高。
• **AI系統複雜性**: 模型越複雜、越像「黑盒子」，其可解釋性就越低，潛在的偏見與錯誤也越難被發現，風險越高。
• **利害關係人影響廣度**: 決策影響的客戶群體或內部單位越廣，單一錯誤造成的衝擊也越大，風險越高。
• **救濟選項完整性**: 是否提供消費者清晰、有效的申訴、人工複核或補救管道。管道越不完整，消費者權益風險越高。`
      },
      {
        title: '第三方業者之監督管理',
        explanation: '金融機構將AI導入委外時，其最終責任仍在本機構。因此，必須對第三方業者進行嚴格的監督管理：\n• **盡職調查**: 評估業者的技術能力、資安水平、法遵紀錄與營運狀況。\n• **簽訂書面契約**: 明確雙方權責、資料所有權、保密義務、損害賠償及稽核權利。\n• **確保資料保護**: 要求業者遵循與金融機構同等的資料保護與安全標準。\n• **留存作業紀錄**: 要求業者提供完整的作業紀錄，以利後續追蹤、稽核與爭議處理。'
      }
    ],
    applications: [
      { scenario: '高風險AI系統：自動化核貸模型', description: '一個完全自動化的AI信貸審核系統，因其決策直接決定客戶能否獲得貸款（影響重大）、使用大量個人財務資料（個資程度高）、且由AI自主決策，將被評定為高風險系統。因此，需要採行最嚴格的治理、監控、公平性檢測及可解釋性要求。' },
      { scenario: '低風險AI系統：內部文件歸檔助手', description: '一個用於協助內部員工自動將公文分類歸檔的AI工具，因其不直接面對客戶、不涉及客戶個資、且最終歸檔結果仍由人工確認，風險性相對較低。因此，可採用較簡便的管理與監控措施。' }
    ],
    memoryAids: [
      {
        title: '風險評估六角戰士',
        explanation: '評估AI風險時，可從「**影響**、**個資**、**自主**、**複雜**、**廣度**、**救濟**」六個面向進行全面檢視，如同一個能力均衡的六角形戰士圖。'
      }
    ],
    summary: '總則為金融業的AI應用建立了共同語言和基礎框架。透過了解AI的定義、生命週期，並建立以風險為基礎的管理思維，金融機構才能在追求創新的同時，有效地控制潛在風險，為後續落實六大核心原則奠定基礎。'
  },
  L32102: {
    introduction: '金融監督管理委員會結合國際趨勢與台灣監理政策理念，提出金融業運用AI的六大核心原則。這六大原則是本指引的綱領，如同一座燈塔，旨在引導金融業在兼顧消費者權益、金融市場秩序及社會責任下，積極投入科技創新，促進金融服務升級，實現一個可信賴的AI未來。',
    keyConcepts: [
      {
        title: '原則一：建立治理及問責機制 (Governance & Accountability)',
        explanation: '**核心意涵**: AI不能在無人負責的真空中運行。金融機構應對其AI系統承擔最終責任，建立由上而下、權責分明的治理架構，並將AI風險納入全行的風險管理體系。'
      },
      {
        title: '原則二：重視公平性及以人為本的價值觀 (Fairness & Human-centricity)',
        explanation: '**核心意涵**: AI應服務於人，而非傷害人。應積極防範演算法偏見，避免對特定族群造成歧視（如數位紅線），確保AI的運作符合普惠金融與公平待客原則，並始終處於人類的有效監督與控制之下。'
      },
      {
        title: '原則三：保護隱私及客戶權益 (Privacy & Customer Rights)',
        explanation: '**核心意涵**: 信任是金融的基石。應在AI的全生命週期中，嚴格遵守個資法規，妥善保護客戶隱私，並尊重客戶對於是否使用AI服務的知情權與選擇權。'
      },
      {
        title: '原則四：確保系統穩健性與安全性 (Robustness & Security)',
        explanation: '**核心意涵**: 系統的可靠是底線。應確保AI系統能夠抵抗內外部的惡意攻擊（安全性），並在面對異常情況或壓力環境時，仍能穩定、可靠地運行（穩健性），以維護金融穩定。'
      },
      {
        title: '原則五：落實透明性與可解釋性 (Transparency & Explainability)',
        explanation: '**核心意涵**: AI不能是個無法理解的黑盒子。應適度地向客戶揭露AI的使用情況（透明性），並確保AI的決策邏輯能被內部人員和主管機關所理解與審計（可解釋性）。'
      },
      {
        title: '原則六：促進永續發展 (Sustainability)',
        explanation: '**核心意涵**: 追求創新應與社會責任並行。應考量AI發展對環境（如能源消耗）、社會（如數位落差）及員工（如工作權益）的影響，使其發展策略與ESG（環境、社會、治理）目標相結合。'
      }
    ],
    applications: [
      { scenario: 'AI核保系統的綜合考量', description: '一家保險公司在導入AI核保系統時，必須同時考量六大原則：(一)由風控委員會負責**治理**；(二)測試模型對不同地區、年齡的客戶是否存在**公平**性問題；(三)嚴格保護客戶的健康**隱私**；(四)確保系統能抵抗惡意騙保攻擊，並保持高**安全性**與**穩健**性；(五)向客戶**透明**告知AI參與核保，並能向內部解釋拒保的**可解釋**原因；(六)評估系統的長期能耗，並為核保人員提供轉型培訓，促進**永續**發展。' }
    ],
    memoryAids: [
      {
        title: '六大原則關鍵字',
        explanation: '1. **治理** (Governance): 高層要管，權責分明。\n2. **公平** (Fairness): 不偏心，不歧視。\n3. **隱私** (Privacy): 保護個資，尊重選擇。\n4. **安全** (Security): 系統要穩，不怕攻擊。\n5. **透明** (Transparency): 對外要說，對內要懂。\n6. **永續** (Sustainability): 關懷環境、社會、員工。'
      }
    ],
    summary: '六大核心原則構成了金融業導入AI的倫理羅盤和治理框架，從組織管理、客戶權益、系統穩定到社會責任，提供了一個全方位的指導。金融機構在規劃AI策略時，應將這六大原則內化為組織文化與作業流程，以實現可信賴的AI發展。'
  },
  L32201: {
    introduction: '本章闡述核心原則一，金融機構應對其使用的AI系統承擔相應的內、外部責任。內部責任涉及建立清晰的治理架構與權責單位；外部責任則涉及對消費者與社會的責任。目標是建立一個權責分明、可監督、可問責的管理體系，確保AI的發展與運用是在有效的治理框架下進行。',
    keyConcepts: [
      {
        title: '內部責任：治理架構 (三道防線模型)',
        explanation: '金融機構應將AI治理融入既有的「三道防線」風險管理架構中：\n• **第一道防線 (業務單位)**: 作為AI系統的所有者和使用者，對AI的日常運作、風險識別與控制負有首要責任。\n• **第二道防線 (風險管理、法遵、資安等獨立單位)**: 負責制定全行的AI風險管理政策與標準，並對第一道防線的AI應用進行獨立的監督與審查。\n• **第三道防線 (內部稽核)**: 負責對AI治理框架及風險管理措施的有效性，進行客觀、獨立的查核與確信。'
      },
      {
        title: '高階管理層與董事會的角色',
        explanation: '• **董事會**: 應將AI視為重大議題，負責核定整體AI發展策略與風險胃納，並對AI治理負有最終監督責任。\n• **高階主管/委員會**: 應由足以督導跨部門業務的高階主管或指定之委員會（如AI治理委員會、風險管理委員會），負責整體監督管理AI系統的運用，審議重大AI專案，並定期向董事會報告。'
      },
      {
        title: '外部責任：對外溝通與問責',
        explanation: '• **建立溝通管道**: 應建立有效的對外溝通管道（如客服專線、網站專區），讓外界（如消費者、主管機關）可查詢或申訴受AI決策影響的相關資訊。\n• **確保目的合規**: 確保AI系統的實際運用符合其規劃目的與相關法規，不偏離初衷，並能對其產生的外部影響承擔責任。'
      }
    ],
    applications: [
      { scenario: '設立AI治理委員會', description: '一家大型金控可以設立一個由副總經理級以上高階主管領導的「AI治理委員會」，成員橫跨法遵、風控、資訊、業務及客服等部門，負責審議全公司的AI發展策略、重大AI專案的倫理風險，並定期向董事會報告。' }
    ],
    memoryAids: [
      {
        title: '治理三要素',
        explanation: '1. **高層要管** (Board & Senior Management Supervision)\n2. **部門要分工** (Three Lines of Defense)\n3. **對外要溝通** (External Communication & Accountability)'
      }
    ],
    summary: '建立有效的治理與問責機制是落實負責任AI的基石。透過建立由上而下、權責分明的三道防線治理架構，並確保對外溝通的管道暢通，金融機構才能確保AI的發展方向與企業價值及社會期望保持一致，並在發生問題時能夠有效地追溯與問責。'
  },
  L32202: {
    introduction: '本單元接續核心原則一，探討如何將AI風險納入現有的風險管理機制，以及如何透過人員培訓來強化組織的AI治理能力。目標是建立一個動態、全面的AI風險管理流程，並確保組織內所有相關人員都具備足夠的知識與能力，能以風險為基礎做出適當的決策與監督。',
    keyConcepts: [
      {
        title: 'AI風險管理機制',
        explanation: '• **政策制定**: 應訂定明確的AI風險管理政策與指導方針，作為全行遵循的最高準則。\n• **整合至現有框架**: 將AI特有的風險（如模型風險、演算法偏見、數據隱私風險）整合至現有的企業整體風險管理(ERM)及內部控制架構中，進行統一的識別、評估、監控與報告。\n• **AI模型之風險管理 (Model Risk Management)**: \n  - **部署前**: 進行嚴格的概念驗證(PoC)，了解並記錄模型的目的、假設、限制、方法，並進行充分的壓力測試與偏見測試。\n  - **持續驗證**: 模型上線後，應持續監控其性能表現是否衰退（數據漂移）、決策邏輯是否穩定。\n  - **模型清單 (Model Inventory)**: 建立並維護一份全行統一的AI模型清單，如同資產負債表一樣，詳細記錄每個模型的版本、所有者、風險等級、輸入、輸出及預期用途，這是有效治理的基礎。'
      },
      {
        title: '人員培訓與資源',
        explanation: '• **提升人員能力 (AI Literacy)**: 應對不同層級、不同職能的相關人員提供客製化的培訓：\n  - **董事會與高階主管**: 需了解AI的策略意涵、重大風險與治理責任。\n  - **開發與測試人員**: 需接受AI倫理、安全開發、偏見緩解等技術培訓。\n  - **業務與風控人員**: 需學會如何解讀AI的輸出、評估其風險，並與AI進行有效協作。\n• **識別新角色與技能**: 應識別因導入AI而產生的新工作角色（如AI訓練師、提示工程師），評估所需的新技能，以便規劃招聘或內部培訓。\n• **建立溝通管道**: 建立與內外部利害關係人的溝通管道，將各界反饋意見納入AI生命週期的各階段評估中。'
      }
    ],
    applications: [
      { scenario: 'AI模型風險管理流程', description: '一家銀行在部署一個新的AI信評模型前，其風險管理部門會要求開發團隊提交一份詳盡的模型文件，說明其使用的數據、演算法及預期用途。模型上線後，風管部門會每季監控模型的表現是否衰退（如KS值下降），並要求團隊解釋原因及提出改善計畫。' },
      { scenario: 'AI教育訓練規劃', description: '一家保險公司為其董(理)事會及高階管理層，舉辦「AI在金融業的應用與風險」專題講座。對於第一線的核保與理賠人員，則開設「如何與AI協作」的實務工作坊，教導他們如何解讀AI的建議並做出最終判斷。' }
    ],
    memoryAids: [
      {
        title: '風險管理ABC',
        explanation: '• **A (Align)**: 將AI風險與現有風管框架對齊。\n• **B (Build)**: 建立模型管理流程與清單。\n• **C (Cultivate)**: 培養人員的AI知識與能力。'
      }
    ],
    summary: '有效的AI風險管理與持續的人員培訓，是確保AI治理能夠落地執行的兩大支柱。透過將AI風險制度化、流程化，並不斷提升組織整體的AI素養，金融機構才能建立起應對AI挑戰的韌性，做出兼顧創新與穩健的決策。'
  },
  L32301: {
    introduction: '本章闡述核心原則二，金融機構在使用AI系統時，應重視公平性，盡可能避免演算法的偏見所造成的不公平。由於AI系統是從歷史數據中學習，若數據本身存在偏見，AI便會複製甚至放大這些偏見，可能導致對特定弱勢族群的歧視，形成「數位紅線」(Digital Redlining)。本單元旨在建立對AI公平性的正確認知，並提供在AI生命週期各階段的具體落實方法。',
    keyConcepts: [
      {
        title: '公平性的主要概念',
        explanation: '• **決策的合理性**: 使用個人屬性（如年齡、性別、居住地）作為模型決策因素，必須有統計上或業務上站得住腳的合理理由，且不得違反相關法規（如性別工作平等法）。如無合理理由，則不應對特定群體產生系統性的不利差別待遇。\n• **決策的準確性與避免歧視**: 應定期審查及驗證AI模型與數據，不僅追求整體準確率，更要關注模型在不同子群體上的表現是否一致，以達到盡可能避免歧視的目標。'
      },
      {
        title: '公平性之落實方式 (依生命週期)',
        explanation: `• **系統規劃及設計階段**: \n  1. **確立目的與辨識受影響群體**: 確認AI系統目的，並主動辨識可能受到系統性不利差別待遇的群體（如高齡、偏鄉、特定性別等）。\n  2. **定義公平性指標**: 根據業務場景，選擇合適的量化公平性指標（如人口統計均等、機會均等）。\n  3. **提供救濟選項**: 應規劃受不利影響群體可申訴、要求人工複核的救濟選項。
• **資料蒐集及輸入階段**: \n  1. **檢視數據偏見**: 檢視數據來源及蒐集方式是否可能產生樣本偏見或歷史偏見。\n  2. **使用多元數據**: 盡量使用多元、具代表性的數據，並可採用過採樣(Oversampling)或欠採樣(Undersampling)等技術來平衡數據分佈。\n  3. **謹慎使用個人屬性**: 在決定採用某個人屬性前，應辨識其是否符合AI規劃目的，並評估其必要性與潛在的代理變數風險。
• **模型建立及驗證階段**: \n  1. **偏見測試**: 透過工具與技術，測試與驗證模型對不同群體的預測及決策，確認其運作的公平性。\n  2. **採用偏見緩解演算法**: 可採用處理中(in-processing)的演算法，在訓練時即加入公平性約束。\n  3. **留下紀錄**: 應將模型設計目的、運算邏輯、公平性測試結果等以簡單易懂的方式留下書面或數位紀錄。
• **系統部署及監控階段**: \n  1. **定期監控**: 定期監控與分析AI系統產出之結果是否存在歧視，或隨著時間推移產生新的偏見。\n  2. **採行降低影響之方式**: 辨識AI系統與受不利待遇的特定群體間是否存在關聯性，並採行後處理(post-processing)等方式來降低影響。`
      }
    ],
    applications: [
      { scenario: 'AI招聘系統的偏見風險', description: '一家公司使用AI篩選履歷，若其訓練數據來自於過去以男性為主的工程師履歷，模型可能會學到對女性工程師的偏見。為落實公平性，公司應在「資料蒐集」階段，確保訓練數據中不同性別的履歷具備代表性，或在「模型建立」階段，使用演算法技術來降低偏見影響。' }
    ],
    memoryAids: [
      {
        title: '公平性四階段檢核',
        explanation: '1. **規劃**：想清楚，別害到人，訂標準。\n2. **蒐集**：收資料，要多元、要平衡、要小心。\n3. **建立**：做模型，要測試、要修正、要記錄。\n4. **部署**：上線後，要常看、要調整。'
      }
    ],
    summary: '確保AI的公平性是金融業實踐普惠金融與公平待客原則的延伸。這需要金融機構在AI的整個生命週期中，從數據、演算法到監控，系統性地識別和緩解潛在的偏見風險，以建立一個無論背景、族群，都能被公平對待的AI服務環境。'
  },
  L32302: {
    introduction: '本單元接續核心原則二，探討AI系統的運用應符合「以人為本」及「人類可控」的原則。這意味著AI應作為增進人類福祉的工具，其運作應尊重人類的自主權與基本權利，並始終處於人類的監督與控制之下，具備可靠的「剎車」機制。同時，對於日益普及的生成式AI，其產出的資訊也需要建立相應的風險管控機制。',
    keyConcepts: [
      {
        title: '以人為本 (Human-centric)',
        explanation: 'AI系統在其全生命週期中，應以支持人類自主權、尊重人類基本權利及允許人類監督為原則，以落實人類價值，並達到改善人類福祉之目標。AI是工具，人是目的。'
      },
      {
        title: '人類在決策過程中的監督機制',
        explanation: '根據AI的自主程度與風險高低，應設計不同層級的人類監督機制：\n• **人在指揮 (Human-in-command, HIC)**: 人類負責設定AI的總體目標、策略與道德邊界，並對AI的整體活動進行監督。AI在執行層面可以有高度自主性，但最終責任由人類承擔。適用於複雜的長期策略規劃。\n• **人在迴圈內 (Human-in-the-loop, HITL)**: 人類主動參與決策迴圈的每一步。AI系統僅提供建議或資訊，每項關鍵決策都必須由人類審核並下達命令後，AI才能執行。適用於高風險、高影響的決策，如最終的核貸或拒保決定。\n• **人在迴圈上 (Human-over-the-loop, HOTL)**: AI在大部分時間自主運行，人類僅在高層次上監督系統。僅在AI模型遇到意外、超出其能力範圍或發出低信賴度警示時，才由人類接管控制或進行仲裁。適用於需要快速反應但風險可控的場景，如即時交易監控。'
      },
      {
        title: '以人為本及人類可控原則之落實方式',
        explanation: `• **事前評估**: 運用AI系統前，應先進行倫理與人權影響評估，辨識系統是否遵循法令，並判斷是否可能影響客戶自主權或基本人權。\n• **分級監督**: 應評估AI輔助決策所需的人類參與程度，根據決策的影響程度，採取不同級別的監督機制（如HIC, HITL, HOTL）。\n• **保留人工介入**: 針對重要的關鍵系統，應保留人員可參與審查、核准或最終決策的權利，並確保人員能隨時、安全地暫停或關閉AI系統。`
      },
      {
        title: '生成式AI產出資訊之風險管控',
        explanation: '金融機構導入生成式AI時，應同樣評估其是否對特定群體產生偏見或歧視。若使用第三方業者開發的生成式AI，仍需由金融機構人員就其產出資訊的風險（如事實錯誤、偏見內容），進行客觀且專業的管控與審核，以避免對客戶產生不公平之情況或造成聲譽損害。'
      }
    ],
    applications: [
      { scenario: 'AI理財顧問', description: '一個AI理財顧問系統應採用「人在迴圈內(HITL)」的模式。AI可以根據客戶的財務狀況和風險偏好，產生投資組合建議，但最終的投資決策必須由客戶本人或人類理財專員確認後才能執行。' },
      { scenario: '自動化交易系統', description: '一個高頻交易系統可能在大部分時間自主運行，但應設計「人在迴圈上(HOTL)」的機制。當市場出現極端異常波動或系統偵測到自身模型可能失效時，應能自動觸發警報，由人類交易員接管控制。' }
    ],
    memoryAids: [
      {
        title: '人類監督三種模式',
        explanation: '• **指揮 (HIC)**: 我是總司令，我設定戰略，你（AI）去執行。\n• **迴圈內 (HITL)**: 你是我的副駕，你提供導航建議，方向盤在我手上。\n• **迴圈上 (HOTL)**: 你在自動駕駛，我看著路況，有緊急情況我隨時踩剎車。'
      }
    ],
    summary: '落實以人為本與人類可控原則，是確保AI始終作為人類工具而非主宰的關鍵。金融機構應根據AI應用的風險與影響程度，設計適當的人類監督機制，保留人工介入的最終權利，並對生成式AI的產出進行嚴格的風險管控，以建立安全、可靠且值得信賴的人機協作環境。'
  },
  L32401: {
    introduction: '本章闡述核心原則三，金融機構應充分尊重及保護消費者的隱私，並妥善管理及運用客戶資料。在AI與大數據技術發展下，客戶的個人資訊常被大量蒐集以訓練模型，這可能對客戶隱私造成潛在威脅。本單元旨在強調在AI生命週期各階段中，落實隱私保護與資料治理的具體作法，確保資料使用合乎法規並贏得客戶信任。',
    keyConcepts: [
      {
        title: '核心概念：隱私保護設計 (Privacy by Design)',
        explanation: '應將隱私保護作為系統設計的預設核心要求，而非事後補救。這意味著在AI生命週期的每個階段，都要主動地、系統性地考慮和嵌入隱私保護措施。\n• **尊重客戶隱私**: 應妥善處理客戶資料，視同處理自身資產，避免資料外洩風險。\n• **資料最小化原則**: 僅蒐集與處理為達成特定、明確、合法業務目的直接相關且「必要」的客戶資料，避免蒐集過多不必要的敏感資訊。\n• **保護智慧財產權**: 運用AI時，除個人資料外，亦應注意保護營業秘密、模型參數等智慧財產權。'
      },
      {
        title: '隱私保護及資料治理之落實方式 (依生命週期)',
        explanation: `• **系統規劃及設計階段**: \n  1. **進行隱私衝擊評估(PIA)**: 評估AI系統設計是否符合個資法等規範及內部資料治理政策，識別潛在隱私風險。\n  2. **遵循資料最小化**: 依AI設計目的，評估所需蒐集資料的必要性，如公開資料已可滿足，則不需蒐集非公開資料。\n  3. **建立保護機制**: 建立保護個資免於未授權存取的技術與組織機制，如加密、存取控管、定期安全監控及員工保密訓練。
• **資料蒐集及輸入階段**: \n  1. **確保合法性與告知同意**: 記錄資料蒐集來源，確保已依個資法取得客戶的明確同意或符合其他法定要件。\n  2. **採用隱私增強技術(PETs)**: 如資料包含個資，應評估是否需進行額外的隱私保護處理，如假名化(Pseudonymization)、匿名化(Anonymization)或差分隱私(Differential Privacy)等技術。\n  3. **驗證資料品質**: 驗證資料的準確性與完整性，避免因錯誤資料損害客戶權益。
• **模型建立及驗證階段**: \n  1. **確保合法合規**: 確保用以訓練AI模型的資訊及AI系統產生的資訊，不違反個資法等規範。\n  2. **確保合作夥伴合規**: 確保合作夥伴及供應商亦符合隱私權規範及安全標準，並簽訂資料處理附錄(DPA)。
• **系統部署及監控階段**: \n  1. **定期監控與稽核**: 定期監控AI系統、合作夥伴及供應商是否持續遵守隱私權規範及安全標準。\n  2. **建立應變計畫**: 當發生資料外洩或違反個資法情事時，應有明確的應變流程，循現行機制通報主管機關及受影響客戶。`
      }
    ],
    applications: [
      { scenario: 'AI精準行銷', description: '一家銀行希望利用AI分析客戶交易數據，以推薦最適合的信用卡。在「資料蒐集」階段，銀行應確實告知客戶資料將被用於行銷分析，並取得其同意。在「設計」階段，應採用「資料最小化原則」，僅使用與消費偏好相關的數據（如消費類別、金額），而非撈取所有客戶資料（如詳細交易明細）。' },
      { scenario: '聯邦學習 (Federated Learning)', description: '多家金融機構希望聯合訓練一個反詐欺模型，但又不希望分享各自的客戶交易資料。她們可以採用聯邦學習技術，讓模型在各機構的本地伺服器上進行訓練，只將加密後的模型更新參數傳回中央伺服器進行聚合，如此原始資料不出機構，即可達到保護隱私的目的。' }
    ],
    memoryAids: [
      {
        title: '隱私保護四字訣',
        explanation: '• **知 (Inform)**: 告知客戶，取得同意。\n• **少 (Minimize)**: 只收必要的，不多拿。\n• **保 (Protect)**: 加密加鎖，嚴格控管。\n• **查 (Audit)**: 持續監控，定期檢查。'
      }
    ],
    summary: '隱私保護與資料治理是贏得客戶信任的基石。金融機構在享受AI帶來效益的同時，必須將保護客戶隱私內化為AI開發與應用的最高準則，在AI生命週期的每個環節都採取具體的保護措施，並確保整個流程的合法合規。'
  },
  L32402: {
    introduction: '本單元接續核心原則三，探討金融機構在使用AI系統向客戶提供服務時，應尊重客戶的選擇權，並在適當情況下提供替代方案。這不僅是保障消費者權益的體現，也是在數位轉型過程中，維持服務溫度與包容性的關鍵。目標是確保客戶在與AI互動時擁有充分的知情權和選擇權，以維護其權益。',
    keyConcepts: [
      {
        title: '尊重客戶選擇權的核心事項',
        explanation: '• **告知義務**: 應在互動的適當時機，以清晰易懂的方式，主動告知金融消費者，該金融服務係由AI系統所提供或輔助。\n• **資訊透明**: 應提供必要資訊以便消費者瞭解，在正常使用過程中，AI系統的功能為何，以及由AI協助做出的決策可能會如何影響他們。\n• **提醒替代方案**: 應提醒金融消費者是否存在AI系統以外之替代方案（如人工服務），以讓其自行決定是否選擇使用AI系統所提供之服務。'
      },
      {
        title: '提供替代方案的考量因素',
        explanation: `金融機構是否必須提供替代方案，應進行綜合權衡。可參考下列因素，決定於客戶退出使用AI服務時，是否同步提供替代方案：
1. **對客戶之風險及危害程度**: 若AI決策對客戶有重大負面影響（如拒貸），則提供替代方案（如人工複審）的必要性就越高。
2. **替代方案之可行性及成本**: 提供人工服務的成本是否過高，是否具備技術可行性。
3. **技術可行性與複雜性**: 同時維運AI與人工兩種方案的複雜度與效率。
若權衡上述因素後決定不提供替代方案，宜進一步評估是否為客戶提供其他補救措施（如清晰的申訴管道）。`
      },
      {
        title: '對生成式AI的特別考量',
        explanation: '金融機構應注意運用生成式AI可能導致的客戶資料外洩風險。在無適當管控機制（如採用封閉型部署之模型、確認系統環境安全性、對輸入資料進行去識別化處理等）下，金融機構人員不得向生成式AI提供未經客戶同意提供之資訊。'
      }
    ],
    applications: [
      { scenario: '智能客服與人工客服', description: '一家銀行導入智能客服機器人來處理常見問題。在對話開始時，應明確告知用戶「您正在與AI客服機器人對話」。同時，應提供一個清晰的選項，例如輸入「轉接專員」，讓用戶可以在任何時候選擇退出AI服務，與人工客服對話。這就是提供了明確的替代方案。' },
      { scenario: 'AI核貸系統', description: '一家線上貸款公司主要以AI系統進行快速核貸。他們應在服務條款中清楚說明決策過程有AI參與。對於被AI拒絕的客戶，應提供清晰的申訴管道，由人工進行案件複審，這就是一種補救措施，保障了客戶的權益。' }
    ],
    memoryAids: [
      {
        title: '客戶選擇權三部曲',
        explanation: '1. **告知 (Inform)**: 明白告訴客戶這是AI。\n2. **解釋 (Explain)**: 說明AI會做什麼、有何影響。\n3. **給選擇 (Give Choice)**: 提醒客戶有別的選項（人工服務）。'
      }
    ],
    summary: '尊重客戶的選擇權是公平待客原則在AI時代的具體體現。透過主動告知、資訊透明化以及在合理範圍內提供替代方案，金融機構不僅能保障消費者權益，更能建立與客戶之間基於信任的長期關係。'
  },
  L32501: {
    introduction: '本章闡述核心原則四，金融機構在運用AI系統時，必須確保其系統的穩健性(robustness)與安全性。系統的穩健性是指AI系統具有預防風險發生的方法，能可靠地按照預設目的執行，並將非預期或意外的不利影響降至最低。這如同汽車的車體結構與懸吊系統，是確保行車安全的基礎。本單元將聚焦於系統穩健性的主要概念與落實方式。',
    keyConcepts: [
      {
        title: '系統穩健性的主要概念',
        explanation: '• **穩定性 (Stability)**: 指AI系統在執行過程中及面對錯誤、異常或惡意輸入時，具有良好的應對與容錯能力，不會輕易崩潰或產生不可預測的結果。\n• **準確性 (Accuracy)**: 指系統有能力做出正確判斷以達成其規劃目的。這不僅是追求高準確率，更包含對不同類型錯誤（如偽陽性、偽陰性）的控制。\n• **可重製性 (Reproducibility)**: 指在相同的條件（數據、程式碼、環境）下重複AI系統之測試或推論，仍會得到相近的產出。這是科學驗證與系統除錯的基礎。\n• **韌性 (Resilience)**: 指系統在面對未在預期內的資料輸入或環境變化（如市場劇烈波動）時，仍能維持其功能，或能優雅地降級，而非災難性地失效。'
      },
      {
        title: '系統穩健性之落實方式 (依生命週期)',
        explanation: `• **系統規劃及設計階段**: \n  1. **定義指標與門檻**: 明確定義用以衡量系統穩健性的技術指標（如準確率、延遲、容錯率）及其應達到的驗收標準。\n  2. **規劃風險抵減**: 針對AI系統可能失效的情境進行風險評估，並規劃備援機制、人工介入流程等風險抵減作法。
• **資料蒐集及輸入階段**: \n  1. **資料治理**: 高品質、具代表性的資料是確保模型穩健的根本。應建立嚴謹的資料治理流程，確保資料品質。
• **模型建立及驗證階段**: \n  1. **選擇具韌性模型**: 選擇較具備韌性之模型，並透過正規化、數據增強等技術提升其泛化能力。\n  2. **交互驗證與調校**: 透過K-摺交互驗證等技術，得到更穩定的模型性能評估，避免因偶然的數據劃分而高估模型表現。\n  3. **對抗性測試**: 主動使用經過設計的、可能欺騙模型的「對抗性樣本」來測試模型，以評估並提升其面對惡意攻擊時的韌性。\n  4. **壓力測試**: 在模擬的極端市場條件或高併發請求下測試AI系統，確保其表現依然穩健。
• **系統部署及監控階段**: \n  1. **灰度發布/A-B測試**: 採用逐步上線的方式，先讓小部分流量使用新模型，觀察其穩定性，再逐步擴大範圍。\n  2. **建立監控機制**: 持續監控模型的預測準確率、預測結果分佈是否發生偏移（數據漂移），並於準確性下降或出現問題時，即時進行處理或觸發再訓練流程。`
      }
    ],
    applications: [
      { scenario: '股票交易AI的壓力測試', description: '一家證券公司在正式上線一個AI交易決策系統前，會先在模擬環境中進行壓力測試。他們會輸入歷史上發生股災時（如2008年金融海嘯、2020年COVID-19初期）的市場數據，來評估該AI系統在極端市場壓力下的決策是否依然穩健，避免產生災難性的虧損。' }
    ],
    memoryAids: [
      {
        title: '穩健性三支柱',
        explanation: '• **穩 (Stable)**: 遇到怪招（錯誤輸入）不會倒。\n• **準 (Accurate)**: 判斷事情要準確。\n• **同 (Reproducible)**: 同樣情況，結果要相同。'
      }
    ],
    summary: '系統穩健性是確保AI系統長期可靠運行的基礎。金融機構必須在AI的整個生命週期中，從數據品質、模型選擇、壓力測試到上線監控，全方位地建構與驗證系統的穩定性、準確性與可重製性，才能將非預期的風險降至最低，保護客戶與自身的利益。'
  },
  L32502: {
    introduction: '本單元接續核心原則四，探討系統安全性的議題。安全性高的AI系統，係指具有較強抵禦外部安全威脅、攻擊或惡意濫用之資安防護能力。這如同為汽車安裝堅固的門鎖與警報系統。金融機構應遵循相關資安規範，將AI安全納入整體資安防護體系，建立適當的防護與管控措施，確保AI系統的整體安全。',
    keyConcepts: [
      {
        title: 'AI特有的資安威脅',
        explanation: '除了傳統的網路攻擊，AI系統還面臨一些特殊的威脅：\n• **資料中毒 (Data Poisoning)**: 攻擊者在訓練階段，故意向訓練數據中注入精心設計的惡意樣本，以污染模型，使其產生錯誤的預測或植入一個只有特定觸發器才能激活的「後門」。\n• **模型規避/對抗性攻擊 (Evasion / Adversarial Attacks)**: 攻擊者在推論階段，對輸入數據進行微小的、人眼難以察覺的修改，以欺騙已部署的模型做出錯誤的判斷。\n• **模型竊取 (Model Stealing)**: 攻擊者透過大量查詢模型的API，逆向工程出模型的內部參數或功能，竊取機構的智慧財產。\n• **提示注入 (Prompt Injection)**: 針對生成式AI，攻擊者透過惡意設計的提示，來操縱或欺騙模型，使其繞過安全限制。'
      },
      {
        title: '系統安全性之落實方式 (依生命週期)',
        explanation: `• **系統規劃及設計階段**: \n  1. **威脅建模 (Threat Modeling)**: 辨識AI系統在各個環節可能面臨的潛在威脅，並將安全性需求納入設計規格中。\n  2. **提升人員資安意識**: 對開發及維運人員進行AI安全相關的教育訓練。
• **資料蒐集及輸入階段**: \n  - **強化資料安全控管**: 透過加密、存取控制等方式，保護訓練資料在儲存與傳輸過程中的安全，防止被竊取或竄改。
• **模型建立及驗證階段**: \n  1. **評估廠商與開源工具安全性**: 評估或定期檢視AI相關廠商或使用的開源函式庫是否存在安全漏洞。\n  2. **保護AI相關資產**: 辨識、追蹤及保護AI相關資產（如模型權重、訓練資料、關鍵提示），並進行嚴格的存取控制。\n  3. **留下紀錄**: 針對模型、資料及提示留下相關書面或數位紀錄，以利安全事件的追溯。
• **系統部署及監控階段**: \n  1. **保護基礎設施**: 對API、模型及資料之使用進行適當控管（如認證、授權、速率限制），積極防範惡意攻擊。\n  2. **部署前安全評估**: AI模型部署前先進行滲透測試、弱點掃描等安全評估。\n  3. **持續監控**: 監控模型的輸入與輸出，以觀察是否有可疑的攻擊模式（如大量相似的查詢），並建立應變計畫。`
      }
    ],
    applications: [
      { scenario: '防止模型被竊取', description: '一家開發了專有AI信評模型的金融科技公司，在將模型部署為API服務時，會採取多重安全措施，例如設置嚴格的API金鑰認證、限制請求速率、監控異常的API調用模式，以防止惡意使用者透過大量查詢來逆向工程或竊取其核心模型。' },
      { scenario: '保護訓練數據安全', description: '在訓練AI模型的過程中，為避免因第三方工具或人員疏失導致模型參數或客戶資料外洩，金融機構應採取嚴格的管控措施。例如，在一個安全的、與外網隔離的環境中進行模型訓練，並對所有參與人員進行嚴格的權限控管與背景審查。' }
    ],
    memoryAids: [
      {
        title: 'AI安全防護罩',
        explanation: '• **事前預防**: 威脅建模，提升意識。\n• **資料加密**: 數據要上鎖。\n• **資產盤點**: 家當（模型、資料）要數好，嚴格控管。\n• **部署監控**: 上線後要時時看守，偵測異常。'
      }
    ],
    summary: '系統安全性是AI系統的防護罩。面對日益增加的網路威脅，特別是針對AI的新型攻擊，金融機構必須在AI生命週期的各個環節，從員工意識、資料控管、廠商管理到部署監控，建立起一個縱深防禦的資安體系，以保護珍貴的數據與模型資產，確保AI系統的安全運行。'
  },
  L32601: {
    introduction: '本章闡述核心原則五，金融機構在運用AI系統時，應確保其運作的透明性，並在與消費者直接互動時進行適當揭露。透明性旨在提供外部利害關係人（如客戶、主管機關、社會大眾）關於AI系統的相關資訊，使其了解系統對其權益的影響、限制與風險，以提升民眾的信任度，是化解AI「黑盒子」疑慮的第一步。',
    keyConcepts: [
      {
        title: '透明性的主要概念',
        explanation: '係指提供外部利害關係人(stakeholder)有關AI系統之相關資訊，讓他們能夠理解AI系統的存在、目的、基本運作邏輯，以及該系統對其權益的潛在影響、限制與風險。其核心是「告知」與「揭露」。'
      },
      {
        title: '透明性共通原則之訂定',
        explanation: '金融機構宜就評估AI系統所需之適當透明性訂定共通性原則，並根據不同應用場景與對象，決定透明的程度、時機及形式。例如：\n• **對象區隔**: 對一般客戶的揭露應淺白易懂；對主管機關的揭露則需更詳盡的技術與風險說明。\n• **通知樣版**: 應事先備妥在客戶往來生命週期各階段中，可能需對客戶通知之項目樣版（如服務條款更新、AI決策通知）。'
      },
      {
        title: '透明性之落實方式 (依生命週期)',
        explanation: `• **系統規劃及設計階段**: \n  - **決定透明性程度**: 根據風險評估結果，決定AI系統的透明性程度，並確認在客戶生命週期各階段所需的主、被動通知項目及其形式。\n  - **規劃淺白揭露**: 規劃與金融消費者互動時，如何以淺白、非技術性的用語適當揭露相關資訊，例如：讓消費者知悉其正考慮的金融商品或服務係由AI提供或輔助。
• **模型建立及驗證階段**: \n  - **測試與驗證**: 測試與驗證相應的透明性功能（如UI上的提示訊息）。\n  - **調整作業流程**: 規劃如何適當調整作業流程（如客服及客訴處理），以因應客戶在接收透明資訊後可能提出的疑問。\n  - **更新服務條款**: 規劃如何適當揭露並更新客戶或網站之約定服務條款，例如向客戶說明AI系統如何使用客戶資料、客戶可能會有之利益與風險等。
• **系統部署及監控階段**: \n  - **主動告知**: 與消費者直接互動前，宜主動告知該互動或服務係利用AI系統自動完成。\n  - **定期監控**: 定期監控AI系統透明性達成情形，並根據客戶反饋或法規變化進行調整。`
      }
    ],
    applications: [
      { scenario: 'AI理財顧問服務', description: '一家銀行推出AI理財顧問服務。在其服務介紹頁面及使用者條款中，應以顯著、清晰的方式告知客戶，其投資組合建議是由AI演算法生成。在客戶註冊使用前，應說明AI會如何使用客戶的財務數據，並揭露演算法可能存在的限制與風險。' },
      { scenario: '智能客服機器人', description: '當客戶進入銀行的線上客服時，對話視窗應首先顯示一則訊息，如：「您好！我是智能客服小助手，將由我為您服務。若需轉接專人，請隨時輸入『轉接專員』」。這就是主動告知與揭露，落實了透明性原則。' }
    ],
    memoryAids: [
      {
        title: '透明三要素',
        explanation: '1. **主動說**: 主動告訴客戶這是AI。\n2. **說清楚**: 用簡單的話說明白AI會做什麼。\n3. **留條款**: 在服務條款裡詳細寫明權利義務。'
      }
    ],
    summary: '透明性是建立信任的基礎。金融機構透過在AI應用的各個環節，特別是與客戶的接觸點上，主動、清晰地揭露相關資訊，不僅能保障客戶的知情權，更能化解其對新技術的疑慮，從而提升對金融機構AI服務的接受度與信任感。'
  },
  L32602: {
    introduction: '本單元接續核心原則五，探討可解釋性(explainability)的議題。若透明性是讓外界「知道」AI的存在，可解釋性則是讓相關人員能「理解」AI決策的「原因」。其主要對象為組織內部人員（如業務、風控、稽核）及主管機關，旨在確保AI系統的決策是可理解、可審計、可管理的，是打開AI「黑盒子」的關鍵。',
    keyConcepts: [
      {
        title: '可解釋性共通原則之訂定',
        explanation: '金融機構宜就評估AI系統可解釋性訂定共通性原則，並依據風險為本原則，決定所需的可解釋性程度。\n• **評估可解釋性程度**: AI決策對客戶影響越大、風險越高的系統，所需的可解釋性程度也越高。\n• **選定解釋方法**: 根據模型類型與業務需求，選定適合的解釋方法（如特徵重要性、SHAP、LIME等），並明定其基本要求。'
      },
      {
        title: '可解釋性之落實方式 (依生命週期)',
        explanation: `• **系統規劃及設計階段**: \n  - **決定可解釋性程度**: 決定所需之可解釋性程度及相關資訊提供對象。\n  - **模型選擇**: 在準確率相近的情況下，優先選擇本身可解釋性較高的「白箱模型」（如線性迴歸、決策樹）。若必須使用「黑箱模型」（如深度學習），則應同步規劃相應的XAI（可解釋AI）工具。\n  - **規劃文件與權限**: 規劃備置AI系統架構之相關文件或技術報告，並規劃提供監理機關存取及了解AI系統運作之權限。
• **資料蒐集及輸入階段**: \n  - **記錄資料履歷**: 確保以書面化或以數位方式記錄訓練AI系統之資料等相關資訊（如資料來源、時間點、處理方式），以利決策溯源。
• **模型建立及驗證階段**: \n  - **產出可解釋性報告**: 產出可解釋性報告，說明模型的重要特徵、決策邏輯等。\n  - **審查確認**: 審查及確認相關可解釋性之說明是否妥適，並驗證其人員是否知悉AI系統之架構、演算法及其所使用之功能及決策因素。\n  - **確保與重要性相稱**: 確認可解釋性之程度與其AI系統應用之重要性相稱。
• **系統部署及監控階段**: \n  - **定期監控**: 定期監控AI系統可解釋性達成情形，並確保在模型更新後，其解釋依然有效。`
      }
    ],
    applications: [
      { scenario: 'AI信貸審核系統', description: '當AI系統拒絕一筆貸款申請時，它不能只給出「拒絕」的結果。一個具備可解釋性的系統，應能同時輸出一份報告，向內部的審核人員指出導致拒絕的主要原因，例如：「申請人的負債比過高」、「近期信用卡循環利息過高」等。這使得人類可以審核、理解並為AI的決策負責。' },
      { scenario: '稽核部門審查AI模型', description: '銀行的內部稽核部門在審查一個用於交易監測的AI模型時，會要求開發團隊提供完整的模型文件，包括其設計目的、使用的特徵、演算法，以及一份可解釋性報告。稽核人員需要確保模型的決策邏輯符合銀行內部的風控政策與外部監理規範。' }
    ],
    memoryAids: [
      {
        title: '解釋三問',
        explanation: '1. **對誰解釋？** (內部人員、主管機關)\n2. **解釋到多深？** (依風險程度決定)\n3. **怎麼解釋？** (選擇白箱模型或XAI工具)'
      }
    ],
    summary: '可解釋性是AI系統得以被有效管理和監督的前提。金融機構必須確保其AI系統的決策過程不是一個無法檢視的「黑盒子」，而是能夠被內部相關人員清晰理解、審查和驗證的。這不僅是為了符合監理要求，更是有效進行模型風險管理、持續優化模型的基礎。'
  },
  L32701: {
    introduction: '本章闡述核心原則六，金融機構在運用AI系統時，應確保其發展策略及執行與永續發展之原則相結合，包括減少經濟、社會等不平等現象，保護自然環境，從而促進包容性成長及社會福祉。AI的運作可能消耗大量能源，並可能加劇數位落差，因此金融機構應重視其ESG（環境、社會、治理）責任。',
    keyConcepts: [
      {
        title: '主要概念',
        explanation: '• **兼顧利害關係人**: 運用AI時，宜將社會、環境等視為利害關係人，在追求商業利益的同時，兼顧社會公平及生態責任。\n• **結合永續發展目標(SDGs)**: AI系統的策略與執行方向，宜依據聯合國永續發展目標及自訂之永續發展原則，並適當列入永續發展綜合指標，將AI作為實踐ESG的工具。'
      },
      {
        title: '永續發展之落實方式',
        explanation: `• **辨識產生之影響**: 建立機制辨識與評估AI系統對環境（如碳足跡）、社會（如就業、歧視）產生之正面與負面影響或風險。\n• **環境面向 (E) - 綠色AI (Green AI)**:\n  - **優化硬體設施**: 選擇能效較高之硬體設備（如節能伺服器、低功耗處理器），並優化機房散熱與管理，以提高能源利用效率。\n  - **共享資源及虛擬化**: 透過虛擬化技術及資源共享方式，將運算資源及資料倉儲集中管理，減少重複之硬體設置，從而節省能源消耗。\n  - **改進模型與演算法**: 在滿足需求下，優先採用更輕量、更高效的演算法，減少模型之複雜度與計算需求，從而提高運算效率及資源利用率。\n  - **預先處理資料**: 預先處理數據，以減少不必要的數據傳輸，並可透過提升資料品質，減少為提升準確率而重複運算所消耗之能源。\n  - **智慧控管能效**: 借重能源效能監控系統，實時監測AI系統之能源消耗與效能表現。\n• **社會面向 (S) - 包容性AI (Inclusive AI)**:\n  - **促進普惠金融**: 利用AI分析替代數據，為信用紀錄不足的弱勢族群提供金融服務。\n  - **縮小數位落差**: 規劃友善的數位介面，並為數位弱勢族群提供額外支持。`
      }
    ],
    applications: [
      { scenario: '綠色AI機房', description: '一家金融機構在建置其AI運算中心時，優先採購具有最新節能認證的伺服器，並導入智慧散熱與能源管理系統，以最小化訓練和運行AI模型所需的電力消耗，減少其碳足跡。' },
      { scenario: '普惠金融AI應用', description: '一家銀行利用AI技術分析傳統金融數據以外的替代數據（如公用事業繳費紀錄），為那些過去因缺乏信用紀錄而無法獲得銀行服務的偏鄉居民或微型企業，提供小額貸款服務。這便是利用AI促進普惠金融，減少經濟不平等的例子。' }
    ],
    memoryAids: [
      {
        title: '永續AI三面向',
        explanation: '• **環境 (E)**: 省電、節能、高效運算。\n• **社會 (S)**: 普惠金融、縮小數位落差。\n• **治理 (G)**: 評估AI對社會環境的衝擊，並納入決策。'
      }
    ],
    summary: '將永續發展理念融入AI策略，是金融業實踐企業社會責任的具體展現。透過系統性地評估AI對環境與社會的影響，並在硬體、軟體及應用層面採取節能與包容性的措施，金融機構可以確保其AI創新在創造商業價值的同時，也為社會的永續穩定發展做出貢獻。'
  },
  L32702: {
    introduction: '本單元接續核心原則六，探討在AI帶來的數位轉型過程中，金融機構應尊重並保護一般受僱員工的工作權益，並透過適當的教育與培訓，促進員工能適應AI帶來的變革。目標是在追求營運效率的同時，兼顧對員工的關懷，實現和諧的人機協作未來，達成永續經營的目標。',
    keyConcepts: [
      {
        title: '核心原則：維護員工工作權益',
        explanation: '金融機構在AI系統運用過程中，宜對一般員工提供適當之教育及培訓，促進員工能適應AI帶來之變革，並盡可能維護其工作權益。AI應是增強員工能力的工具，而非僅是取代員工的手段。'
      },
      {
        title: '降低數位焦慮與落差',
        explanation: '金融機構可依據金融消費者屬性，提供符合其需求之服務，以降低可能之數位焦慮或落差。例如提供金融消費者選擇面對面服務之機會，以減少客戶對AI系統之焦慮；或提供數位體驗活動，提升數位運用上較為弱勢族群採用數位服務之誘因。'
      },
      {
        title: '員工教育及培訓相關事項',
        explanation: '• **尊重與保護工作權益**: 金融機構必須尊重並保護一般受僱員工的工作權益，包括在數位轉型過程中，主動溝通、提供適當的教育及培訓以助其適應新的工作環境、減少失業風險。\n• **技能再培育 (Reskilling) 與技能提升 (Upskilling)**: 應分析AI導入後，現有職位所需的技能變化，並規劃相應的培訓計畫。例如，將重複性工作被取代的員工，培訓為能與AI協作、處理更複雜問題的專家，或轉型為「AI訓練師」。\n• **建立專案小組**: 視需要建立專案小組，負責監控AI系統對員工工作的影響及員工適應情況，並根據實際需求調整教育及培訓計畫。\n• **提升永續意識**: 亦可提高員工對節約能源、減少資源過度使用及照顧數位弱勢之意識，並提供相應之培訓及指導。'
      }
    ],
    applications: [
      { scenario: 'AI導入後的客服人員轉型', description: '一家銀行導入AI客服機器人來處理大量重複性查詢後，並未裁撤客服人員。而是規劃了轉型培訓計畫，將原有的人力客服，培訓為能夠處理更複雜客戶問題、更具同理心的「客戶關懷專員」，或轉型為負責維護和優化AI機器人知識庫的「AI訓練師」，實現了員工價值的提升。' },
      { scenario: '友善高齡者的金融服務', description: '為避免數位落差，一家銀行在推行其新的AI理財APP時，特別在分行舉辦了針對高齡客戶的「智慧手機理財教學班」，並保留了傳統的電話理財專員和臨櫃服務，讓不熟悉數位工具的客戶也能享受到金融服務。' }
    ],
    memoryAids: [
      {
        title: '員工轉型雙引擎',
        explanation: '• **賦能 (Enable)**: 透過教育訓練，賦予員工與AI協作的新技能（技能再培育、技能提升）。\n• **關懷 (Embrace)**: 關懷員工在轉型中的焦慮，主動溝通，提供多元選擇與支持。'
      }
    ],
    summary: 'AI的導入不應以犧牲員工權益為代價。成功的數位轉型，是技術創新與人文關懷並行的過程。金融機構透過為員工提供必要的轉型培訓，並為客戶提供多元包容的服務管道，不僅能維護員工的工作權益、縮小數位落差，更能建立一個更具韌性與向心力的組織，迎接AI時代的挑戰。'
  }
};
