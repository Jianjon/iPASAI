import type { LearningContent } from '../../types';

export const L34_CONTENT: Record<string, LearningContent> = {
  L34101: {
    introduction: '歐盟《人工智慧法案》（EU AI Act）是全球首個針對AI技術的全面性、橫向的法律監管框架。其目標是在促進AI技術創新與投資的同時，確保在歐盟境內開發和使用的AI系統是安全的，並尊重現有的基本權利與價值觀。本單元將深入探討此法案的第一、二章，涵蓋其總體目標、適用範圍，以及被完全禁止的「不可接受風險」AI實踐，這些構成了法案的倫理基石。',
    keyConcepts: [
      {
        title: '總則 (Chapter I): 目標、範圍與定義',
        explanation: `• **目標**: 確保AI系統的安全與合規，保護民眾的基本權利（如隱私、非歧視），同時為AI的發展建立統一、明確的法律框架，增強市場信任，促進技術投資。\n• **境外效力 (Extraterritorial effect)**: 這是AI法案最關鍵的特點之一。不論AI系統的提供者或使用者位於何處，只要該AI系統的「輸出結果」在歐盟境內被使用，就可能受到本法案的管轄。這意味著，即便是臺灣的公司，若其AI產品或服務提供給歐盟市場，就必須遵守相關規範。\n• **AI系統的定義**: 法案採用了基於OECD的、廣泛且具未來性的定義：AI系統是一種基於機器的系統，其設計旨在實現不同程度的自主性，並且能夠為明確或隱含的目標，從接收的輸入中推斷如何生成輸出，如預測、內容、建議或決策，從而影響物理或虛擬環境。這個定義強調了AI的「自主性」和「影響環境」的能力。`
      },
      {
        title: '禁止的AI實踐 (Chapter II): 不可接受風險',
        explanation: `法案明確劃出了四條不可逾越的「紅線」，這些對人類安全和基本權利構成明顯威脅的AI應用，將被【完全禁止】在歐盟市場上使用。
1.  **潛意識操縱技術**: 禁止使用旨在扭曲個人行為的潛意識技術，或利用特定技術，對個人或群體產生重大影響，從而可能導致身心傷害的AI系統。
2.  **利用弱勢群體**: 禁止利用任何因年齡、身心障礙或特定社會經濟狀況而處於弱勢的群體，部署旨在扭曲其行為並可能對其或他人造成身心傷害的AI系統。
3.  **通用型社會信用評分**: 禁止由公共主管機關出於通用目的，對自然人進行社會信用評分，導致對某些群體產生不利或不相稱的後果。
4.  **執法領域的敏感應用**:
    • **無差別抓取臉部影像**: 禁止為了創建或擴展臉部辨識資料庫而無差別地從網際網路或閉路電視畫面中抓取臉部影像。
    • **工作場所與教育機構的情緒識別**: 禁止使用情緒識別系統來推斷個人情緒。
    • **執法中的遠程即時生物辨識**: 原則上禁止執法單位在公共場所進行無差別的即時人臉辨識。僅在尋找特定犯罪受害者、預防真實且迫在眉睫的恐怖攻擊、或追捕嚴重刑事犯罪嫌疑人等極少數、經嚴格司法授權的情況下，才被允許作為例外。`
      }
    ],
    applications: [
      { scenario: '玩具公司的潛在風險', description: '一家玩具公司開發了一款內建AI語音的玩偶，該AI會利用兒童天真的心態，誘導他們購買更多周邊產品。這種作法可能被視為「利用弱勢群體（兒童）的脆弱性」，屬於被禁止的AI實踐。' },
      { scenario: '執法單位的疑慮', description: '某國執法單位希望在大型車站部署即時人臉辨識系統，以隨機抓捕通緝犯。根據AI法案，這種無差別、無特定目標的即時監控，將屬於被禁止的範疇。' }
    ],
    memoryAids: [
      {
        title: 'AI法案的四條紅線',
        explanation: '1. **不操縱** (No Manipulation)\n2. **不利用** (No Exploitation)\n3. **不評分** (No Social Scoring)\n4. **不濫用生物辨識** (No Biometric Misuse)'
      }
    ],
    summary: '歐盟AI法案的第一、二章為整個監管框架奠定了基礎，它不僅定義了遊戲規則，更重要的是劃出了不可逾越的倫理紅線。理解這些被完全禁止的實踐，是所有AI開發者與提供者進入歐盟市場前，必須完成的第一課。'
  },
  L34102: {
    introduction: '在歐盟AI法案的風險金字塔中，「高風險AI系統」是監管的核心與重點。這些系統雖然不被禁止，但因其可能對個人健康、安全或基本權利產生重大不利影響，必須在上市前與上市後，遵守一系列嚴格的義務。本單元將深入解析法案第三章的內容，聚焦於高風險系統的分類規則，以及其必須履行的七大核心義務中的前半部分。',
    keyConcepts: [
      {
        title: '高風險系統的分類規則',
        explanation: `一個AI系統會被歸類為高風險，主要有兩種途徑：
1.  **作為受規管產品的安全組件**: 如果AI系統本身是一個產品，或是一個產品的安全組件，且該產品受到歐盟現有的特定安全法規（如醫療器材法規、機械指令、玩具安全指令）的規範，那麼該AI系統就自動被視為高風險。
2.  **被列於法案附件三 (Annex III)**: 法案附件三明確列出了一系列特定領域和用途，在這些場景下使用的AI系統將被「推定」為高風險。主要涵蓋八大類別：
    • **生物辨識與身份識別**: 如遠程生物辨識系統。
    • **關鍵基礎設施的管理與營運**: 如水、電、交通網路的管理系統。
    • **教育與職業培訓**: 如用於評估考試成績、決定錄取與否的系統。
    • **就業、勞工管理與自僱機會**: 如用於篩選履歷、評估績效的系統。
    • **關鍵私人與公共服務的取用**: 如用於信貸評分、決定社會福利資格的系統。
    • **執法**: 如用於評估犯罪風險、證據可靠性的系統。
    • **移民、庇護與邊境管理**: 如用於審查簽證申請的系統。
    • **司法與民主程序**: 如用於輔助司法判決的系統。`
      },
      {
        title: '高風險系統的七大義務 (前半)',
        explanation: `1.  **建立並維護風險管理系統**: 提供者必須在AI系統的整個生命週期中，建立一個持續的風險識別、評估和緩解流程。這是一個動態的過程，需不斷更新。\n2.  **高品質的資料治理**: 用於訓練、驗證和測試的資料集，必須滿足高品質要求。這包括確保資料具有**相關性、代表性、無錯誤且完整**。提供者必須有適當的資料治理和管理實踐，並對資料集建立詳盡的文檔，說明其來源、範圍和特性。\n3.  **備妥詳盡的技術文件**: 在系統上市前，必須備妥一套詳盡的技術文件，其內容足以讓主管機關評估該系統是否符合所有規定。文件內容應包含系統的一般描述、設計規格、風險管理、資料治理實踐、驗證與測試結果等。\n4.  **保留紀錄 (日誌功能)**: 系統的設計必須能自動、可追溯地記錄事件（Logs）。這些日誌應足以讓事後能夠追蹤系統的運行狀況、決策過程，並監控其是否符合預期，是實現問責性的基礎。`
      }
    ],
    applications: [
      { scenario: 'AI履歷篩選系統', description: '一家企業使用AI來自動篩選和排序求職者的履歷。由於這屬於附件三中的「就業」領域，該AI系統將被視為「高風險」。企業（作為使用者）必須確保其採購的系統符合法案要求，而系統的提供者則必須能出示其資料治理實踐（證明訓練資料無偏見）、風險管理計畫等技術文件。' },
      { scenario: 'AI醫療診斷軟體', description: '一家公司開發AI軟體以輔助醫生從X光片中診斷肺炎。由於該軟體屬於醫療器材，其內嵌的AI系統將自動被歸類為「高風險」。該公司在上市前，必須完成對應的合格評定程序，並備妥所有七大義務所要求的文件與證據。' }
    ],
    memoryAids: [
      {
        title: '高風險八大領域速記',
        explanation: '「**生**、**基**、**教**、**勞**、**公**、**法**、**移**、**司**」：生物辨識、基礎設施、教育、勞工、公共服務、執法、移民、司法。'
      }
    ],
    summary: '高風險系統的分類規則與嚴格義務，構成了歐盟AI法案的監管核心。對於任何可能落入高風險範疇的AI應用，其提供者都必須從專案初期就將風險管理、資料治理、技術文件和日誌紀錄等合規要求，內化為開發流程的一部分，這不僅是法律要求，也是建立可信賴AI的基礎。'
  },
  L34103: {
    introduction: '本單元接續探討歐盟AI法案第三章中關於高風險系統的內容，將完成對七大核心義務的後半部分介紹，並進一步深入解析法案如何為AI供應鏈中的不同角色——包括提供者、進口商、經銷商及使用者——分配各自的責任與義務。法案強調，確保AI的合規性是整個價值鏈的共同責任。',
    keyConcepts: [
      {
        title: '高風險系統的七大義務 (後半)',
        explanation: `5.  **對使用者提供透明且清晰的資訊**: 提供者必須向使用者提供足夠的、清晰易懂的資訊，使其能夠理解AI系統的能力、限制，並能正確地使用和解讀其輸出。這包括一份詳盡的使用說明書。\n6.  **確保適當的人類監督**: 系統的設計必須確保能由人類進行有效的監督。人類監督的措施應旨在預防或最小化風險，並應允許人類擁有「不使用」、「干預」、「停止」或「忽略」系統輸出的權利。監督的程度應與風險等級相稱。\n7.  **高度的準確性、穩健性與安全性**: 系統必須在其整個生命週期中，達到與其預期目的相稱的技術要求。\n    • **準確性**: 應在上市前進行嚴格的測試，並將其性能指標和可接受的誤差範圍在技術文件中明確說明。\n    • **穩健性**: 系統應能抵抗因錯誤或不一致的輸入而產生的錯誤，並在面對意外情況時能有優雅的應對或降級機制。\n    • **安全性**: 系統應具備與其風險相稱的網路安全防護能力，能抵禦試圖利用其漏洞的惡意攻擊。`
      },
      {
        title: '供應鏈各角色的義務',
        explanation: `• **提供者 (Provider)**: 是將AI系統投放市場或投入使用的主要責任方（無論是自行開發還是使用第三方工具）。他們必須承擔前面所述的全部七大義務，確保系統從設計到上市都完全合規，並負責進行合格評定程序（如CE標誌）。
• **進口商 (Importer)**: 是將位於歐盟境外的AI系統首次引入歐盟市場的實體。他們有義務核實該系統的提供者已經履行了所有合規義務、備妥技術文件並貼上CE標誌。他們還需在產品上標示自己的聯絡資訊。
• **經銷商 (Distributor)**: 是在歐盟市場上使AI系統可用的實體（提供者或進口商除外）。他們同樣有義務在分銷前，核實系統具備CE標誌和必要文件。
• **使用者 (User / Deployer)**: 是在自身權限下使用AI系統的任何實體（專業用途）。他們的主要義務是：(1) 按照提供者的使用說明來操作AI系統；(2) 確保輸入資料的相關性；(3) 實施人類監督；(4) 監控系統的運行，並在發現重大風險或事件時，通知提供者和主管機關。`
      }
    ],
    applications: [
      { scenario: '供應鏈責任劃分案例', description: '一家美國公司（提供者）開發了一套AI信貸評分軟體。一家德國公司（進口商）將該軟體引進歐盟。一家法國銀行（使用者）購買並使用該軟體來評估客戶貸款申請。在這個鏈條中：美國公司需確保軟體完全符合七大義務。德國公司需核實美國公司已完成所有合規工作。法國銀行則有責任正確地使用該軟體，並對其信貸決策進行有效的人類監督。' }
    ],
    memoryAids: [
      {
        title: 'AI供應鏈的守門人',
        explanation: '• **提供者**: 產品的「製造商」，負全責。\n• **進口商**: 將產品帶進門的「海關」，負責檢查。\n• **經銷商**: 在市場上賣貨的「零售商」，負責檢查。\n• **使用者**: 使用產品的「司機」，負責安全駕駛。'
      }
    ],
    summary: '歐盟AI法案透過對高風險系統的嚴格要求，以及對供應鏈各方責任的清晰劃分，建立了一個全方位的監管閉環。從技術上的準確性、穩健性到流程上的人類監督，再到市場流通中的層層把關，法案確保了高風險AI的開發與使用是在一個可控、可問責的框架下進行。'
  },
  L34104: {
    introduction: '除了針對特定風險應用的監管，歐盟AI法案也意識到通用目的AI模型（GPAI，或稱基礎模型，如GPT系列）的巨大影響力，並為其設立了專門的規範。此外，對於不屬於高風險但仍可能對使用者產生影響的AI系統，法案也規定了特定的透明度義務。本單元將深入探討法案第四、五章的內容，解析這些針對通用模型和特定系統的「陽光條款」。',
    keyConcepts: [
      {
        title: '有限風險系統的透明度義務 (Chapter IV)',
        explanation: `對於某些特定AI系統，即使其風險有限，但為了避免使用者被誤導或操縱，法案規定了明確的透明度義務。使用者必須被清楚地告知他們正在與AI互動，或正在觀看由AI生成的內容。
1. **與AI互動的系統**: 任何旨在與自然人互動的AI系統（如聊天機器人、虛擬客服），都必須讓使用者知曉他們是在與一個AI系統互動，除非這一點已非常明顯。
2. **情緒識別與生物分類系統**: 使用者必須被告知該系統正在運作。
3. **深度偽造 (Deepfake)**: 由AI生成或操一同的圖像、音訊或影片內容，如果它們看起來像真實的人、物、地點或事件，並且可能被誤認為是真實的，就必須以清晰可見的方式標示為「人工生成」或「經操縱」。
4. **AI生成文本**: 由AI生成的、旨在向公眾發布的關於公共利益事項的文本，也必須標示為人工生成。`
      },
      {
        title: '通用目的AI模型 (GPAI) 的規範 (Chapter V)',
        explanation: `法案為所有GPAI模型的提供者設定了基礎的義務，旨在確保整個AI生態系的透明與合規。
• **所有GPAI模型的義務**:
  - **備妥並更新技術文件**: 包含模型的訓練與測試過程、所用資料的概述等。
  - **向下游提供者提供資訊**: 提供足夠的資訊，讓下游的AI系統提供者能夠理解模型的能力、限制，並使其能夠履行自身在高風險系統下的義務。
  - **制定版權政策**: 必須制定並公開一份政策，說明如何遵守歐盟的版權法規（例如，在訓練資料方面）。
  - **公開訓練內容的詳細摘要**: 需公開一份關於用於訓練模型的內容的詳細摘要。`
      },
      {
        title: '具「系統性風險」的GPAI模型的額外義務',
        explanation: `對於那些能力特別強大、經評估可能對社會產生系統性風險的GPAI模型（如OpenAI的GPT-4），法案施加了更為嚴格的額外義務：
• **進行模型評估**: 必須對模型進行標準化的性能評估，包括對抗性測試，以識別和緩解潛在風險。
• **評估與緩解系統性風險**: 必須評估並緩解任何可能源於該模型的系統性風險。
• **追蹤與報告嚴重事件**: 必須建立流程來追蹤和報告可能由模型引起的嚴重事件。
• **確保高度的網路安全**: 必須採取措施來保護模型本身及其物理基礎設施的安全。
• **報告能源消耗**: 必須記錄並公開模型的能源消耗情況。`
      }
    ],
    applications: [
      { scenario: '新聞媒體使用AI生成文章', description: '一家線上新聞媒體使用一個GPAI模型來自動生成關於財經市場的分析報導。根據法案，由於該文章涉及公共利益，媒體在發布時必須清晰地標示「本文由AI輔助生成」，以履行其透明度義務。' },
      { scenario: '新創公司基於GPT-4開發應用', description: '一家歐洲新創公司使用OpenAI的GPT-4 API來開發一個高風險的AI法律文件審閱工具。作為具有系統性風險的GPAI提供者，OpenAI有義務向這家新創公司提供詳盡的技術文件和模型能力說明，以幫助該公司完成自身在高風險系統下的合規要求。' }
    ],
    memoryAids: [
      {
        title: '透明度三原則：說、標、明',
        explanation: '• **說**: 跟人聊天，要**說**是AI。\n• **標**: 生成內容，要**標**是假的。\n• **明**: 公開文章，要**明**是AI寫的。'
      }
    ],
    summary: '歐盟AI法案不僅監管終端應用，更向上游追溯，對作為AI生態系基石的通用模型施加了關鍵的透明度與風險管理義務。這些「陽光條款」旨在確保從模型的開發者到最終的使用者，整個鏈條上的資訊是透明的，權責是清晰的，從而建立一個更健康、更值得信賴的AI生態系。'
  },
  L34105: {
    introduction: '歐盟AI法案的目標並非抑制創新，而是在確保安全與基本權利的框架下，引導AI的健康發展。為此，法案第六、七章特別設計了支持創新的措施，並建立了一個清晰、多層次的治理架構來確保法案的統一實施。本單元將介紹法案中的「監管沙盒」機制，以及負責監督法案執行的歐盟層級與國家層級的關鍵機構。',
    keyConcepts: [
      {
        title: '支持創新的措施 (Chapter VI)',
        explanation: `• **AI監管沙盒 (AI Regulatory Sandboxes)**: 這是法案促進創新的核心機制。
  - **是什麼**: 由國家主管機關設立的一個受控的「實驗環境」。它允許AI系統的提供者或潛在提供者（特別是新創與中小型企業），在上市前或投入使用前，於一個真實或模擬的環境中，在主管機關的直接監督下，開發、訓練、驗證和測試其創新的AI系統。
  - **目的**: 旨在降低創新者的合規門檻與不確定性，讓他們可以在一個安全的「沙盒」環境中測試其產品，並從監管機構獲得指導，確保其從一開始就符合法案要求。
  - **參與**: 參與沙盒應基於自願原則。
• **支持中小企業(SMEs)**: 法案要求各成員國應採取措施，為中小企業提供優先進入監管沙盒的機會、設立專門的溝通管道以提供指導，並在某些情況下考慮減免其合格評定費用。`
      },
      {
        title: '治理架構 (Chapter VII)',
        explanation: `法案建立了一個雙層的治理結構：
• **歐盟層級**:
  - **歐洲人工智慧辦公室 (AI Office)**: 設立於歐盟執委會內部的一個新機構。它是整個法案在歐盟層級的執行核心，負責監督對通用目的AI模型的執法、協調各國標準、處理跨境事務，並為整個治理體系提供專業支持。
  - **歐洲人工智慧委員會 (AI Board)**: 由每個歐盟成員國的一名代表組成。其主要職責是作為一個諮詢機構，向執委會和成員國提供建議和專業知識，促進各國監管實踐的一致性，並協助制定相關標準。
• **國家層級**:
  - **國家主管機關 (National Competent Authority)**: 每個歐盟成員國都必須指定一個或多個國家級的主管機關，負責在其境內實施和執行AI法案。
  - **市場監督機關 (Market Surveillance Authority)**: 負責對已進入市場的AI系統進行監督、檢查和執法。`
      }
    ],
    applications: [
      { scenario: '一家新創公司的發展路徑', description: '一家位於愛爾蘭的新創公司開發了一款用於早期皮膚癌篩查的高風險AI應用。由於對合規流程不熟悉，他們申請加入了愛爾蘭主管機關設立的AI監管沙盒。在沙盒中，他們可以在真實的匿名化醫療數據上測試其演算法，並從監管機構獲得關於資料治理和風險管理的直接指導，從而大大加速了其產品的合規上市進程。' }
    ],
    memoryAids: [
      {
        title: '治理架構：一大腦、一議會、眾手腳',
        explanation: '• **一大腦**: AI辦公室 (AI Office) - 歐盟層級的執行核心。\n• **一議會**: AI委員會 (AI Board) - 各國代表的諮詢機構。\n• **眾手腳**: 國家主管機關 - 各國的在地執法單位。'
      }
    ],
    summary: '歐盟AI法案在嚴格監管的同時，也透過監管沙盒等機制為負責任的創新預留了空間。其建立的歐盟與國家雙層治理架構，旨在確保這部複雜的法規能夠在27個成員國中得到一致、有效的實施。這套「胡蘿蔔加大棒」的組合拳，體現了歐盟在AI治理上的務實與遠見。'
  },
  L34106: {
    introduction: '一部法律的效力，取決於其執行的強度。歐盟AI法案的第八章和第十章賦予了其真正的「牙齒」。第八章詳細規定了AI系統上市後的持續監督義務，而第十章則明確了違反法案將面臨的嚴厲處罰。本單元將深入探討這兩個章節的內容，解析企業在AI產品上市後的持續責任，以及未能履行義務可能導致的嚴重後果。',
    keyConcepts: [
      {
        title: '上市後監督 (Post-Market Monitoring, PMM) (Chapter VIII)',
        explanation: `AI的合規性並非一次性的上市審查，而是一個持續的過程。高風險AI系統的提供者必須建立並維護一個與其風險等級相稱的上市後監督系統。
• **目的**: 主動地、系統性地收集、記錄和分析AI系統在整個生命週期中的性能數據和相關經驗。
• **核心義務**:
  - **建立PMM計畫**: 需制定一份詳盡的計畫，說明將如何收集和分析性能數據、用戶回饋、相關技術發展等資訊。
  - **報告嚴重事件**: 一旦發現其AI系統導致或可能導致了嚴重事件（如對健康、安全、基本權利的嚴重威脅），提供者有義務立即向相關國家的市場監督機關報告。
  - **採取糾正措施**: 當發現系統不合規或存在風險時，提供者必須立即採取必要的糾正措施，如更新、召回或撤下產品，並通知經銷商、進口商和使用者。`
      },
      {
        title: '市場監督與資訊分享',
        explanation: `• **市場監督機關的權力**: 國家市場監督機關有權對市場上的AI系統進行檢查，要求提供技術文件，甚至進入企業場所進行稽查。如果發現不合規的系統，他們有權要求提供者採取糾正措施、限制其上市，甚至下令召回。
• **歐盟層級的資料庫**: 將建立一個公開的歐盟資料庫，用於註冊獨立的高風險AI系統，提高市場透明度。`
      },
      {
        title: '罰則 (Penalties) (Chapter X)',
        explanation: `這是確保法案被嚴格遵守的最強硬手段。罰款的金額是分級的，並且是基於公司的【全球年度總營業額】計算，使其極具威懾力。
• **最高罰則 (Tier 1)**: 違反「禁止的AI實踐」（第二章）或高風險系統的資料治理義務。
  - **罰款**: 最高可達 **3500萬歐元** 或 上一財年全球年度總營業額的 **7%**，以較高者為準。
• **次高罰則 (Tier 2)**: 違反法案中的其他大部分義務，例如高風險系統的其他合規要求、GPAI模型的義務等。
  - **罰款**: 最高可達 **1500萬歐元** 或 全球年度總營業額的 **3%**，以較高者為準。
• **最低罰則 (Tier 3)**: 向主管機關提供不正確、不完整或誤導性的資訊。
  - **罰款**: 最高可達 **750萬歐元** 或 全球年度總營業額的 **1.5%**，以較高者為準。`
      }
    ],
    applications: [
      { scenario: 'AI系統的持續監控', description: '一家醫療AI公司的高風險診斷軟體上市後，其PMM團隊會持續分析來自醫院的匿名使用數據和醫生回饋。當他們發現軟體對某個特定人群的誤診率有上升趨勢時，必須立即調查原因，發布軟體更新作為糾正措施，並評估是否需要向主管機關報告。' },
      { scenario: '罰則的巨大影響', description: '一家全球年營業額為100億歐元的大型科技公司，如果被發現在歐盟市場上使用了被禁止的社會信用評分系統，它可能面臨最高達7億歐元（100億的7%）的天價罰款。' }
    ],
    memoryAids: [
      {
        title: '罰款三級跳：7%, 3%, 1.5%',
        explanation: '記住三個關鍵的罰款比例，由重到輕：\n• **7%**: 踩了「紅線」（禁止的AI）。\n• **3%**: 沒做「功課」（違反其他主要義務）。\n• **1.5%**: 說了「謊話」（提供不實資訊）。'
      }
    ],
    summary: '上市後監督義務與嚴厲的罰則條款，共同構成了歐盟AI法案的執法閉環。它明確傳達了一個信號：AI的責任是持續的，違規的代價是高昂的。這將迫使所有市場參與者，從AI的開發到使用的每一個環節，都必須將合規性作為最高優先級。'
  },
  L34107: {
    introduction: '在規定了嚴格的強制性義務之外，歐盟AI法案也為市場的自我調節和軟性治理預留了空間，並提供了法案生效與實施的具體時間表。本單元將介紹法案第九章中關於「行為準則」的內容，並總結法案第十一至十三章中關於授權、生效日期與過渡期的最終條款，為企業的合規準備提供一個清晰的時間規劃。',
    keyConcepts: [
      {
        title: '行為準則 (Codes of Conduct) (Chapter IX)',
        explanation: `• **是什麼**: 由AI系統的提供者、使用者或相關的產業協會等，【自願】制定的一套實踐準則。
• **目的**: 旨在為【非高風險】的AI系統，如何有效地、自願地應用高風險系統的某些要求（如風險管理、人類監督等）提供清晰、具體的指導。它也是一個鼓勵實踐法案總體目標（如環境永續、性別平等等）的工具。
• **角色**: 行為準則是對強制性法律的補充，而非替代。它為風險較低的AI應用提供了一個「軟法」治理的途徑，鼓勵產業的最佳實踐。
• **範疇**: 準則可以涵蓋如永續發展、利益相關者參與、促進AI素養等主題。`
      },
      {
        title: '授權、委員會程序與最終條款 (Chapters XI-XIII)',
        explanation: `這些章節主要涉及法案的立法技術細節和實施時間表。
• **授權與程序**: 規定了歐盟執委會如何制定執行法案所需的技術標準、更新高風險清單等的權力與程序。
• **生效與實施時間表 (Timeline)**: 這是所有企業最關心的部分。法案的實施是分階段的，給予市場足夠的適應時間：
  - **法案生效 (Entry into Force)**: 在歐盟官方公報上公布後的第20天。
  - **法規開始適用 (Application)**:
    - **生效後6個月**: 成員國必須廢除或修改與法案中「禁止的AI實踐」相衝突的國內法規。**禁止條款開始適用**。
    - **生效後12個月**: 關於「通用目的AI模型(GPAI)」的義務開始適用。
    - **生效後24個月**: 法案的**絕大部分條款**開始全面適用，包括對高風險AI系統的義務。
    - **生效後36個月**: 針對某些作為受規管產品安全組件的AI系統的義務開始適用。
• **過渡期**: 對於在法規全面適用之日（生效後24個月）前就已經投放市場的AI系統，提供了一定的過渡期，讓其有時間進行調整以符合法案要求，但某些重大變更除外。`
      }
    ],
    applications: [
      { scenario: '遊戲產業的行為準則', description: '歐洲的遊戲開發者協會，可以共同制定一份關於在遊戲中負責任地使用生成式AI的行為準則。該準則可能涵蓋如何防止生成有害內容、保護未成年玩家、以及尊重用於訓練的數據版權等，以向公眾和監管機構展示其產業的自律和社會責任。' },
      { scenario: '企業的合規時間規劃', description: '一家正在開發高風險AI應用的公司，在法案生效後，必須立即檢視其產品是否涉及任何被禁止的實踐。然後，他們有大約24個月的時間來調整其開發流程、完善技術文件、建立風險管理體系，以確保在法規全面適用之日能夠完全合規。' }
    ],
    memoryAids: [
      {
        title: 'AI法案上路時間表',
        explanation: '• **+6個月**: 紅燈亮起（禁止條款生效）。\n• **+12個月**: 基礎模型要守規矩（GPAI義務生效）。\n• **+24個月**: 全面執法（大部分條款生效）。'
      }
    ],
    summary: '歐盟AI法案的最終章節，為市場的軟性治理和法規的平穩過渡提供了清晰的路徑圖。透過鼓勵自願性的行為準則，法案在剛性的法律之外，也促進了產業的最佳實踐。其分階段實施的時間表，則為全球所有受影響的企業提供了寶貴的緩衝期，來理解、消化並落實這部複雜而深遠的法規，迎接AI監管新時代的到來。'
  }
};
